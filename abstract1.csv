All Abstracts,
Project 1It is hardly necessary to say that taking a chemical approach to study the origin of life is adventurous and risky. However| all living things must have arisen from some form of prebiotic chemistry and this has attracted chemists for decades. A question of particular importance is how the first macromolecules such as proteins were formed. It is often postulated that such molecules would only arise after a genetic system was established (this is the case in the modern world). We are going to try to assemble large protein-like molecules from a concentrated solution of short peptides. The peptides will contain a random arrangement of amino acids and we hope that they will come together in such a way as to produce an active protein-like molecule. We will try to stabilise these large molecules and study their properties.Project 2Oxygenated functional groups are the spine of organic chemistry. Many of the most common functional group interconversions involve breaking the strong carbon-oxygen bond| a seemingly trivial operation in modern organic chemistry. Whilst this process is indeed straightforward| there is always a price to pay in terms of the activating agents that must be added to drive the chemistry to completion. This price can be hidden in the lab| where the small scale of reactions and powerful analytical methods renders reaction by-products unimportant. On the process scale however| the requirement for large quantities can create severe environmental and economic problems in terms of cost| purification| toxicity and waste processing that can render otherwise good reactions entirely unworkable. A powerful solution to these problems would be to develop processes that use catalytic amounts of activating agents.
In this project 'Radiation and Us: Making the Invisible Visible' we will develop interactive exhibits and shows to be situated in Northern Ireland's premier interactive science centre| W5. This will be done through a partnership of researchers into the medical uses of radiation from Queen's University and science communications experts from W5. The title of the project has a double meaning: radiation is often used to make visible of our insides which would otherwise remain invisible. Additionally| in this project| through the interactive simulations we will make the detailed behaviour of the invisible radiation visible to all.People generally have a negative view of radiation| considering it to be a mysterious entity. It is usually associated with negative things like bodily harm| destruction| danger and nuclear war. These negative associations can be a barrier to people's understanding and learning. However radiation has many interesting and positive uses including medical applications.Radiation is invaluable for medical diagnosis techniques ranging from the X-rays we all know from the dentist to more sophisticated ways of making three dimensional images of the insides of our bodies. Radiation is also invaluable in the treatment of cancer| being the second most common form of therapy after surgery. By illustrating the science behind these positive uses of radiation we hope to engage the audience and encourage some of the pupils to study the relevant sciences further.Because of radiation's invisibility and the safety concerns associated with it| it is not possible for school pupils or members of the general public to learn by doing activities involving radiation directly. However researchers into its medical uses have sophisticated computer simulations which show how the radiation travels through our bodies either for making X-ray images or for the treatment of cancer.We will use some of these simulations to develop an interactive exhibit to be situated in Northern Ireland's premier interactive science centre| W5 supported by shows covering the same topic. The interactive simulations will also be distributed using the World Wide Web and CD ROMs.These simulations will be designed to have an educational benefit for pupils from 12 years upwards but also to be of interest to the general public. They will present the user with challenges such as making a radiotherapy plan| avoiding a patient's sensitive organs with the radiation while getting enough of it into the patient's tumour. Radiation tracks will be displayed to demonstrate the science of radiation as well as its medical applications. The user will be presented with a scientifically accurate view of the creation and stopping of some of the X-rays and particles as it would occur inside a patient's body. This will take the form of an ever-changing animated display of the tracks created by the particles. The users will be able to interact with the simulations by sending in radiation from different directions and see how the X-rays and particles interact differently with different parts of the body. For example the bones stop more of the X-rays as we all know from X-ray photographs but in these simulations we can all see it happening before our eyes| making the behaviour of the invisible radiation visible.
Elastic fibres play a key role in normal tissue function| and age-related degenerative alterations in their biomechanical properties severely affect dynamic functions of the cardiovascular system| lungs and skin. This study aims to provide important information on the effects of ageing on the properties of tissue by bridging the gap between known mechanical changes at the whole tissue and molecular levels. This will be achieved through developing acoustic methods for characterising the mechanical properties of soft tissue. By using high frequency acoustic microscopy in the frequency range of 100 MHz - 1 GHz we will obtain spatially resolved maps of mechanical properties in thin histological sections with a spatial resolution in the x y plane of around 1 micron. This information will then be correlated with changes in the properties of elastic fibres extracted from tissue and combined with conventional biochemical| ultrastructural and proteomic approaches| to shed light on the causative mechanisms of elastic fibre ageing.
This feasibility study determines if the economics-inspired mechanisms recently proposed by Huberman and Jurca can create on-line service provision businesses that can be trusted by customers without reliance on brand or reputation of the provider. Practical deployment of these economics-inspired 'instant trust' approaches faces steep challenges and unknowns| both with respect to the feasibility of the technological ICT implementation and to the practicality of the associated business models. In particular| the mechanisms are based on theoretical assumptions (e.g.| perfect sharing of information) that may be hard toimplement and may result in business models (e.g.| compensation payments) that may pose unacceptable business risks. This feasibility study therefore aims at determining technical as well as business feasibility of these economics-inspired instant trust approaches. We will study this question assuming a service provider scenario| and in collaboration with an entertainment application server provider SME. If successful| the project has the potential to open up the service provision market| allowing small and medium-sized enterprizes to break into these markets| while at the same time better protecting customers against one-sided terms and conditions.
It is proposed to undertake a study of fundamental structural properties of noncommutative rings and algebras involving the notions of nil algebras| algebraic algebras and growth of algebras (Gelfand-Kirillov dimension).There are very difficult open problems in each of these areas| and also there are many interconnections between the three main themes. The project will investigate several of these open problems.The most famous problem in the area of nil algebras is the Koethe Conjecture| first posed in 1930| which asserts that if a ring has no nonzero nil ideals then it has no nonzero nil one-sided ideals. This is a fundamental question about the general structure of rings| and a thorough understanding of nil and nilpotent rings is necessary for any serious attempt to understand general rings. Related problems concerning nil rings will be one of the main themes of this project. The Fellow has already made fundamental contributions to this area| including the construction of a simple nil algebra over any countable field.The most famous problem about algebraic algebras is the Kurosh Problem which asks whether the knowledge that a finitely generated algebra is algebraic over a base field is sufficient to ensure that the algebra is finite dimensional. This is untrue in general| as demonstated by Golod and Shafarevich in 1964. However| many partial positive results are known| and a second main theme of the project is to clarify the borderline between positive and negative solutions of the Kurosh Problem. There are close connections between this theme and the previous theme: for example| the Golod-Shafarevich algebras are infinite dimensional nil algebras that are not nilpotent.The third main theme is the growth of algebras| and| in particular| a study of algebras with restricted growth. The Fellow has already made a fundamental contribution to this area in proving the Artin-Stafford Gap Theorem| which asserts that there are no graded domains with growth strictly between 2 and 3.A substantial part of the third theme will be to investigate the problems arising in the first two themes under restrictions on the growth of the algebras. For example| the Golod-Shafarevich algebra has exponential growth| but the Fellow has recently produced a examples with (relatively) small growth. The exact limits on the growth conditions in many of the open problems will be investigated in the project.
Source separation is a critical early processing stage in electronic surveillance systems where the multiple simultaneouslyintercepted transmissions need to be detected| separated and identified for possible threats (e.g. pulsed and continuouswave radar| navigation systems| etc.). When the signals to be detected and separated overlap in time and frequency thiscan prove a challenging signal processing task that cannot be solved through simple filtering or beamforming.Recently sparse representations have emerged as a very powerful technique for solving source separation problems|particularly in underdetermined scenarios (i.e when there are fewer target sources than sensors)| including the difficultcase of single channel source separation. Sparse representations usually exploit prior knowledge of the nature of thesignals to be intercepted to create 'nonlinear' separation algorithms that substantially surpass the performance oftraditional filtering techniques. Furthermore| in certain circumstances| they can also be adapted to learn the structure ofthe signals being observed to achieve the separation in a totally blind manner.The aim of this project is to develop new algorithms based around sparse representations capable of detection|separation and classification of individual EM signals that overlap in time and frequency. In addition computationalefficiency will be pursued by borrowing recent ideas from compressed sensing theory.
Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission| but may be because it included sensitive information such as personal details.
This research project is exploring how firms are applying and engaging with new digital technologies to become more efficient| profitable and dynamic. While there is considerable understanding about how digital technologies allow firms to create value| there is much less understanding of how firms can use DE to sense what consumers and society needs and monetize that value and turn it into financial returns for investors| entrepreneurs and shareholders. This is part of a more general concern that the UK economy is relatively good at invention but less good at producing firms that capture its benefits in new| fast growing markets. By exploring how digital technology is transforming the three elements that make up a business model - how firms understand customers' needs| how they create value for customers| and how they capture and monetize this value - this project will generate new understanding about how digital technology can be commercialised more effectively. This knowledge will help firms in the UK generate more jobs| more economic growth and improved services to firms and the general public. 

The empirical part of the project will conduct research on (a) sectors that generate digital technology such as open-source software (b) sectors that use digital technology in products of services such as digital entertainment and (c) sectors that use DE in their processes such as B2B financial services. The results will help us understand:
- (a) how firms sense and understand what their customers (and society) want using digital technologies. For example| there are now large data-sets being generated about how individuals interact with new products and services| which can increasingly be collected in real time to allow much faster feedback from customers about their likes and dislikes. Similarly| new sensors are allowing firms to monitor how other firms are using their products and services. This information| and the closer engagement with customers digital technologies allow| can be used to inform better decisions about customers' needs and faster and more effective decision making about the design of new commercial offerings. 
- (b) how they create value for their customers. For example| new digital technologies allow a much larger information content to be provided with goods and services| they enhance the allocation of resources| they allow pre-emptive maintenance and allow improved financial modelling| etc. These changes are increasing the commercial opportunities between traditional sectors| where firms can create value in areas where there is limited competition.
- (c) how they capture (and monetize) that value. Digital technologies can fundamentally change markets. As a result| it is often unclear how they capture the value that they create. This was seen in the failure of many dot.com firms| but even today many firms are failing to turn the value they generate through innovation into commercial returns and profits. 

The project will also engage in fundamental theoretical research about the nature of models| and modelling in the economy and explore how managers can and should use models. For this work the project draws on expertise from a wide range of academic disciplines| including philosophy of science| sociology| engineering and the natural sciences. 

In all this work| the project team will engage closely with industrialists and non-academic research users in the UK government and civil society. A key part of the project involves building capacity in this area| which will be achieved through a significant investment of time and effort in training for the wider academic community and career development for junior researchers able to work closely with a wide body of other researchers across the boundaries that separate industry| academia and government.
The behaviour of multiphase particulate or granular systems (e.g. in fluidised beds and pneumatic conveyors) presents severe experimental problems because they are opaque| largely preventing the use of optical techniques. Also| inserting physical probes inevitably disturbs the system under investigation. Thus| it has been difficult to develop reliable scale up criteria or validate numerical simulations of these systems. We aim to validate and explore the limitations of measurement using two complementary| non-intrusive experimental techniques: Electrical Capacitance Tomography (ECT) and Magnetic Resonance Imaging (MRI)| using the combined expertise of Ohio State University (ECT) and Cambridge (MRI). Particular regard will be paid to the applicability of these techniques in the validation of the predictions of Discrete Element Modelling (DEM) and in the development of scale-up criteria in gas-fluidised beds. This is timely| given recent developments in all three of these areas| particularly in the potential that ECT could have in the design of truly industrial-scale fluidised beds| provided it is properly validated.The experimental techniques considered here (MRI and ECT) are complementary in that their strengths lie in measuring different features of multi-phase granular systems. MR enables the bulk solids motion to be visualised| as well as the particle velocity profiles| in both the dense solids phase and the lean (bubble| jet| void) phase . Furthermore| it is possible to determine voidage profiles. We also propose to extend MR to be able to image gas directly for the first time in a multiphase system. ECT has a major advantage in that it does not have any serious restrictions regarding size| although equipment must be non-metallic. As with MRI| it is possible to determine the velocity of voids| i.e. bubbles and slugs| and voidage profiles. The velocity of the bulk solids cannot be determined| however. Importantly| there is an overlap in the variables which can be measured by either technique| the most important ones being voidage profiles and the rise velocity of voids. These measurements will be used for cross-validation of the two techniques.
Intermolecular interactions involving molecules with unpaired electrons are a crucial part of phenomena ranging from nerve cell signalling to water oxygenation| and it is necessary to know the intermolecular potential in order to predict the preferred alignment of molecules in atmospheric chemistry and in gas-phase chemical reactions such as combustion. However| intermolecular potentials are difficult to obtain| and molecules with unpaired electrons further complicate the situation| especially when an unpaired electron can occupy two or more orbitals with similar energies.In our proposed work| we shall develop and assess the theoretical methods that we believe are the most promising for calculating intermolecular potentials of molecules with unpaired electrons| and apply the methods to interactions involving the chemically important molecule NO| whose unpaired electron can occupy two different 'pi' orbitals. These orbitals are equal in energy (degenerate) in the isolated NO molecule| but not when other molecules interact with it in weakly bound molecular complexes. We shall use a range of experimental methods to obtain information about these NO-X complexes| where X includes a number of diatomic molecules| rare gas atoms| and methane| and the NO molecule will be prepared in several different electronic and spin-orbit states.The work will involve collaboration between research groups at the Universities of Nottingham and Oxford| with experience in the calculation of intermolecular potentials| quantum chemistry of excited electronic states| and spectroscopy of Van der Waals complexes. The breadth and depth of this expertise| supported by collaborations with other leading research groups and by nationally-leading supercomputer facilities| offers the likelihood of substantial progress in this topical and exciting area of research. The spectroscopy of NO-X complexes will use microwave spectroscopy to obtain detailed information on the low-energy regions of the potential energy surfaces| and stimulated emission pumping to obtain information on the higher-energy vibrational and rotational states of the complexes in the ground electronic state. This will provide new information on the Van der Waals stretching motion and the hindered rotational motion of the complexes| and on the interplay between the spin-orbit interaction in the NO monomer and the Van der Waals interaction between the two monomers.Intermolecular potentials for the NO-X complexes will be calculated using a combination of the supermolecule method and new methods including intermolecular perturbation theory and the Maximum Overlap Method. The splitting of the spatial degeneracy by the intermolecular interaction makes these calculations non-standard and very challenging| especially for excited states and for polyatomic molecules X. From the intermolecular potentials| theoretical rotational and vibrational spectra will be predicted by solving the Schrdinger equation for the nuclear motion of the complex| including the non-Born-Oppenheimer effects that arise from coupling of the different spin-orbit states of NO by the intermolecular potential.The interplay between experiment and theory will be crucial| because the new theoretical methods can be assessed by their ability to reproduce the experimental data| and the results of the theoretical calculations will give additional| detailed| information on the potential energy surfaces| which cannot be obtained from the experiments. It is also expected| from our recent work on NO-methane and on the A states of NO-rare gas complexes| that the spectra will prove to be complicated and difficult to assign. The theoretical calculations will therefore be invaluable in understanding the experimental data.
What is it about maggots that makes them good at wound healing? What are the best experimental conditions for engineering bone tissue in the laboratory? How do plaques form in blood vessels and can we predict when they are likely to rupture? What causes curvature of the spine in children and how can surgery be used to minimise its effect?The above questions illustrate the types of problems that can be studied by teams of mathematicians working in partnership with biologists and clinicians. The aim of this proposal is to organise a series of multidisciplinary meetings (mathematics-in-medicine study groups) and workshops at which mathematicians| biologists and clinicians collaborate on similar important biomedical problems. As a result we hope to promote the application of mathematical modelling to issues of medical importance and to ensure that the UK maintains a leading role in this rapidly developing field.
Our overall objective is to develop algorithms for long distance route-based visual navigation through complex natural environments. Despite recent advances in autonomous navigation| especially in map-based simultaneous localisation and mapping (SLAM)| the problem of guiding a return to a goal location through unstructured| natural terrain is an open issue and active area of research. Despite their small brains and noisy low resolution sensors| insects navigate through such environments with a level of performance that outstrips state-of-the-art robot algorithms. It is therefore natural to take inspiration from insects. There has been a history of bio-inspired navigation models in robotics but there are known components of insect behaviour yet to be incorporated into engineering solutions. In contrast with most modern robotic methods| to navigate between two locations| insects| use procedural route knowledge and not mental maps. An important feature of route navigation is that the agent does not need to know where it is at every point (in the sense of localizing itself within a cognitive map)| but rather what it should do. Insects provide further inspiration for navigation algorithms through their innate behavioural adaptations which simplify navigation through unstructured| cluttered environments.One objective is to develop navigation algorithms which capture the elegance and desirable properties of insect homing strategies - robustness (in the face of natural environmental variation)| parsimony (of mechanism and visual encoding)| speed of learning (insects must learn from their first excursion) and efficacy (the simple scale over which insects forage). Prior to this we will bring together current insights regarding insect behaviour with novel technologies which allow us to recreate visual input from the perspective of foraging insects. This will lead to new tools for biologists and increase our understanding of insect navigation. In order to achieve these goals our Work Packages will be:WP1 Development of tools for reconstructing large-scale natural environments. We will adapt an existing panoramic camera system to enable reconstruction of the visual input experienced by foraging bees. Similarly| we will adapt new computer vision methods to enable us to build world models of the cluttered habitats of antsWP2 Investigation of optimal visual encodings for navigation. Using the world model developed in WP1| we will investigate the stability and performance of different ways of encoding a visual sceneWP3 Autonomous route navigation algorithms. We will test a recently developed model of route navigation and augment it for robust performance in natural environmentsOur approach in this project is novel and timely. The panoramic camera system has just been developed at Sussex. The methods for building world models have only recently become practical and have not yet been applied in this context. The proposed route navigation methodology is newly developed at Sussex and is based on insights of insect behaviour only recently observed. Increased knowledge of route navigation will be of interest to engineers and biologists. Parsimonious route-following algorithms will be of use in situations where an agent must reliably navigate between two locations| such as a robotic courier or search-and-rescue robot. Our algorithms also have potential broader applications such as improving guidance aids for the visually-impaired. Biologists and the wider academic community will be able to use the tools developed to gain an understanding of the visual input during behavioural experiments leading to a deeper understanding of target systems. There is specific current interest from Rothamsted Agricultural Institute who are interested in how changes in flight patterns affect visual input and navigational efficacy of honeybee foragers from colonies affected by factors like pesticides or at risk of colony collapse disorder.
The 'University of Local Knowledge' (ULK) is a community project that celebrates local skills and knowledge| helping community members to value and spread their knowledge which in turn will aid community stability. The project has the full support of the local community| and is led in part by a steering group of community representatives. Working with artist Suzanne Lacy| KWMC has begun to capture film clips| or 'classes'| in which residents share expertise and co-construct knowledge through events and performances.We will build on this foundation by developing technologies and techniques that help us scale up and study community skill and praxis. The University of Local Knowledge will bring together KWMC and the Knowle West community with a team of academics| artists and educators to study the deployment and use of technologies and techniques to collaboratively develop knowledge to enhance our understanding of the relationships between physical and digital community. We will help capture skills in a University-like structure in order to teach and publicise to others within and beyond the community; individual 'classes' will be assembled into programmes of 'study' that will be housed in 'departments' and 'faculties'. We will build systems through which further 'classes' can be added and pedagogic structures can be changed by contributors. We have chosen University as a deliberately contentious metaphor to provoke debate around what constitutes knowledge and why values are placed on different spheres of expertise. These 'classes' will be films/videos of Knowle West residents describing how to do something that they are an expert at; KWMC have captured an initial pool of examples which can be used to populate ULK. The resulting ULK structure will be visualised as a network of classes| departments and faculties. We will implement such structures within an online web service| and allow users both to comment and upload new classes| but also allow experienced members to adapt and 'mash up' the structure of ULK itself in order to better organise or present programmes of study. These web services will also be displayed in physical installations deployed within Bristol. In addition to configuring programmes of study we will convene a series of events including a conference with 'seminars' arranged in local sites| including shops| libraries and homes| with academics and local experts paired in conversation.
Coal will likely remain in an important position in the world energy mix in the foreseeable future because of its stability in supply and low cost in production. However| coal fired power generation industry has to substantially reduce its pollutant emission to survive in the future carbon constrained energy market. Oxycoal combustion with CO2 capture from flue gas is an emerging technology that can be adapted to both new and existing coal-fired power stations leading to a substantial reduction in carbon emission. Various assessments suggest that oxycoal technology is feasible and more favourable than other CCS (Carbon Capture and Storage) technologies| such as post-carbon capture. Currently| oxycoal combustion technology is still in its laboratory and technology demonstration stages and there is a significant knowledge gap in this new technology. A number of uncertainties exist in the combustion process where the changes in the heat transfer and combustion characteristics are| among others| the major concerns. Issues with system designs such as the optimum oxygen concentrations and its impact need to be investigated. Other complications include such as high concentrations of sulphur and mercury and changes in deposition and corrosion in the boiler and the downstream elements. If the technology is to be widely adopted in power generation industry for CCS then it is imperative that the impacts of these changes in the combustion processes are well understood| and that economic solutions to mitigating the problems encountered are identified.The proposed research aims to achieve an in-depth understanding of the oxycoal combustion processes| to develop key modelling capabilities for process prediction| and to provide guidelines to the power generation industry on design new and/or retrofitting existing power plant with oxycoal combustion technology. Because of the high costs of performing large scale tests| process modelling is commonly used as an alternative in technology development. In this project| advanced Computational Fluid Dynamics (CFD) techniques will be employed to perform detailed simulations on the oxycoal combustion processes. Because the oxycoal combustion is very different from the conventional air-coal combustion| new oxycoal specific CFD sub-programmes will be developed in order to achieve accurate modelling results. In parallel to the CFD modelling| well controlled practical measurements will be carried out to setup a comprehensive database on the oxycoal combustion and to provide validation to the CFD model development. In addition| a unique 3D flame monitoring system will be developed to monitor the oxycoal combustion flames. This integrated approach of advanced computational modelling| detailed experimental testing| and 3D flame imaging forms a mutual validating and complementary system to ensure a credible research output so that an in-depth understanding of the impact of oxycoal on flame characteristics| critical reaction kinetics| and devolatilsation and char reaction in the combustion processes may be achieved.The project consortium comprises of three academic centres of expertise from Leeds| Kent and the Imperial College. Three leading energy research institutes in China are joint force on the research. Collaborative research programmes have been arranged to carryout experimental testing and theoretical simulation in both UK and China. The project has also gained strong supported from leading power generation companies and commercial CFD developer providing practical advice on oxycoal combustion tests and combustion model development. The project provides a platform for the leading UK groups and leading Chinese partners to work together in tackling the significant issues related to the oxycoal combustion technology| which is expected to contribute significantly in cutting the CO2 and other greenhouse gases emissions in the power industry in both countries.
Although swallowing is a function performed effortlessly hundreds of times daily by healthy humans| it is an extremely complex process that involves the rapid and precise coordination of numerous muscles and tissues in the human body. In stroke (that affects thousands of people every year in the UK with an annual NHS cost of 2.3 billion) and many other pathologies of the nervous system| dysphagia (abnormal swallowing) frequently occurs and can lead to fatal pneumonia. Video-Fluoroscopy (VF) is the gold-standard for diagnosing dysphagia. For a VF swallowing study| the patient is seated comfortably and given barium enriched (to become opaque in the x-ray) liquid. The patient swallows while x-ray video images of the head and neck are being recorded. This video has to be manually examined by clinicians| but this task is visually demanding| extremely time consuming and error prone| since it requires the replay of the entire video frame-by-frame in slow motion and the very careful examination of the involved anatomical areas. This has direct consequences to the diagnostic accuracy.We propose to develop a system that processes the entire video sequence automatically and calculates measurements that are critical for robust diagnosis by the clinician. Specifically| instead of the clinicians examining the video data frame-by-frame in slow motion| the system will be able to do the job automatically and provide the clinicians with the required measurements. We propose to do this through the development of image processing algorithms that segment an image to its constituent regions. These regions will be the specified anatomical areas and the liquid during swallowing. By automatically tracking all these regions during time| the system will be able to calculate all measurements needed by the clinician to perform a diagnosis. After the algorithms are developed| we plan to apply the system to normal and affected subjects| and compare the automatically calculated measurements with ones estimated manually. The proposed work will have significant benefits on patients| NHS and the scientific community. It is novel as none of the previous works attempted the proposed automation| and is timely due to the current needs for improving the effectiveness of VF-based evaluation.
We will develop a data science of the natural environment| deploying modern machine learning and statistical techniques to enable better-informed decision-making as our climate changes. While an explosion in data science research has fuelled enormous advances in areas as diverse as eCommerce and marketing| smart cities| logistics and transport| health and wellbeing| these tools have yet to be fully deployed in one of the most pressing problems facing humanity| that of mitigating and adapting to climate change. This project brings together world-leading statisticians| computer scientists and environmental scientists alongside an extensive array of key public and private stakeholder organisations to effect a step change in data culture in the environmental sciences.

The project will develop a new approach to data science of the natural environment driven by three representative grand challenges of environmental science: predicting ice sheet melt| modelling and mitigating poor air quality| and managing land use for maximal societal benefit. In each motivational challenge| there is already an extensive scientific expertise| with intricate models of processes at multiple scales. However this sophisticated modelling of system components is usually let down by naive integration of these components together| and inadequate calibration to observed data. The consequence is poor predictions with a high level of uncertainty and hence poorly-informed policy making. As new forms of environmental data become available| and the pressures on our natural environment from climate change increase| this gap is becoming a pressing concern| and we bring an impressive team to bear on the problem.

A key theme of the project is integration| developing a suite of novel data science tools which work together in a modular fashion| and with existing scientifically-informed process models. By building a team that spans the inter-disciplinary divisions between data and environmental scientists we can ensure the necessary interoperability of methods that is currently lacking. Working with the full range of stakeholder environmental organisations will enable continual co-design of the programme and training of end-user scientists to ensure a reduction of the skills gap in this area. The resultant culture shift in the data literacy of the environmental sciences will enable better decision-making as climate change places ever greater strains on our society.
The UK Earthquake Engineering Field Investigation Team (EEFIT) has decided to mount a reconnaissance mission to the Abruzzo region of Italy following the earthquake of magnitude 6.2 MW| which occurred on the 6th April 2009. A team of nine people| (structural and geotechnical earthquake engineering| geology| seismology| casualty| and GIS experts)| are planning to leave for L'Aquila| Italy on the 17th April 2009 and spend six days in the disaster zone. This grant application seeks financial support to help meet the travel costs and field expenses of the participating academic team members and to aid EEFIT support entry of collected field data (photographs and observations) into an improved version of the Virtual Disaster Viewer system developed following the EPSRC funded China Earthquake mission last year (Grant Ref: EP/G030111/1). This platform will allow members of the global earthquake engineering community| especially to review and provide their assessment of damage by comparing before and after satellite images of the affected areas and to remotely and in real-time upload their own field data as it is collected for rapid dissemination. The objectives of the mission will be to investigate and assess the causes of structural damage| infrastructure damage and geotechnical failures in the epicentral region and report back to the UK Engineering and lay community. The investigation will also include aspects of casualty and social vulnerability assessment. Dissemination through the improved Virtual Disaster Viewer system will increase the effectiveness of earthquake reporting| promoting awareness of earthquake risk. It will also be a shared repository for observations made by several international teams of experts| in particular those of the Joint Research Centre in Italy. Hence| this initiative will continue to strengthen existing| and foster new relationships between researchers and engineers in EEFIT and the worldwide earthquake engineering community.
Positron Emission Tomography (PET) is a field of medical imaging that uses radioactive compounds to make images and obtain information about diseases| such as cancer| in the human body. PET is used to trace where special types of radioactively labelled compounds distribute| accumulate and breakdown in the body. This information is extremely useful when developing new drugs for disease treatment and diagnosis because it can allow the identification of possible drug candidates at an earlier stage of the drug development process. During a PET scan a radioactive compound is injected into a live subject (animal or human)| the radioactive compound rapidly decays and gives out radiation of a know energy which travels out through the body. This radiation| in the form of photons| is detected by the PET scanner and transformed into images that give us information about the distribution and concentration of the radiotracer in the subject's body. The synthesis of radiolabelled compounds for use in PET scans is particularly challenging due to the short half-lives of the common radionuclides used in PET| for example [11C]carbon has a half-life of only 20.4 min. Normally radiosyntheses for PET have to be carried out within three half-lives to provide enough radioactivity to do a scan| (within 60 mins for 11C). New methods and strategies for rapidly conducting radiochemical reactions and improving radiolabelling for new PET tracers are essential for future drug development and disease treatment. This research proposal aims to synthesise new tracers| for use in PET scans| rapidly and efficiently using a microfluidic reaction system and newly developed catalysts to enhance the rates and radiochemical yields of important reactions used in 11C labelling. Catalysts can have a remarkable influence over yields| rates and selectivities of chemical reactions. It is therefore vitally important to choose the most effective catalyst for a specific chemical reaction| this is even more apparent when the reactions under study have to be completed in extremely short reactions as in the synthesis of radiolabelled compounds. New and existing catalysts| based on a highly active palladium(I) complex| will be screened for the methylation reaction with particular emphasis on identifying catalysts that give high yields during the early stages of reactions. Once the best catalysts have been identified they will used in radiolabelling experiments using a microreactor system. Miniaturised reactor systems or microreactors are ideally suited for radiosyntheses due to the extremely small amounts reagents used in these reactions; typically sub-micromolar quantities of radioactive compounds are produced. In addition| the added benefits of enhanced heat and mass transport observed within such micro-systems may result in better yields in shorter reaction times. This system will be applied to the reaction of [11C]methyl iodide (a commonly used reagent in PET) with certain precursors that will be used to form a series of drug candidates which have the potential to bind to specific receptors in the central nervous system. The class of candidate molecules to be synthesised is particularly interesting since they have recently been developed as selective| high-affinity ligands for receptors that have been associated with a number of central nervous system disorders| including schizophrenia| anxiety| depression| Parkinson's disease| addiction and pain. Improved strategies to radiolabelling new candidate molecules that target these receptors and their study using PET scans will lead to a greater understanding of drug-receptor binding and may lead to the development of new drugs to treat central nervous system disorders.
The proposed research project aims to discover whether videos uploaded and exchanged by terrorists and sympathizers contain hidden data| and to recover any such data if this was the case for gathering intelligence on their plans and operations. 

For that| we will create a high performance and scalable video steganalysis tool called SEEK (Steganalytic vidEo rEsearch frameworK). 

The tool will be at the core of a system capable of locating| collecting| analyzing| and sanitizing videos shared on the Internet by terrorists or their affiliates.

While primarily aimed at helping counter terrorism and law enforcement| with a primary objective of significantly enhancing UK security| the outcomes of the SEEK proposal will also benefit a number of other disciplines and activities. 

We will contribute to the UK digital economy by improving the security of companies in general and video hosting or sharing sites in particular. 

For instance| some of SEEKs outputs will directly help companies eliminate any hidden data in any video| and detect and stop data loss when video steganography is used by cyber criminals to exfiltrate stolen data stealthily| which is becoming an increasingly common practice. 

SEEK also has some potential as a business venture expanding as steganalysis as a service (including analysis of other media)| which could create jobs and bring unique technological expertise in the UK.
One of the challenges in predicting the solidification of multicomponentmaterials such as metallic castings is to describe the evolution of mushy layers: partially solidifiedregions in which solid and liquid phases coexist. Such systems exhibitunusual properties not seen in single-phase systems. One example is thealteration of the crystalline structure by convection of heat and solute making theflow problem nonlinear and leading to the formation of solid-free dissolution channels|or 'chimneys'| in the solid matrix. A strikingly complex pattern ofchimney convection has been observed in recent laboratory experiments: a new'breathing mode' of convection has been found| in which chimneys allperiodically appeared and disappeared in phase. This project aims at anunderstanding of the observed behaviour using mathematical techniques. In particular| the nonlinear interactions between steady andstanding-wave oscillatory convection modes will be elucidated| and stableflow regimes and their parametric sensitivity quantified. Further laboratory experiments will also be conducted to provide more detailed information about this newly discovered phenomenon.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Libhpc aims build and demonstrate an environment for the component-based construction of HPC applications. This environment will enable method implementers to publish and share their contributions as multi-implementation adaptable components| shareable across domains and architectures| making them inherently more re-usable. End users will then be able to compose applications without reference to underlying machine or processor architectures. The aim of libhpc is to initiate a software development pattern for HPC that has knowledge capture and re-use at its core.Libhpc will be based on the combination of two long lines of research: that of Professor Sherwin in the development and application of spectral/hp element codes and that of Professor Darlington in the development of innovative application development methodologies. The project will take as its starting point the Nektar++ methods library and its application to the modelling of blood flow through an aortic arch. This application and the library will be re-factored to identify the necessary re-usable components and co-ordination forms required. These components will be designed and implemented| targeted at a variety of architectures| including| distributed memory clusters| shared memory clusters and GPU processors. A software methods repository with supporting meta-data will be constructed along with application-construction and mapping tools. This environment will then be used to re-express the aortic modelling application and map it systematically to a number of different architectures and machine configurations. These applications will be benchmarked to assess their performance and the improvement in human productivity and reusability gained.
The TERALINKS project is dedicated to the demonstration of a real-time THz communication system| with the 200-300 GHz bandwidth| in an operational environment.
The TERALINKS consortium aims to integrate three key enabling technologies and demonstrate the state of the art system with industrial relevance: THz sources (photonics- based for bandwidth and core network compatibility)| THz power generation using travelling wave tubes as one of the most promising high power sources at frequencies of interest| and advanced THz antennas. The TERALINKS consortium consists of key European institutes with notable but complementary expertise in every key building block of novel THz communication systems| and all consortium members have established considerable experiences in developing THz communication components and the system using technologies than span from photonics| to high frequency electronics. Our vision is to take fundamental research from individual university labs to a point where it is can revolutionise future mobile communications| with a manifold return for Europe| in innovation and exploitation. The project duration is proposed for 24 months.
Spin electronic devices hold out tremendous potential for high-density non-volatile memories| reconfigurable electronic devices and possibly solid-state quantum computing elements. Such devices will almost certainly require new materials to overcome some of the major problems currently arresting progress such as low spin injection efficiency. Carbon nanotubes have been shown to offer some possible benefits| but devices are difficult to fabricate. Carbon nanotubes can be thought of as layers of a hypothetical material graphene rolled into hollow cylinders. We have discovered a way of making planar graphene films| which are just a few atomic layers thick but remain metallic| continuous and of remarkably high quality. This new material offers the same possible advantages as carbon nanotubes for spintronic applications such a coherent spin transport and lack of a Schottky barrier at the ferromagnetic-metal/graphene interface. This programme builds on the current graphene work at Manchester to explore the potential of this material in making novel devices to investigate and optimise spin injection effects and hence allow the production of novel elements for potential applications. The programme will also elucidate the suggested proximity effects at graphite-ferromagnetic interfaces. It has been suggested that at such interfaces a ferromagnetic-like state is induced in the graphite layers at the interface. We can look at this effect on one to three layer graphene stacks by looking for increased spin scattering in the graphene for polarised carriers passing along the interface region. We also intend to look at the potential for using spin current torque effects to reverse the magnetisation direction in a nanomagnet| which is an ideal way of switching devices for non-volatile memory applications.
Active Vibration Suppression is the area of research at the intersection of two mostly independent disciplines| Structural Mechanics and Active Control. The dynamic behaviour of large flexible systems such as bridges| buildings and aerospace structures generally involves many natural frequencies and modes; in theory an infinite number in continuous structures. In two important respects the available structural-dynamics (finite element) models are unsuitable for use with conventional active control (state-space) methods; they are too large and do not represent damping accurately enough. This problem is addressed by a new approach to active vibration suppression using measured receptances. The method| which may be cast an inverse problem| offers a completely fresh theoretical viewpoint| with attendant new understanding. The theory has its origins in structural dynamics| whereas generally in active vibration suppression| theory developed by the active control community is applied to structural vibration problems. The method developed is generic| having wide applications and not limited to particular types of structures. It addresses a problem that is presently very difficult to tackle with existing methods. It is not limited by physical size or complexity| and does not rely on (possibly inaccurate) mathematical models. The research will include not only the theoretical development of a completely new approach but also the demonstatation of practical usefulness of the theory in laboratory tests| rotor simulations and helicopter ground vibration tests. The research will be carried out in close collaboration with engineering scientists from Westland Helicopters Ltd.
If a load is applied to a solid material| the material deforms first elastically (it reverts to its original shape if the load is removed). Above a critical load| the material changes its shape permanently| i.e.| it undergoes plastic deformation. Consider| for example| a cylinder made of some material which we compress by pushing from top to bottom. If we apply a load such that the stress (the force per unit area) is everywhere the same in the cylinder| it will deform homogenously by getting shorter and thicker| and remain so after we have removed the load. If the cylinder is large| we will observe that the deformation increases gradually as we increase the stress| and the stress needed to obtain a given relative deformation will not depend on the size of the cylinder (the force does| but the stress does not!). But when the deforming body becomes very small| what we observe might be quite different. Reserachers in the US have a few years ago started do do such experiments on very small cylinders| say| 1/100 of a millimetre in diameter| which they machined out of single cystal blocks of some metals. What they observed was: (1) Even if the stress is increased slowly and steadily| the deformation does not increase gradually but in large jumps. These jumps occur randomly| and take place at different stresses in different specimens - even if those specimens are machined out of the same block. (2) The stress required to deform different specimens to a given strain scatters hugely| and in general increases as the specimens become smaller. (3) Even though the stress is everywhere the same| the specimens deform in a very inhomogenous manner. As a consequewnce| the cylinders assume a kind of accordeon-like shape.The first two of these aspects have been studied in some detail| but not much is as yet known about the spatial distribution of deformation in such small specimens. Therefore| we have teamed up with the US researchers who pioneered the microdeformation method. We want to investigate the spatial distribution of deformation in micron-scale specimens. We plan to fabricate micro-specimens of some metal and| for comparison| a nonmetallic crystal (a salt)| to deform them to different degrees| and then to investigate the distribution of deformation by imaging the specimen with great resolution. To this end we will use an atomic force microscope and an optical device called a scanning white-light interferometer. By analysing the images we will see how in detail the deformation has occurred| and possibly gain hints as to what causes the deformation bursts and the general unpredicatbility of deformation in such small specimens.Why is it important? Imagine you want to bend a sheet of metal| say for making it into a cylinder for producing a can. If you apply an equal force| you will get a nice cylindrical shape. However| if you try to do the same on a very small scale| the result might look quite different! So| randomness and localization of deformation may affect our ability to form materials into very small shapes and to produce very small parts for microtechnologies. As such technologies will become more and more important in the next decades| we should gain the knowledge and expertise needed to handle forming processes on the microscale. Our research wants to make a contribution to obtain some of the basic information needed for this purpose.
Nonlinear partial differential equations (PDE) are of universal applicability in the modelling of real-life situations from the flow of air around a wing to the behaviour of financial markets. They are also a natural language for describing the laws of mathematical physics and differential geometry. Their study poses profound intellectual challenges to pure mathematicians as well as important computational problems where accurate numerical data is required in specific applications. Despite its international importance and intense research activity on several fronts| including important breakthroughs in recent years| the UK appears to lag behind its competitors in this area.The present proposal is to establish the Centre for Analysis and Nonlinear Partial Differential Equations| run jointly by the University of Edinburgh and Heriot--Watt University at Edinburgh. This centre will improve the UK's current position through a number of specific actions:--- appointment of outstanding researchers in areas under-represented in the UK--- a programme of instructional workshops open to researchers in the UK and beyond--- two major research workshops on current trends and developments in nonlinear PDE--- a substantial visitor programme to bring the world's best researchers to the UK to give high-profile lectures and establish new research contacts--- development of new research links with industry and other interested parties--- development of new undergraduate and graduate courses in analysis aimed at meeting the needs of the next generation of researchersThe proposal comes from the Maxwell Institute of Mathematics| which is a new joint venture combining the strength of mathematical sciences at the University of Edinburgh and Heriot-Watt University. Funded by the Scottish Funding Council and the Office of Science and Technology| the Maxwell Institute aims to be a pre-eminent centre for research and post-graduate training in the mathematical sciences| offering an environment able to attract and foster the very best mathematical talent from around the world. The Maxwell Institute is one of five joint research initiatives| the others covering a wide range of topics in engineering and geoscience. The present bid will take advantage of the Maxwell Institute's position alongside the other joint research initiatives to develop new collaborations and applications of nonlinear PDE in these areas.The other distinctive feature of this proposal is the presence of the International Centre for Mathematical Sciences (ICMS) which is a joint initiative of the mathematicians at Edinburgh and Heriot-Watt which was set up in 1990. Since then ICMS has developed a reputation for the running of high-level international instructional and research workshops| and the infrastructure it provides will be crucial in organizing the proposed workshops. At the same time| these workshops provide a broadening of ICMS's current activities and will add to its international reputation.The new research grouping will be managed by a Scientific Steering Committee composed of two mathematicians from each of University of Edinburgh and Heriot-Watt University| and also including at least one representative from industry and at least one person from overseas. The committee will be regularly consulted| especially on the workshop and visitor programmes.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Solvents are ubiquitous in chemistry| used to bring species together for reactions| for separations and for processing but most chemical synthesis makes use of volatile organic compounds (VOCs). VOCs are toxic| volatile| flammable and are largely passive spectators to the reactions carried out within them yet are central to all industrial production of chemical species from therapeutics to catalyst particles. Recently| however| a family of novel solvents| deep eutectic solvents (DES) have been demonstrated| by one of our team| to allow water-sensitive synthetic reactions to be safely done on the benchtop and also to play an active role in directing reactions and structuring nanomaterials. This recently developed class of solvents therefore have enormous potential to replace VOCs with safer| greener liquids which| in addition| have intriguing properties| currently not understood| that allow them to defy existing synthetic practice. Yet DES bring their own challenges to transitioning them into manufacturing practice| requiring development of a new manufacturing platform to enable their rapid deployment in industrial processes| as well as requiring an improved understanding of how these solvents facilitate syntheses.

DES are room temperature liquids consisting of mixtures of a salt and hydrogen-bonding neutral molecules. Cheap| non-toxic| biodegradable| sourced from biomass| they are highly tuneable for specific applications. Yet| surprisingly little is understood about how DES structures and interactions facilitate and direct syntheses. This project aims to link a greater understanding of solvent structuring in DES and solute interactions in DES| with state-of-the-art organometallic synthesis and functional meta-materials preparation| and crucially focuses on implementation of manufacturing solutions to allow these fundamental investigations a route into real industrial practices. Use of molecular assemblies in DES and novel continuous manufacturing technologies will open the way to design of cheaper| safer| more environmentally friendly reaction processes| leading to new functional materials and greener routes to pharmaceuticals| agrochemicals and other fine chemicals.
The interaction between nano-objects of different dimensionality| e.g. electrostatic Coulomb-coupling of a zero-dimensional quantum dot (QD) to a two-dimensional (2D) system is of fundamental interest and of great relevance for charge-based memories. This interaction between a single QD and a 2D system shall be studied here. Innovative use of the complementary expertise of the partners will combine| for the first time| Sb-based QDs with a split-gate structure| which will allow the precise control of the charge-state of a single QD. Sb-based QDs have strong hole confinement yielding a potential retention time of many years at room temperature| enabling the analysis of the influence of charged QDs on a 2D system up to 300 K. In the mid-long term perspective| the results could be important for future generations of memories: knowledge of the interaction of a 2D system with a single QD might allow us to reach the ultimate limits of charged-based memories (e.g. Flash).
The project will bring together two streams of scheduling research which involve patterns of different types: resource patterns and job patterns. Resource patterns are typical for personnel scheduling problems and for project management; job patterns are usually studied within machine scheduling. In spite of the differences in the nature of two types of patterns and the differences in application areas for two types of problems| there are a number of complementary features in the underlying models which have not been explored in the past. Within this project| we intend to complete the in-depth analysis of the two models| perform the knowledge exchange between the two areas and develop a new methodological framework for solving problems with patterns. The study of the separate problems with resource patterns and those with job patterns will be concluded with the study of the combined problem with both types of patterns| which models new features of real-world applications not studied before.
We seek to create conformal sensors unlike existing electronics that exploit the ultra-thin form factor achieved by additive manufacture to offer flexible labels with sensing| wireless communication and energy harvesting to charge entirely integrated batteries. To achieve this| we must re-engineer antennas and batteries (the largest devices in wireless systems and which suffer poor efficiency from close integration). Our battery-assisted labels will be printed using sustainable inks with reclaimable materials for the circular economy. They will communicate at distances greater than passive alternatives and enable 'on object' or 'on-skin' monitoring| e.g. of atmospheric vapours or medical testing. Successful outcomes will provide unprecedented data from attach-and-forget smart labels that can be customised by overprinting with different sensing films. To achieve this our team of leading Wireless| Battery Formulation| and Digital Manufacturing researchers| will combine with the UK National Catapult for Printed Electrics. 

Previous battery-free (passive) UHF RFID based tag sensors proposed for smart connected ecosystems are inherently limited in their functionality (e.g. no data logging or analog to digital interface) and the communication range is a few metres or less. This limitation arises through the need to harvest sufficient power. A battery would overcome the range and functionality limitations| but at the cost of overall bulk due to battery volume| including holder size | and the physical separation needed between the conducting battery casing and the antenna in order to maintain radiation efficiency. Also| there are serious implications for the end of life of millions of pervasive sensing labels containing the materials commonly used in battery formulation. With these constraints and the expectation of interconnecting separate components| it will never be possible to produce truly thin label-like power-assisted electronics. 

The labels we propose will be inherently low energy in operation| but integrated battery assistance will make possible many potential applications including bio-sensing| pharma smart monitoring &amp; patient compliance| security| industrial and domestic chemical| temperature| &amp; power monitoring| and enable encryption in emerging big data nodes for Smart Connected Systems. To ensure deliverable outputs in this work| we will focus on creating proof of concept vapour sensing tags to address two identified needs. 

1. We will develop labels to sense air pollution which is well known to reduce quality of life and attacks infrastructure through acid rain. 
2. We will create atmospheric sensing labels for industrial processes and product testing as identified by our partner Givaudan. 

The team of RFID engineers| functional materials scientists| inkjet experts and the national Catapult for printed electronics will engineer efficient antennas on battery substrates| demonstrate ultrathin battery chemistries| suitable for additive manufacture that offer performance similar to commercial coin cells| create inks to print thin film Nitrogen Oxide sensors| create prototype sensing wireless labels by inkjet printing| and produce test runs of the devices using commercial roll-to-roll techniques. Our designs will be integrated into a demonstrator system that can read the tags and display results in an accessible way.
Each year| over 5400 UK patients are referred to lower limb prosthesis clinics (2011)| of whom over 90% are below- or above-knee amputees. The main causes of amputation are diabetes| limb dysvascularity (loss of blood supply)| accidents and injury in the battlefield. 

Prosthetic legs have the potential to dramatically improve the mobility| confidence and the quality of life of users. With an effective prosthetic solution| users can be independent in their daily living| e.g. walking| stair climbing and potentially running. In addition| advanced prosthetic legs enable amputees to improve their posture which in turn has a positive effect on reducing wear-and tear on their unaffected joints. However| individuals with lower-limb amputation lack the nervous structures associated with the foot and ankle from the prosthesis and| compared with able-bodied individuals| suffer from lack of stability. Technologies do not exist for targeted delivery of feedback information from the prosthesis to the nervous system. 

As part of the EPSRC-funded SenseBack project| a highly-experienced team of UK researchers are developing a number of key technologies to restore sensation to the individuals using prosthetic hands. The proposed translational Alliance between Newcastle University and &Ouml;ssur (www.ossur.com) will facilitate translation of the the technologies developed in the SenseBack project to lower-limb prostheses. With &Ouml;ssur| within the next decade| we aim to create an artificial leg that can generate mechanical power| adapt autonomously to the user's changing needs and also provide feedback to the user regarding the state of the limb and the prosthesis.
Nature has evolved large and complex molecules - proteins - which are comprised of simple building blocks that fold into specific three-dimensional shapes. These folded molecules are important for mediating many physiological chemical reactions. We are interested in examining the weak interactions that hold these molecules in their precise three-dimensional shape| and attempting to replicate them in simple synthetic systems. This involves the design and synthesis of molecules designed to fold into specific shapes| and simulation of their properties using high-level quantum calculation. The insight provided by these calculations will allow us to understand the forces that shape the properties of these small| designed molecules| and will also permit us to potentially emulate the exquisite specificity and reactivity exhibited by natural systems. We hope that this understanding will allow us to develop small| functional molecules that emulate some of the desirable properties of proteins.
Semiconductor-based photon-counting detectors have risen to prominence in the last decade as new application areas have emerged| such as quantum information processing| and in particular quantum cryptography. These photon-counting detectors - mainly fabricated from silicon - have also taken over from photomultipliers in a number of laboratory applications where their room temperature operation| fast timing| small footprint and low power consumption have proved advantageous in a host of applications| for example fluorescence lifetime imaging. New photon-counting applications areas in ground-based| airborne and even satellite-borne laser-induced reflection techniques have been developed in recent years (eg for detection of trace gas concentrations)| as well as significant developments in low-power optical imaging and high-resolution depth imaging. In the near-infrared spectral region - where silicon-based detectors are highly inefficient - there remain substantial issues with available single-photon avalanche diode (SPAD) detectors. Their performance deteriorates due to the high noise levels associated with thermal excitation of carriers across the relatively narrow bandgaps| as well as the effects of mid-gap trapping centres causing the deleterious effects of afterpulsing| further contributing to detector noise levels. This project aims to establish a new class of germanium/silicon SPADs that will operate efficiently in the near-infrared| particularly at the strategically important telecommunications wavebands| and combine the advantages of low-noise Si single-photon avalanche multiplication with the infra-red sensing capability of Ge. This new class of detectors will take advantage of recent advances in epitaxial Ge/Si growth and be fabricated in conjunction with the recently-created UK Silicon Photonics consortium (UKSP)| which offers world-class device growth and fabrication facilities. The detectors will be validated on existing state-of-the-art testbeds for quantum key distribution and time-of-flight ranging/depth imaging. The project leverages the combined expertise and facilities of existing UK Silicon Photonics consortium to do additional and new work| thus adding value to that consortium.
The proposal is a first attempt to secure high-resolution maps showing the intensity and spectral quality of artificial lighting for multiple urban areas anywhere in the world. We argue that they are an essential first step for understanding and addressing the engineering| social and biological impacts of artificial lighting and their related policy dimensions| which has hitherto been undermined by a lack of quality data at an appropriate spatial scale. Artificial lighting (AL) and urbanisation are linked| so much so that remotely sensed measures of AL are used as proxies for urban area| population| electric power consumption| density of built infrastructure and economic activity. Increases in AL have not only led to a wide range of benefits for society| but also an equally wide range of costs (e.g. changes in energy consumption and supply| infrastructure| human health| quality of life and ecological function and ecosystem services). The central platform for this research is quantification of the spatial variability in lighting at a city scale| both in terms of its intensity (illuminance and radiance) and spectral quality. This is needed because although accurate and comprehensive ground-based measures of artificial lighting and its impacts (e.g. safety) are available| they are not scalable. Conversely| larger scale satellite-based measures are typically of coarser resolution (1km)| have poor sensitivity to low radiances| and lack multiple spectral bands. The demand for datasets at a spatial extent| resolution and quality relevant for managing urban landscapes has therefore not yet been met. Our research team's recent focus on urban futures (SUE 2 grant) identified AL as a local condition critical to the success of many of today's sustainability investments. We identified that changes in spectral range and intensity of lighting will either support or undermine initiatives aiming to improve road safety| energy efficiency and urban biodiversity. Further investigation revealed the lack of datasets to support a more quantitative sensitivity analysis and associated future proofing. We created a pilot project with Birmingham City Council| who were in the process of commissioning unrelated aerial surveys and were keen to support our research. The stunning results led to the first ever high-resolution quantification of the luminance and spectral quality of lighting within a City. It is likely data of this type have not been produced before due to technical| financial and logistical barriers| which we have demonstrated no longer exist. The aim of this project is to collect| process and analyse data from remotely sensed digital images to provide the first set of geo-referenced| radiance-calibrated| high-resolution city lightscape maps| for multiple cities in the UK. Data calibration| processing and analysis will follow an initial phase of collection. Throughout these phases the team will work across disciplines and sectors| with an international partner| lighting industry representatives and data collectors to ensure the outputs are targeted to end users. The deliverables from this project are (i) the first fully quantitative high resolution mapping of artificial lighting at a city scale for multiple urban centres in the UK| (ii) the first model of the relationship between urban structure and artificial lighting| and (iii) the first multi-city comparison of artificially lit landscapes. These have broad utility and are expected to generate considerable public interest. The AL issue is significant| as it impacts a very wide range of issues associated with the built environment that have become core topics of debate within academic and practitioner communities as well as within wider society. The deliverables from this project will provide an essential and timely dataset from which to better consider lighting issues at appropriates scales| depending upon the subject of interest (energy| health| ecology| etc.).
Biotechnology has made significant advancements in the understanding of human genomics and proteomics revolutionising medical diagnosis| prevention and treatment. Advances and breakthroughs in target-oriented biotechnology research have been used to enhance the synthesis of a number of commercially significant products. It has been reported that there are over 6000 biopharmaceuticals currently in development| potentially worth in excess of $100's bn (&pound;145bn in 2012). Despite the increasing successes in discovering protein-based medicines| their manufacture in a cost effective and reliable fashion remains a major industrial challenge| which currently limits the ability of the biopharmaceutical industry to deliver solutions to patients. The vision here is to develop a programme for process intensification and de-bottleneck of downstream bioprocessing (DSB)| by implementation of Seeding and Continuous Biopharmaceutical Crystallisation (SCoBiC)| for the separation and purification of biopharmaceuticals. The ambition of this proposed project to develop strategies for a continuous biocrystallisation process| including selective crystallisation directly from multicomponent fermentation broths by seeding| for whole antibodies and antibody fragments. The goal is to reduce manufacturing costs| provide for simpler processes while achieving the high purity of material achievable from multi step chromatography. This ambition is driven by the awareness that separation and purification processes represent one of the most time and cost-intense downstream operations in the manufacture of commercial biopharmaceutical products. This proposal will develop a continuous biocrystallisation platform as an alternative to conventional DSB| offering improvements to manufacturability| enabling higher throughput| lowering the product costs| an increase in product quality and stability| including opportunities for novel formulations and technologies.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Silicon chips have revolutionised the way we live our lives. Silicon is used in almost all electronic circuitry. However| there is one area of electronics that| at the moment| silicon cannnot be used to fill; that is in the emission of light. Silicon cannot normally emit light| but nearly all telecommunications and internet data transfer is currently done using light transmitted down fibre optics. So in everyones home signals are encoded by silicon and transmitted down wires to a station where other (expensive) components combine these signals and send light down fibres. If cheap silicon light emitters were available| the fibre optics could be brought into everyones homes and the data rate into and out of our homes would increase enormously. The applicants intend to collaborate with international research groups who are trying to make silicon emit light using tiny clumps of silicon called nanocrystals . These nanocrystals can emit light in the visible and can be made to emit in the infrared by adding erbium atoms to them. A number of techniques available in Manchester| Guildford and Japan will be applied to silicon chips made in Canada to understand the light emission and to try to make silicon chips that emit light. In addition we will work with the UK company Qinetiq to investigate other uses of the nanocrystals in sending coded messages down fibers.
We will build a group in Mathematical Statistics based upon established excellence and expertise in the Statistical Laboratory and elsewhere in the University. Theoretical statistics takes its life blood from areas of potential application| and thus the current project will be developed in collaboration with distinguished groups elsewhere in Cambridge and the UK. The principal target of the Statistics group will be to develop core mathematical and methodological statistics of generic importance for applications. The major partner is the Engineering Department| where applications are confronted through the development of generic theory. Through strong links to application areas| the research of the group will bring greater value to UK industryFour new Lectureships will be established| funded initially from the EPSRC Award but thereafter as a full charge on University funds. A further University-funded Chair in Statistics will be created in the Statistical Laboratory. The five appointees will join existing tenured staff in the Statistical Laboratory and Engineering with associated interests to form a new group. There will be about 21 person-years of postdoctoral Research Assistantship| and 9 PhD studentships. The individuals appointed to these posts will support the research programmes of members of the group| will collaborate with cognate groups in Cambridge| and will be trained as independent researchers suitable for employment in the UK higher-education sector. The Research Assistants will pursue innovative research| while developing their levels of administrative and teaching skills through contact with undergraduate and graduate students.
Most of Aston's research in EPS subject areas is undertaken in the School of Engineering and Applied Science (EAS) with areas of excellence in the other Schools (notably Aston Business School and the School of Life and Health Sciences).

EAS has recently moved its research to an Institute structure| building on the world-leading success of EBRI (the European Bioenergy Research Institute) and AIPT (Aston Institute of Photonic Technologies). SARI (the Systems Analytics Research Institute - incorporating the Non-linearity and Complexity Group) was formally launched at the start of 2015| while two further Institutes| the Aston Institute for Materials Research (AIMR) and the Aston Logistics and Systems Institute (ALSI) were founded in 2016| complemented by the Aston STEM Education Centre (ASEC). These Institutes embody our research priority areas where DTP-funded studentships will be made available| alongside Servitisation Research in the Aston Business School (ABS) and the Physical Science/Life Science nexus in The School of Life and Health Sciences (LHS).

Every student will be a member of a Research Institute to support both their generic and technical training needs and to allow the students to function effectively as a cohort. The Institutes ensure there are critical masses of researchers leading to a vibrant research culture. Students will be encouraged to join the Institute that is the most appropriate for them. Those students who are on projects allocated to ABS and LHS will be expected to make use of the equivalent provision within those Schools and to join the most appropriate Institute within the School of Engineering and Applied Science.

Over the first year of their studies| the entire cohort of PGR students will study in an Integrated Graduate Research Environment. Training needs analysis will be carried out by supervisors. Compulsory modules will include generic research skills and time management| collaborative research| academic writing/presentation skills| entrepreneurship| and outreach. Optional modules will develop the students' technical skills relevant to their research project.

We normally expect PhD students to have weekly meetings with their supervisors and monitor progress through the documentation of these meetings. Three times per year there are formal progress review meetings that must be documented.

At the end of their first year| students prepare a qualifying report on their research and their research plan| and are examined in a formal viva. At the end of the second year| students should either prepare a progress report or give a presentation: in addition| there is an expectation that students will have at least one publication submitted to a peer-reviewed conference or journal. At the start of their third year of study| students are expected to provide a thesis outline and write-up plan.

For the coming DTP period our strategy is to strengthen the research student community through investment in around 14 studentships per year on top of those provided by the DTP. The focus will be on using the majority of the studentships to help develop the careers of a cohort of new academics who have recently joined Aston. 

More information on the postgraduate experience at Aston can be found on our Graduate School's web page: http://www.aston.ac.uk/current-students/graduateschool/

Specific opportunities for PhD research can be found on the relevant School research web pages:

http://www.aston.ac.uk/eas/research/prospective-research-students/ http://www.aston.ac.uk/aston-business-school/programmes/research/ http://www.aston.ac.uk/lhs/research/postgraduate-research/
Markets for radio frequency (RF) devices are various and cover ranges of low voltages (1.5| 3V etc.) for mobile applications. Conventionally| the devices required to build the front-end amplifiers are built within the same process as the digital CMOS circuitry which dominates the overall system realisation. The state-of the-art (SOA) CMOS processes are relatively expensive especially for lower volume production which is attractive to smaller companies and start-ups. Our proposal is to provide a high performance vertical MOSFET within a standard digital CMOS process such that the minimum feature size can be rather larger than SOA allowing a lower cost solution. The higher performance for the vMOST comes from the ease of producing a very short channel vertically using standard ion-implantation| rather than laterally which requires expensive patterning techniques (lithography). We have already shown the feasibility of a number of novel solutions to address some of the inherent propblems of vMOSTs. We believe that a high performance 0.1um vertical transistor with high gain and high operating voltage will be able to provide significant advantages for the market. Like all developments| it depends on the performance that can be achieved economically| and this is a key aim of this project. A sub- 0.1um transistor should exhibit an fT of around 100GHz and so provide useful power to over 10GHz. This would allow the replacement of GaAs and LDMOS devices in power stages of cellular and wireless LAN applications up to 5GHz. New connectivity and satellite uplink applications operate in frequencies up to 12GHz| and so the feasibility of the vertical MOSFET for this regime is a further objective.
The science and engineering of materials have been fundamental to the success of nuclear power to date. They are also the key to the successful deployment and operation of a new generation of nuclear reactor systems. The next-generation nuclear reactors (Gen IV) operating at temperatures of 550C and above have been previously studied to some extent and in many cases experimental or prototype nuclear systems have been operated. For example| the UK was the world-leading nation to operate the Dounreay experimental sodium-cooled fast nuclear reactor (SFR) for ~19 years and a prototype fast reactor for ~20 years. However| even for those SFRs with in total of 400 reactor-years international operating experience| their commercial deployment is still held up. A formidable challenge for the design| licensing and construction of next-generation Gen IV SFRs or the other high-temperature nuclear reactors is the requirement to have a design life of 60 years or more.

The key degradation mechanisms for the high-temperature nuclear reactors is the creep-fatigue of steel components. When structural materials are used at high temperature| thermal ageing and inelastic deformation lead to changes in their microstructures. The creep and creep-fatigue performance of structural materials are limited by the degradation of microstructures. The underlying need is to develop improved understanding and predictive models of the evolution of the key microstructural features which control long-term creep performance and creep-fatigue interaction. This Fellowship will use an integrated experimental and modelling approach covering different length and time scales to understand and predict the long-term microstructural degradation and creep-fatigue deformation and damage process. I will then use the new scientific information to make significant technological breakthroughs in predicting long-term creep-fatigue life that include microstructural degradation process. I will thereby realise a radical step beyond the current phenomenological or a functional form of constitutive models which received very limited success when extrapolated to long-term operational conditions. This research will put me and the UK at the forefront of nuclear fission research.

This Fellowship will enable the 60 years creep-fatigue life of the next-generation high-temperature nuclear systems by developing a materials science underpinned and engineering based design methodology and implement it into future versions of high-temperature nuclear reactor design codes. In consequence| Gen IV reactor technologies will become commercially viable and Gen IV SFRs will be built globally to provide an excellent solution for recycling today's nuclear waste. This fellowship aims to influence the international organisations responsible for the next-generation nuclear design codes and gaining an early foothold in the international nuclear R&amp;D via this research will give the best chance to secure Intellectual Property and return long term economic gains to our UK.
This project aims at providing a stepping stone in quantum information processing by the realization of Feynman's vision of quantum simulation of a quantum system using a well controlled and model quantum system evolving according to a tailored Hamiltonian. Using cold atom systems in optical lattices| which already have proven their power in showing typical condensed matter quantum effects like the Mott insulator| this stepwise approach is much more conservative than typical efforts in quantum computation. In particular it is likely to quite naturally deliver one of the main currently foreseen applications of a quantum computer: a general quantum simulator. In this respect this project promises to drive our fundamental understanding of the involved issues of entanglement generation or quantum state analysis and consequently to provide a solid basis for further steps in this area.The key new feature of this project is the attempt to achieve for the first time full control over a many-body quantum system by implementing single site resolution for quantum state manipulation as well as quantum state analysis. Disorder phenomena shall serve as the test case for completely controlled lattice Hamiltonians and will allow tackling non-trivial and technologically relevant problems in quantum transport such as metal to insulator transitions or magneto-fingerprints .The project is well aligned with the mission of the Midlands Ultracold Atom Research Centre| an EPSRC Science and Innovation initiative established to foster the link between cold atom and condensed matter physics. It will thus create great mutual benefits with the existing theory groups and foster UK cold atom networking with groups at other universities. This is underlined by winning Massimo Inguscio| one of Europe's leading scientists in cold atom research| to come to the UK as a visiting researcher.Discussions with QinetiQ| as part of a Quantum Technology Partnership (QTP) involving Birmingham| Warwick| Oxford and Lancaster| have identified a number of potential spin-off applications related to cold atom research and we are actively pursuing ways of developing these for future commercialization and mutual benefit. These include sensors based on cold-atom lattice systems and related technology| particularly integrated optics and lasers for future portable cold-atom systems.
This project seeks to advance the current understanding of carbonation in lime and cement materials. A novel approach is proposed where the reaction with carbon dioxide will be studied using micro pH electrodes. pH variations in a thin water film at the sample surface will allow the reaction mechanism to be determined. A detailed understanding of the surface morphology and composition will be provided by a comprehensive electron optical and surface analytical study. The reaction of these materials with carbon dioxide is or great interest as sequestration of carbon dioxide is a key initiative aimed at reducing climate change. Lime has the ability to adsorb significantly higher quantities of carbon dioxide during the setting process in comparison to alternative products such as cement and has important applications in the restoration and conservation of historic buildings in addition to renovation and new build projects. Cement acquires its strength from hydration of reactive silicate and aluminate clinker phases however in the long term carbonation of these phases can lead to a reduction in mechanical performance and the corrosion of steel reinforcements if present.Although the chemical process of carbonation is well known the mechanisms in lime and cement mortars are poorly understood. This research programme seeks to address this issue.In recent years the producers of low carbon footprint materials such as hemp and wastes from a range of industrial processes have expressed interest in the incorporation of their materials as fillers and additives in lime and cement products including mortars| renders| plasters and concrete. The addition of these environmentally friendly materials not only influence the micro and macro pore structure but soluble constituents may introduce ionic species into the pore water| the influence of which on carbonation is unknown. This proposal aims to study the carbonation process by monitoring ion concentrations at different locations within the liquid film on the surface of a calcium hydroxide substrate. Proton concentrations will be measured using specially manufactured microelectrodes consisting of nanostructured palladium hydride discs approximately 10 micrometers in diameter and electrodeposited on the end of a normal microdisc electrode. Held precisely with a micropositioner the pH microelectrode will be brought to within a few micrometres from the surface under investigation. In a similar way| commercially available ion selective electrodes will be used to determine the calcium ion concentration. In the second phase of the project the effect of ions leached from additives commonly used in conjunction with lime will be investigated. These can be divided into the following five groups| blast furnace slag (GGBS)| bottle glass| wood ash| hemp and metakaolin.Additives of interest will include glass| ashes / slag and organic surfactants.
Lighting and displays form essential parts of our daily lives and consume approximately 20% of the electricity used worldwide. Consequently| significant energy and cost savings can be achieved by improving the efficiency of these devices. Due to their lightweight| flexibility and high-performance optical and electrical properties| Organic Light-Emitting Diodes (OLEDs) are a central focus of this research and have huge potential for application in technologies such as smart phones| televisions and lighting. OLEDs are| like classic LEDs| able to transform electrical energy into visible| ultra-violet (UV) or near Infra-red (NIR) light. However| unlike LEDs| OLEDs consist of several very thin| stacked layers organic materials and do not rely on small| point-shaped single crystals. In addition| organic systems are highly attractive for mass production stemming from their ability to be deposited on a variety of low-cost substrates such as glass| plastic or metal foils| and due to their relative ease of processing. Indeed| because production costs of these devices are typically dominated by fabrication and packaging| the relatively weak van der Waals bonded organic films also create the opportunity for a new suite of innovative fabrication methods| including direct printing through the use of contact with stamps| or alternatively via ink-jets and other solution-based methods.
 
Even though OLEDs have huge potential to achieve a higher energy efficiency than LEDs and may also be processed under more sustainable conditions| today's state of the art white OLEDs still have higher power consumption than white LEDs. In terms of efficiency| initial attempts to implement OLEDs based upon purely organic materials were restricted by the type of excited state which emits the light. Indeed| upon electrical excitation 25% of the emitting molecules are in a so called singlet excited state| while 75% are in triplet excited states. However| conventional organic materials cannot emit from the triplet excited states| meaning that only a maximum efficiency of 25% could be achieved. An extensive research effort successfully led to 2nd generation (so called phosphorescence) OLEDs that use heavy metals to promote light emission from the triplet states and| in principal| achieve 100% efficiency. However| until now the only phosphorescent materials found practically useful are iridium and platinum complexes that are unappealing for commercial applications due to their high cost and low abundance.

This research proposal seeks to investigate| using multi-scale modelling| the fundamental properties crucial to molecules and materials for a new class of OLEDs that exploits thermally activated delayed fluorescence. This exploits a small energy gap between the two emitting states (singlet and triplet) so that thermal energy can transfer population from the triplet state to the singlet state. Importantly this mechanism opens the possibility to achieve| in principal| 100% efficiency and crucially precipitates the potential to return to materials containing only lighter more abundant elements| such as organic molecules. By combing quantum chemistry| molecular and quantum dynamics| this multidisciplinary approach will produce a detailed physical and chemical understanding of the material properties on a wide variety of time and length scales. Critically| these simulations will underpin our understanding of the properties that lead to their efficiency. This bottom up approach will consequently provide important insight into achieving systematic material design with the potential for vastly improved and cheaper devices.
This proposal seeks funding for a Visiting Fellowship to investigate novel nano-composite TiN/Ag surface coatings with potential applications in areas as diverse as cutting tools and biomaterials.Titanium nitride (TiN) is a workhorse hard| wear resistant coating material| which is widely applied to cutting and forming tools and other components operating in an abrasive wear environment. TiN is not| though| known as a low friction material and does not generally offer protection to the mating face during use. Indeed| unlubricated tribological tests on films produced by these techniques tend to result in coefficients of friction in the range 0.3-0.9| depending on test geometry| mating face material| etc. However| our studies have shown that the introduction of pulsed processing at the target and more recently at the substrate can lead to a remarkable enhancement of the tribological characteristics of TiN coatings with| for example| coefficients of friction of less than 0.1 being recorded in unlubricated wear tests.It is anticipated that the inclusion of silver in these coatings can further enhance their characteristics. When deposited together by co-sputtering from two targets| the coating forms a structure that consists of a matrix of TiN surrounding nano-particles of silver. In wear situations| the silver particles can act as a solid lubricant| thus lowering the coefficient of friction and reducing damage to the mating face. The 'self-lubricating' nature of these coatings| combined with their high hardness and scratch resistance makes them attractive for tribological applications. Moreover| titanium compounds are also biocompatible. Combining these properties with the inherent anti-microbial nature of silver opens up a number of novel applications for TiN/Ag nano-composite films in| for example| the bio-medical or food processing industries.Whilst Ag-containing nano-composite coatings have been the subject of a number of studies| there is very little published work on the TiN/Ag system| with only limited consideration of the properties of these films. The Visiting Fellow will| therefore| study the production of nano-composite TiN/Ag coatings| characterise their surface properties| and investigate novel applications of these coatings. Collaborators at the Jost Institute of Tribotechnology at UCLan will assist the Visiting Fellow in the assessment of the tribological properties of the coatings. And from a microbiological perspective| in-post staff at MMU will assist by assessing the coatings in terms of their effect on microbial retention and viability on surfaces using a range of microorganisms of importance in medical device infection| and contamination of food processing surfaces.
Silks toughness and mechanical tunability does not depend solely on controlled processing but also on the self-organisation of the elastomeric precursor proteins of the silk. It appears that water hydration plays a major role for self-organisation and stability of silk proteins. Recent findings from our lab suggest that the elastomeric nature of silk protein in solution can be derived from a measure of their structural disorder and their relative content of glycine residues. In order to elucidate the mechanisms by which structural disorder and hydration are linked to promote elastomericity in silks we propose to visualise the processes as they occur using small angle scattering (Neutron and X-ray)| polarised spectroscopy (FTIR/CD) and thermal analysis (DMA). This will allow us to examine experimentally and analyse in vitro (i) how silk proteins fold and assemble in solution; and| (ii) how hydration affects silk fibres mechanical performances. This project will provide the fundamentals to understand and quantify the dynamics of interactions between large structural proteins and their environment with application to artificial spinning of biopolymer fibres| and chemical control of biological aggregates| such as amyloids.
The main concern of the nanovisions project will be the production of exciting| novel| images| stills and animations that will be employed in a variety of forums| exhibition| lectures and websites. At the Department of Electronics and Electrical Engineering there are a three major research groups| nano| bio and opto electronics; their activities involve nano and micro technology. including modeling| design| fabrication and characterisation of devices. These activities are all a rich source of images and concepts that can be rendered into visually exciting displays.Murray Robertson of Visual Element will use the visual material supplied by the department of electronics and electrical engineering and will produce images| stills and animations based on this material. Murray Roberstson brings to this a proven track record in creating visually exciting material illustrating scientific topics. The initially the target| after 6 months of effort on producing the material| will be to have an exhibition at the Glasgow Science centre and an associated series of lectures. The material will then be made available through a web site| and the exhibition will be transferred to the James Watt Nanofabrication centre where it will be given a more permanent home. There will also be a significant evaluation activity. The project will be monitored by taking note of visitor numbers| hits on the web site and copyright requests on the images. First reaction evaluation will come through assessing visitors questionnaires and initial press reaction. Longer term evaluation will come through assessing the impact on the national debate on nanoscience and technology.
none
The offshore wind industry has experienced significant growth in recent years| and continues to expand both in the UK and worldwide. Most of the offshore wind turbines installed to date are located in relatively shallow water and are mounted on fixed bottom support structures. Given the limitation of suitable shallow water sites available with high wind resources and also to reduce the environmental and visual impact of turbines| it is necessary to extend wind turbines to deeper water through the development of floating offshore wind turbine (FOWT) systems| which mount wind turbines on floating support platforms. 

The project aims to fill an important gap in the design| manufacturing and testing of emerging FOWT techniques by specifically characterising extreme loading on FOWTs under complex and harsh marine environments. These are typically represented by storm conditions consisting of strong wind| extreme waves| significant current| rising sea level and complex interplay between these elements| through a coordinated campaign of both advanced CFD modelling and physical wave tank tests. This has direct relevance to the current and planned activities in the UK to develop this new technology in offshore wind. 

In addition| the project aims to develop a suite of hierarchical numerical models that can be applied routinely for both fast and detailed analysis of the specific flow problem of environmental (wind| wave| current) loading and dynamic responses of FOWTs under realistic storm conditions. As an integral part of the project| a new experimental programme will be devised and conducted in the COAST laboratory at the University of Plymouth| providing improved understanding of the underlying physics and for validating the numerical models. Towards the end of the project| fully documented CFD software and experimental data sets will be released to relevant industrial users and into the Public Domain| so that they may be used to aid the design of future support structures of FOWTs and to secure their survivability with an extended envelope of safe operation for maximum power output.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Pioneering research into the development of hybrid halide perovskite solar cells as a viable alternative to existing technology has established a unique opportunity for the UK to maintain a highly competitive position in the development of photovoltaics. We are at the forefront of modelling work to understand the fundamental properties of these systems. The principle goal of the project is to establish a fundamental understanding of organic-inorganic perovskite technologies| identifying new target materials to accelerate technological development| whilst developing computational tools applicable across the entire field of solid-state materials research. Our team draws together a comprehensive range of expertise in photovoltaics| materials design and theoretical solid-state physics. The consortium involves two well-equipped universities and offers a powerful combination of expertise and infrastructure for materials modelling| bridging levels of simulation from fundamental theory to high-throughput screening| in the manner required for breakthrough discoveries in the field of hybrid photovoltaics. 

The facilities and expertise available for the research programme will be enhanced by links to experimental groups provided by the EPSRC SUPERSOLAR Hub (EP/J017361/1). Critical mass and training targets will be achieved by linking the main research theme through our graduate programmes and Centres for Doctoral Training.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Additive manufacturing (AM) has gained significant interests from industries of different sectors. Among different AM processes| Wire + Arc Additive Manufacturing (WAAM)| which used metal wire as feedstock and electric arc as a heat source| has been shown to be suitable for producing large scale components with comparatively low equipment cost and running cost. The WAAM process has been developed in Cranfield University for many years| many large components of different materials| including titanium alloys| aluminium alloys| nickel alloys as well as steels have been successfully built for industrial partners. 
The end-user industries| such as Airbus| FMC technologies and Glemalmond Group see significant benefits presented by the WAAM process to be able to manufacture structural components in a short lead time with low cost. Kuka Systems sees the great opportunity to get the forefront of this technology and to get the business benefit from commercialisation of the first WAAM machine. The main target of this project is to develop a commercial robotic WAAM machine (ROBOWAAM) that can be used by industrial partners for building meter scale components. Cranfield University will integrate its extensive WAAM process knowledge into a feature- based path planning software to support the end-users to manufacture components for their applications. In additional an online feedback control system will be developed and integrated into ROBOWAAM machine to correct build height errors. 
To assure the deposition quality of the part| in-process nondestructive testing (NDT) method needs to be applied. Usually NDT is applied after the components has been finished. It is a time consuming and costly process if a defect is found which would either require a repair procedure or may lead to scrapping of the part. Thus an in-process NDT method is required to for inspecting each layer of the deposition. If a defect is found then the current layer will need to be machined before the recommence of the deposition. Cranfield University will collaborate with the University of Strathclyde and Advanced Forming Research Centre (AFRC) on a feasibility study of the in-process NDT method on the WAAM parts with existing NDT technologies. The in-process NDT will be incorporated with the WAAM process into a parallel processing system and the capability of this system will be demonstrated in this project.
In addition| an extended study will be performed on the automation requirements of the whole WAAM chain. This will include the pre-WAAM processes such as substrate cleaning| post-WAAM process such as heat treatment and final machining| parallel processes such as in-process NDT and top surface machining| as well as material manipulation between processes.
This proposal led by the University of Oxford| with support from the Alan Turing Institute (ATI)| Bristol| Edinburgh| KCL| QMUL| Sheffield| Southampton and UCL is for a national GPU system that will support multidisciplinary science with a focus on machine learning and molecular dynamics. The architecture is based on ``fat'' GPU compute nodes| with 8 of NVIDIA's new Pascal GPUs| each with 
a) 16GB 720GB/s HBM2 memory| 
b) an 80GB/s NVlink interconnect to other GPUs| 
c) 6GB/s bandwidth to main system memory| 
d) 6GB/s bandwidth to the Infiniband external network.
Each server also has two 20-core Xeons| 512 GB DDR4 memory and 8TB SSD. 

The motivation for selecting this architecture is the huge growth in research in machine learning and associated areas of data science within the UK| particularly within the universities which are members of the Alan Turing Institute| or SES. The same architecture is also ideally suited for molecular dynamics| medical imaging and a number of other application areas.


The system will be run as a national facility| similar to Archer in being free to all academic users with computing time available to all through a lightweight Resource Allocation Panel| with a top-level steering committee determining the policy on resource allocation between the different application areas (Machine Learning| Molecular Dynamics| Other).
An interconnection network is a mechanism by which different components of a (usually large) computer system communicate. The design of interconnection networks is not straightforward as there are many issues to take into account| such as: the topology (that is| the basic pattern of connectivity of the components); the routing algorithms (that are used in order to transfer messages around the network); the methods of flow-control (that are used in order to deal with congestion when different network packets| for example| request limited hardward resources); and the methods of switching (the way in which once a route for a message has been selected| the message is physically transferred from component to component throughout the network). The whole area is an incredible mix of hardware| software and mathematics| and employs principles from both computer science and engineering.

The field of interconnection networks covers a wide variety of different communications subsystems| from relatively small| very local on-chip networks| through supercomputers and clusters| and on to vast| remote and evolving networks such as those implemented in grid and cloud computing (upon which so much of the ubiquitous computing in modern society depends). Although many interconnection network principles apply universally| the varying domain characteristics and intended applications lead to a number of differences. The full extent of these differences is impossible to cover here but one is the scale of the interconnection network. On-chip networks are relatively small - currently tens of nodes (though there are efforts to scale up to a thousand nodes)| whilst the number of nodes used in data centre networks or supercomputers can be hundreds of thousands. The research in this proposal aims to improve the design of interconnection networks for large-scale systems such as those employed in supercomputers| clusters and data centres by developing closer links between the mathematics behind interconnection networks and the practical construction of interconnection networks.

The practical construction of| for example| a supercomputer that might fill a large room is immensely complex| with a multitude of wires| cables| boards| chips| racks and cabinets all conjoined so that all of the computational power of such a system can be employed to yield efficient solutions to problems on massive data sets. Of course| such a supercomputer has to be programmed so that each of its computational elements knows exactly what to do and when to do it and so that the individual computational results can be rapidly compiled into a solution of the underlying problem. The design of such a hardware and software system is an incredible feat of engineering. Mathematicians abstract the essential interconnection network within such a supercomputer as a graph; that is| as a set of vertices| pairs of which are joined by edges. Whilst this may seem an imprecise abstraction| one can use graph-theoretic properties in order to design interconnection network topologies which possess many properties one would wish of an interconnection network. Graph properties relating to| for example| symmetry| shortest-paths| connectivity| Hamiltonicity| recursive decomposability and embeddings prove to be extremely important in securing good practical properties for interconnection networks. However| up until now there has been a considerable gap between the mathematical theory on the one hand and practical interconnection network performance on the other. Our research proposal aims to narrow this gap by providing a closer link between the theory and practice of interconnection networks| with the ultimate goal being techniques by which we can theoretically design an interconnection network and be sure of its resulting practical properties when built and used.
Energy is one of the major issues at the top of the national policy agenda. Energy Efficiency is key to meeting the national targets set by the UK government and by international treaty to reduce CO2 emissions. Electrical Motors and Drives are the driving force in industry and economy. The two areas are amongst the small number of &quot;grow&quot; areas identified by EPSRC's shaping capability agenda. Similarly| Power Electronics is widely recognised as one of the UK's key and high-growth technologies owing to its pivotal role in delivering low-carbon technologies. For the last several decades| the UK has been leading the way internationally in developing high performance power conversion devices but further improvement in performance calls for accurate validation tools. At Newcastle as well as in the UK| we presently rely on input-output methods to test PM machine drives and power electronics| which proved to lack precision for highly efficient ones. This limitation hampers our research activities because many cutting-edge technologies of importance to the UK| leading to impact in the aerospace| automotive and domestic applications| require high-efficiency motors and drives. To date we cannot accurately validate our numerical models in which the prediction and achievement of very low losses can make the difference between success and failure of a concept. Typically| uncertainties tend to be greater than 2% of system efficiency which may be more than the total predicted loss in the system. As a result| there is a pressing need for a highly accurate facility to measure power losses in electric machines and power converters to an accuracy of 1-2W| which does not currently exist anywhere in the world.
This proposal addresses national and institutional strategic needs by proposing an innovative calorimeter and by examining machines' and converters' power loss models using it. To deliver this we will bring together our leading experts in calorimetry| PM machines and power electronics. Once completed the project will provide the UK (based in Newcastle) with a high-precision and versatile capability for the experimental evaluation of the power losses and efficiency of PM machines and power converters| and then improvements on these devices will follow accordingly. This proposed work will have a long-lasting impact over the next 10-50 years. It will push the boundary forward in accurate power measurement| enabling future development of key emerging industry involving high-efficiency electrical machines and PE devices that would not otherwise happen. The technologies developed from this work will be potentially applied to many applications and will contribute to the UK's competitiveness in high-performance electrical drives such as aircrafts| electric vehicles| renewables and domestic products.
Biotechnology companies use single cells (bacteria| yeast| or mammalian) as 'cell factories' to produce molecules of use in many different sectors| such as pharmaceuticals| enzymes| biofuels| cosmetics or fragrances. In some cases this means that compounds that were previously produced from non-renewable sources (petroleum) can be produced from renewable sources. In other cases cell factories produce useful compounds that would be impossible| too difficult| or too expensive to produce in other ways (e.g. using chemistry). To date| innovation for biotechnological processes has focused on maximising output| but now the challenge is to use cell factories more efficiently by reducing the required input of energy and nutrients. Moreover| as we learn more about how to design and control living cells| we can begin to envision new exciting potential uses for these 'living machines'| especially in the healthcare sector.

In order to do this| we need to be able to engineer living cells that behave controllably in the face of changing conditions. This is what this project aims to achieve. In electronic| mechanical and chemical engineering| robust control is typically accomplished through the use of 'Integral Feedback Control'| which is an effective strategy to guarantee robustness to step-like perturbations and uncertainties. This requires an integrator. In a nutshell| the integrator accumulates information about the system's past behaviour and uses it to adjust and improve its activity as more information becomes available. Integral Feedback Control allows| for example| cruise control systems to maintain a car at constant speed irrespective of the slope of the road or the combined weight of the passengers; or the speed of an escalator to remain constant regardless of the number of people using it. In this project| we will design| model| construct and test a biological integrator to implement 'in-vivo robust control'.

A fully (re-)programmable and controllable cell is one of the core long-term objectives of the blossoming field of synthetic biology. However| no biological integrator currently exists. To fill this gap| we will engineer the first in vivo 'plug-and-play' bio-integrator device that can be customised for different applications. To demonstrate the functionality of our bio-integrator device| we will use it to create engineered cells that can robustly maintain the concentration of a chosen small molecule around a specified value. To accomplish this| the cell will be equipped with both the ability to sense the extracellular concentration of the molecule and to synthesise and secrete the molecule itself. A rigorous control design will allow for the secretion rate to change dynamically so as to counteract step-like perturbations in the extracellular concentration of the molecule. This will establish the necessary theoretical and experimental basis for future extension of this research into in vivo environments.

For example| a biological integrator device would make it possible to engineer microbes that reside symbiotically with or within other organisms| and that are able to sense and self-adjust to changing and uncertain external conditions. We anticipate that this in turn could lead to the emergence of a revolutionary new form of medicine that we are calling 'active in vivo medicine'| i.e. cells that are implanted in patients and monitor the concentration of disease-related biomolecules (e.g. insulin)| modulating their production of these molecules in response to patient need.

In order to investigate how active in vivo medicine might be implemented in real-world conditions| we have integrated into this project a programme of work on 'Responsible Research and Innovation' designed to incorporate the perspectives of a wide range of interested parties into any future development of active in vivo medicine| including: biomedical researchers| clinicians| patient groups| regulators| pharmaceutical firms| and bioethicists.
This UK-China (QUB-DICP) joint project will aim to provide low cost high performance Portable Power Fuel Cell technology capable of operating on alcohol containing fuels with an emphasis on use of biofuels such as bio-ethanol and glycerol| from bio-feedstocks. The collaborative research seeks to seize the initiative in low temperature fuel cell research and development by capitalising upon extremely promising results on Direct Alcohol Alkaline Anion Exchange Membrane Fuel Cell (DA-AAEM-FC) development by both China and UK teams| and exciting data in the literature on anode and cathode catalysts for alcohol-fuelled alkaline fuel cells. The electro-catalytic oxidation of alcohols under alkaline conditions is relatively unexplored| but with some extremely promising reports in the literature on low cost but highly active and selective non-Pt catalysts. Our main strategy is to extend the range of potential fuels| ultimately to side products| waste and (cheap) products from sustainable bio-refining. The broadening of fuel cell fuels from hydrogen and methanol| fuels generally produced from fossil fuels| to bio-feedstocks| e.g. bioethanol| will greatly decrease reliance on fossil fuels for portable power generation. In addition| the use of direct biofeedstock fuel cells as power sources for portable devices as compared to Li-ion rechargeable| will reduced reliance of fossil fuels on electricity generation. In addition| the diversification of feedstock will allow higher energy density fuels to be employed| for example ethanol provides 24 MJ l-1 compared with methanol at 16 MJ l-1. In addition| the safety aspects can be tailored for the application| for example methanol is toxic and this prevents wider deployment of portable fuel cell systems into areas and environments where this is a concern| e.g. in aircraft cabins. The time scale of benefit will be dependent on the continuing introduction of portable power devices based on fuel cells. Flexibility in the form of the fuel used and its purity without having a detrimental effect on the fuel cell lifetime will provide a significant opportunity and impact in future years. The development of an efficient| durable alkaline fuel cell| utilising cheaper catalysts and accessing a wider range of fuels will have a major impact on a number of aspects of power/energy technology. The UK and China teams have strong and complementary skills relevant to the proposed work. Both teams have demonstrated individual achievements and are trying to develop the strength-plus-strength cooperation on electro-catalysis and fuel cell R&amp;D| through this novel and challenging joint project| with a continue two-way transfer of knowledge throughout the project. The joint project will timely provide an excellent platform for the UK and China teams to establish a long-term win-win partnership for working together on the clean sustainable energy technology which will bring great benefits to both countries.
Mathematics is at the heart of most scientific and technological advances. Although it is still a subject that fills most with dread and fear| there is a surprising appetite out there to gain access to this mystical world. The recent publication of the Smith report has documented the current crisis in mathematical education and the implications this could have for the UK economy. The extension of my media fellowship will aim to exploit the mediums of TV| radio and print to breakdown some of the prejudiced views people have of mathematics. On a broader platform| my experience in issues connected with the Royal Society's Science and Society programme will form another strand to my media activity. There is still a desperate need to open a dialogue between the science community and the society that can benefit or be harmed by scientific advances. The media fellowship will provide the space for a member of that scientific community to engage in dialogue.
Knowledge of the spatial and temporal characteristics of the next and subsequent waves to act on marine energy converters is essential for optimal control and ultimately| survivability. Currently| it is possible neither to measure nor reliably infer these. The University of Edinburgh has deployed| for the first time| a flexible| optoelectronic senor ribbon (using ShapeTapeTM technology) in its wave flumes. Previous ShapeTape (tm) applications had been limited to human body shape measurement for athlete training and sports research. The University of Edinburgh research has shown the sensor to be capable of resolving| in the 2-d flume| wave elevation data| giving measurements of individual (and spectral) wave heights| periods| shapes and steepnesses with high correlation with the best available wet techniques.Ultimately| a lattice of these sensor ribbons could allow real-time surface mapping of the advancing waves in fully mixed seas and unlock new opportunities for anticipatory adaptive control of converter response. This is not a near-market technology. This proposal seeks to determine the feasibility of achieving these ultimate benefits via this technology. As such| it will extend the measuring equipment| techniques| data capture and processing to add the third dimension| and to the real sea setting. New signal capture and analysis techniques will be explored in the wave basin and open sea. Key challenges that lie ahead on a route to full scale deployment in anger will be identified| and whether these are tractable or show-stoppers be assessed.
This is an extension of the original Fellowship &quot;Spectroscopy-driven design of an efficient photocatalyst for CO2 reduction&quot;

There is sufficient solar energy incident on the UK to provide for all of our energy needs. However the insolation level varies hugely both within a day and on a seasonal level. For any energy technology to be viable it is essential that it is reliable. A route to overcoming the intermittency of supply issue is to use the solar energy to drive the production of a chemical fuel which can be stored and transported to be available when and where it is needed. Sustainable carbon-based solar fuels and feedstocks (e.g. CH4| CH3OH| CO) can be produced by the coupling of light driven water oxidation to the reduction of CO2. This is an exciting prospect but to realise the goal of low carbon-intensity fuel economy breakthroughs are required for both fuel generation and utilisation systems. Current materials for CO2 reduction and water oxidation do not achieve the required level of efficiency and stability at a viable cost. Similarly the most promising clean technologies for electricity generation on demand from carbon fuels| fuel cells| often suffer from relatively low efficiencies and intolerances to impurities in the fuel feed.

The original fellowship has been highly successful in delivering new low-cost catalysts that can either be driven directly by sunlight (photocatalysts) or indirectly using electrical energy (which could in principle come from a PV panel) to reduce CO2 to CO| an important liquid fuel precursor. Part of the original fellowship developed new capabilities within the UK for a highly sensitive surface sensitive spectroscopy| IR-Vis Sum Frequency Generation Spectroscopy. This experiment has been used to identify with an incredible level of detail the mechanisms of catalysts at surfaces. These| and our wider spectroscopic studies| have been critical in guiding our own catalyst design programme. But the need for mechanistic insights extends beyond our own synthetic programme. A lack of understanding of the mechanisms of catalysis occurring on the surface of electrodes and photoelectrodes is a limiting factor for the entire field preventing the rational development of new materials. Therefore our spectroscopy driven programme will be expanded to address both the crucial reactions of fuel generation (water oxidation and CO2 reduction) as well as to fuel utilisation chemistry| through the study of state of the art metal-oxide fuel cells. 

The project is ambitious| aiming not just to provide the first identification of all key intermediates during water oxidation on the most commonly studied photoelectrode (hematite)| but also to explore how secondary interactions with water and electrolyte salts control the activity. A similar level of mechanistic detail is also sought from leading CO2 reduction catalysts and fuel cell electrodes. This level of mechanistic detail that we aim to deliver could be transformative to our own| collaborators and the wider communities programmes of material development. The delivery of scalable| efficient materials for solar fuels production and utilisation is a challenging goal but the potential impact is enormous. An improved understanding of surface mechanisms on current materials would represent an important step towards this ambition.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
The proposed project is in the area of sustainable chemical technology and is ultimately aimed at developing a novel generic approach towards clean organic synthesis. The methodology| exploiting reactivity of singlet oxygen in diastereo- and enantioselective reactions| will be developed. The proposed methodology is| uniquely| based on the synergy between recently discovered highly effective generation of 1O2| mediated by silicon nanocrystals assemblies| and the novel reaction engineering concept of multifunctional structured reactors with imbedded light-emitting diodes. The proposal identifies the significant potential of adopting new concepts of process intensification (via non-thermal activation and miniaturisation| i.e. enhanced mass and heat transfer) and functional nanomaterials in clean organic catalysis. Most significantly| the proposal addresses the underdevelopments in the areas of clean organic synthesis and non-thermal activation of molecules.
Disordered networks are at the heart of a multitude of materials with functional properties where examples range from the glasses used in optical communications technology to the role of water in geological processes. Establishing the network structure| and its relation to a system's physico-chemical and opto-electronic properties| is a prerequisite for making new materials through the principle of rational design. Here we tackle this issue by using an integrated approach to investigate the fundamentals of basic networks| using pressure to manipulate the bonding and network topology. Oxide and chalcogenide glasses along with water will be investigated| the systems chosen to be exemplars of network forming materials with different bonding mechanisms. The contrasting bonding schemes confer the networks with different characteristics and have the potential for making modified materials with tailored functional and structural properties. Applications include the recovery to ambient conditions of materials with novel characteristics| sequestration of the green house gas CO2 by geological fluids| and the effect of rare-earth clustering on the photonic properties of glass.

The inherent disorder of liquid and glassy network structures is a blessing| in delivering materials of unique scientific and technological importance| but is also a curse| in providing complexity on the atomic scale. The method of neutron diffraction with isotope substitution (NDIS) has played a pivotal role in unravelling the mysteries of disordered materials since it allows access to the so-called partial structure factors i.e. to the maximum information that can be extracted from a diffraction experiment. Over the last 3 years| Bath has led an initiative to develop the techniques for measuring accurate neutron diffraction patterns for glasses and liquids at high pressures using the Paris-Edinburgh press. Thus| the time is now ideal to exploit the NDIS method to make in situ high pressure and temperature investigations of structurally disordered materials.

We intend to investigate the mechanisms of structural collapse in three classes of system with different bonding schemes and concomitant network properties| namely oxide glasses (GeO2)| chalcogenide glasses (e.g. GeSe2| As2Se3| AsSe) and water. These particular systems are chosen because they are archetypical materials for the study of disordered networks e.g. they either show or are anticipated to show polyamorphic phase transformations in which there is an abrupt change in their structure and physical properties with change of pressure and/or temperature. In the case of the chalcogenide glasses| the large structural variability leads to the possibility of recovering new materials with novel functional properties to ambient conditions.

The structure of two types of adapted networks will also be considered| namely salty water and rare-earth alumino silicate glasses. In the former| the experiments will be made under the high pressure and temperature conditions relevant for geological fluids where applications include the sequestration of CO2. In the latter| the phenomenon of rare-earth clustering will be investigated with a view to controlling the separation of nearest-neighbour ions and hence the optical properties of these materials.

Complementary information will be provided| where applicable| by NMR (Warwick)| high energy x-ray diffraction| EXAFS spectroscopy and other experimental techniques. The NMR work will include well established nuclei (27Al and 29Si for the alumino silicates) but will extend the boundaries of the method by using 17O| 73Ge and 77Se. A combination of isotopic enrichment and NMR enhancement schemes will maximise the amount of structural information that can be extracted by using these nuclei as probes. Importantly| the experimental work will be enriched and complemented by molecular dynamics simulations made in collaboration with groups in Oxford| Cambridge and Strasbourg.
The aim of this project is to explore the use of laser-generated ultrasound in thermosonic (TS) bonding. TS bonding is a joining technique which uses a combination of heat| pressure and ultrasonic energy to facilitate the formation of strong metal-metal bonds. It is used mainly for attaching bond wires to silicon chips inside their packages| where it offers a number of advantages over other joining methods. For example| it involves no additional materials (e.g. solders or adhesives)| and it can be carried out at lower temperature and pressure than thermo-compression bonding and lower ultrasonic power than pure ultrasonic welding. 
 
An important potential application for TS bonding is flip chip assembly| a technique used in advanced electronics manufacturing. Flip chip allows unpackaged integrated circuits to be attached to a circuit board or other substrate in a face-down configuration| with electrical connections between the contact pads on the chip and the substrate being provided by conducting &quot;bumps&quot;. Flip chip assembly offers several advantages over other chip attachment methods| such as higher electrical performance| higher interconnect density (more electrical connections per unit area)| smaller footprint and lower height.

Flip chip processes based on solder attachment have been established for many years. However| with the continual drive for miniaturization they are approaching their limits in terms of interconnect density. Alternative approaches based on adhesive bonding are scalable to finer interconnect pitches| but do not achieve the performance or reliability required for many applications. TS bonding could form the basis of a highly reliable| ultra-fine-pitch flip chip technology. However| up to now it has proved challenging to develop robust processes| mainly because it is highly sensitive to co-planarity errors and bump height variations which can lead to bond strength non-uniformity and even damage to the chip. These issues become more severe as the chip size increases| and consequently TS flip chip has been limited to a narrow range of applications involving small devices with low interconnect count.

We propose to develop a TS bonding process in which pulsed laser light is used to generate ultrasound locally at specific bonding sites| using confined ablation of a sacrificial carrier tape sandwiched between the workpiece and a transparent bond head. This approach will enable us to deliver the ultrasonic energy in a flexible manner| allowing for the possibility of compensating for co-planarity and bump height errors. With the proposed system it will also be possible to pre-heat the interface locally by laser| yielding a process with very low overall thermal loading.
 
If successful| the proposed research will ultimately lead to a next generation flip chip technology with wide ranging applications in electronics manufacturing. The new process should also find applications in other fields such as MEMS (microelectromechanical systems) and optoelectronics where joining of delicate components is required.
The FROTH project is a close collaboration between five universities with significant experience in research into wave interactions with fixed and floating structures working together to combine and apply their expertise to different aspects of the problem. The aim is to investigate the detailed physics of violent hydrodynamic impact loading on rigid and elastic structures through a carefully integrated programme of numerical modelling and physical experiments at large scale. Open source numerical code will be developed to simulate laboratory experiments to be carried out in the new national wave and current facility at the UoP [http://www.plymouth.ac.uk/pages/view.asp?page=34369]. 
It is well known that climate change will lead to sea level rise and increased storm activity (either more severe individual storms or more storms overall| or both) in the offshore marine environment around the UK and north-western Europe. This has critical implications for the safety of personnel on existing offshore structures and for the safe operation of existing and new classes of LNG carrier vessels whose structures are subject to large instantaneous loadings due to violent sloshing of transported liquids in severe seas. Some existing oil and gas offshore structures in UK waters are already up to 40 years old and these aging structures need to be re-assessed to ensure that they can withstand increased loading due to climate change| and to confirm that their life can be extended into the next 25 years. The cost of upgrading these existing structures and of ensuring the survivability and safe operation of new structures and vessels will depend critically on the reliability of hydrodynamic impact load predictions. These loadings cause severe damage to sea walls| tanks providing containment to sloshing liquids (such as in LNG carriers) and damage to FPSOs and other offshore marine floating structures such as wave energy converters.
Whilst the hydrodynamics in the bulk of a fluid is relatively well understood| the violent motion and break-up of the water surface remains a major challenge to simulate with sufficient accuracy for engineering design. Although free surface elevations and average loadings are often predicted relatively well by analysis techniques| observed instantaneous peak pressures are not reliably predicted in such extreme conditions and are often not repeatable even in carefully controlled laboratory experiments. There remain a number of deeply fundamental open questions as to the detailed physics of hydrodynamic impact loading| even for fixed structures and the extremely high-pressure impulse that may occur. In particular| uncertainty exists in the understanding of the influence of: the presence of air in the water (both entrapped pockets and entrained bubbles) as the acoustic properties of the water change leading to variability of wave impact pressures measured in experiments; flexibility of the structure leading to hydroelastic response; steepness and three dimensionality of the incident wave.
This proposal seeks to directly attack this fundamentally difficult and safety-critical problem with a tightly integrated set of laboratory experiments and state of the art numerical simulations with the ultimate aim of providing improved guidance to the designers of offshore| marine and coastal structures| both fixed and floating.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
The proposal anticipates a new era of fabrication driven by Synthetic Biology and our ability to manipulate living organisms to make new materials and structures. We are also going beyond the usual application domains of Synthetic Biology by applying it to Civil Engineering| expanding design methods and opening up a new area of Engineering Design.

To achieve this we will develop a living material which can respond to physical forces in its environment through the synthesis of strengthening materials. This concept is partly biomimetic inspired by for example the way in which our bones strengthen| becoming more dense under repeated load. However| we are also proposing to buid this system using living bacteria cells which have no such functional requirement in nature.

Imagine a hydrogel (jelly) containing billions of engineered bacteria. A weight is placed on top of the jelly and| as it is loaded the bacteria in the material sense the mechanical changes in their environment and begin to induce mineral crystals to form. As they make this material the jelly stiffens and strengthens to resist the load. By the end of this project we will be able to demonstrate this principle creating an entirely novel living material. We are working with project partners from across industry and academia to develop this proof of concept and to investigate the broad applications of such a technology to| for example| create self constructing building foundations and make large scale structures where it is very difficult to build using traditional buildings and materials.
We spend some 90% of our time inside buildings where we control the quality of the environment for health| thermal comfort| security and productivity. The quality of the indoor environment is affected by many factors| including design of buildings| ventilation| thermal insulation and energy provision and use. Maintaining the quality of the environment in buildings can have considerable consequences on both local and global environment and on human health. In recent years| the air-tightness of buildings has become an issue| as part of a drive to provide thermal comfort and reduce energy consumption. However| as dwellings are made more airtight| internal pollution sources can have a greater impact on the indoor air quality and occupants may experience adverse health effects unless ventilation is effective. On the other hand| ventilation can lead to ingress of outdoor air pollution; it also reduces energy efficiency of buildings| accounting for 25-30% of the total building energy use. Conversely| efforts aimed at the improvement of energy efficiency through better thermal insulation may affect adversely indoor air quality| e.g. through reduced ventilation and increased moisture content. The latter is the main cause of mould| the exposure to which is being increasingly linked to respiratory and other health problems. Further| burning fuels in micro-generation domestic appliances such as gas boilers and cookers can potentially be hazardous to the health of those in the dwelling or further afield. However| switching to other sources of energy such as biomass| photovoltaics| fuel cells etc.| while reducing the impact on the indoor environment can| on a life cycle basis| cause environmental and health impacts elsewhere. Nevertheless| several Government reports have highlighted the importance of household micro-generation options as well as energy efficiency| given the imperatives for reducing greenhouse gas emissions and widespread fuel poverty. The latter has been linked to Britain's large burden of cold-/winter-related deaths| which often exceed 30|000 per year. Poor indoor environmental quality in residential buildings| offices and schools has been related to increases in sick building syndrome symptoms| respiratory illnesses| sick leave and losses in productivity. Health effects can be immediate (e.g. irritation of the eyes| nose| and throat| headaches| dizziness and fatigue) or can occur over a longer period of exposure to indoor pollutants (e.g. respiratory diseases| heart disease and cancer). A growing body of scientific evidence indicates that the air within homes and other buildings can be more seriously polluted than the outdoor air in even the largest and most industrialised cities. Given that most people spend approximately 90% of their time indoors| their exposure to air pollutants is determined primarily by exposure indoors| particularly in their home. In order to contribute towards achieving a better quality of the indoor environment| this project proposes to study the environmental and health effects related to the generation| conservation and use of energy in buildings| with a particular focus on residential buildings. The main outputs from the project will be an integrated decision-support methodology and software tool for more sustainable management of indoor pollution. The framework will be applied to a number of case studies that will compare environmental| health and economic implications of the principal options for future home energy provision as an aid to policy development. Using a life cycle approach| the project will examine a range of sustainability issues| including environmental impacts (e.g. resource depletion| global warming| acidification| eco-toxicity etc.) and social issues (e.g. human health| comfort and well-being). The economic implications of different options will also be examined.
The proposed research is aimed at producing the core of a flexible technology platform for design and development of high-performance processes of manufacturing a range of engineering materials. The key idea is investigate the spinning disc atomisation process| which is the cheapest and most efficient atomisation method applicable to numerous materials| both theoretically and using theory-guided experiments| and incorporte the findings into a technological platform using the help and resources of an industrial company experiences in this kind of upscaling. Besides its main deliverable| the research will also develop a methodology of investigating a multi-faceted industrial problem where the multiplicity of potential outcomes of the technological process is controlled only implicitly by a few operational parameters.
The EPSRC Centre for Innovative Manufacturing for Continuous Manufacturing and Crystallisation is concerned with establishing new collaborations on the development of novel continuous manufacturing technologies to improve understanding of particle formation and to exploit this knowledge to enhance the manufacture of particles with specific beneficial properties. This has significant potential given the importance of particulate processing across many fine chemical industries including agrochemicals| pharmaceuticals| dyes| pigments and energetic materials.

In partnership with the US-based National Science Foundation Engineering Research Center for Structured Organic Particulate Systems| we propose to create the International Institute for Advanced Pharmaceutical Manufacturing with the goal of advancing the science and technology of integrated primary and secondary continuous manufacturing of pharmaceutical products. The aims of this project are to identify specific activities mapped onto the areas of mutual interest and start to agree forward exchanges| engage with industry and develop specific plans for joint meetings| researcher and faculty exchanges| collaborative research| and training activities that will benefit the wider community in both collaborating countries. In addition| the scope of a Mock Submission| the regulatory process by which new drugs are approved for use| will be developed by engaging jointly with UK/EU and US regulators and industry to agree on the framework that would ensure the impact of academic contributions on addressing the regulatory challenges for the adoption of continuous manufacturing. 

The proposed links with international experts will lead to accelerated progress of integrating continuous manufacturing processes into the high value chemical sector| raise profile of UK-based research| and ultimately enhance the opportunities for high quality| collaborative research outcomes.
Silicon based nano-photonics is becoming a prominent contender in the race for effective all-optical information processing - and is simultaneously becoming a fascinating arena for fundamental research. Integration of optical devices into microelectronic chips is now not only discussed by academic researchers| but is also included in the business plans of microelectronics giants such as Intel and IBM. One of the first practical applications of on-chip nanophotonics is likely to be compact optical processing of multifrequency data streams. Nano-sized silicon waveguides (photonic wires) and resonators offer a very attractive way of realizing photonic components on a chip. This is due to the large index contrast between silicon and air| so that light at a wavelength of 1550nm can be tightly confined for waveguide widths as small as 500 nm. Another widely-recorgnised advantage is the possibility of using well established and wide-spread complementary metal-oxide-semiconductor (CMOS) technology. The presence of a substantial ultrafast Kerr nonlinearity in Silicon nano-structures potentially allows devices to perform at the THz rates that will be required in near-future high-performance sub-systems. Nonlinearity and dispersion control are the key properties needed to develop all-optical processing devices such as modulators| switches| delay lines and amplifiers. They are also the key parameters to be controlled if we are to understand and explore the fundamental optical physics in these structures. The interplay between dispersion and nonlinearity leads to such effects as soliton formation and modulation instability| which will be essential for temporal control and spectral modification. One of the dreams of the optical soliton community has been a three dimensional photonic chip made of a nonlinear material where all the routing is done by means of the spatial solitons| which then serve as an instantly reconfigurable and flexible network of waveguides for transmission and processing of data by means of temporal solitons. The soliton effects in planar silicon chips proposed here are possibly as close as we can hope to get to this dream. The overall aims of the research programme are: to fabricate a range of silicon-on-insulator structures for observation of spatiotemporal solitons| frequency conversion| and spectral| temporal and spatial shaping of femtosecond pulses;bistability effects in cavity arrays; experimentally observe and model the above effects| develop their physical understanding; use the unique properties of silicon to observe new optical phenomena; ensure further scientific progress in the area of nonlinear nano-photonics.
The very definition of complexity and emergence is itself a non-trivial problem. Complexity refers to situations where many simple interacting parts produce an unexpected collective behaviour. This calls for another imprecise concept that is emergence. Complex systems can display the emergence of properties at the macroscopic level that are not found at the microscopic level. One important example of emergence is self-organization. Self-organisation occurs as parts of a complex adaptive system| such as oil molecules in a thin layer| self-organise to form patterns in a state that is statistically stable. The basic mechanism for self organisation comes from feedback. Each part can communicate with its neighbours and arrange into a common collective behaviour. Sometimes| regardless the precise dynamics of the interactions| the evolution of the system is represented by some statistically stable state. This means that this steady state is an 'attractor' in the phase space for the system dynamics and accounts for the robustness of complex systems with respect to external perturbation. The Properties of a complex physical system are emergent just in case they are neither (i) properties had by any parts of the system taken in isolation nor (ii) resultant of a mere summation of properties of parts of the system. The above definition of emergence shows how this process may apply to many systems across all length scales and complexity scales. However| when one moves from physical to social| medical| or even artificial systems| the ability to spot and work with / around this concept becomes more important.Further| the ability to spot emergent entities occurring in very different situations would seem to be vital to allow this concept to grow and be developed. A substantial trans-disciplinary theory of emergence would greatly contribute to the development of a broader application and understanding of complexity science. The EPSRC IDEAS Factory on emergence tackled all of these issues| resulting in a number of funded projects. In order to maintain good communication between those involved in the projects| to further address the outcomes of the sandpit| and to encourage interdisplinary communication surrounding complexity and emergence| a network to cover emergence across disciplines is required.
Visible light is only a very small part of the whole electromagnetic spectrum. The radio spectrum is also very familiar to most people| but less well known is the range of wavelengths in between. In this project we are particularly interested in a part of the spectrum that has come to be known as the terahertz band| so called because the frequency is around 1 THz. Light in the terahertz band can pass through materials that are opaque to visible light| but yet| the wavelength is still small enough to resolve features smaller than 1 mm. Because of this terahertz has attracted a great deal of interest for applications where we need to see through materials| but also take good sharp pictures. Applications include medical and security imaging| particularly because terahertz is non-ionising so can be safely used with humans.Unfortunately terahertz technology suffers from some significant difficulties that requires research to overcome. Bright terahertz sources are difficult to make| so considerable effort is needed to improve what we have at the moment. Terahertz is energetically similar to ambient radiated heat| so sensors have to be both sensitive and highly descriminating. In a complete terhertz imaging system all aspects of the technology and its components are important in determining the overall performance. This project is therefore dedicated to improving sensor performance.There are a number of attributes that we would like for a good sensor. It should be small| consume little power| be very sensitive| and ideally| if it it to be used in an camera| fast enough to allow video rate imaging. We propose to use the optical properties of semiconducting materials and carefully designed metallic structures to capture terahertz radiation. We will demonstrate that these structures can be used to make an array of sensors| just as you would find in a normal camera| and that the sensors are sensitive and selective to terahertz. In the same way that mainstream photography has benefited from microelectronics to make digital cameras possible| we will also be able to make use of integrated circuit technology so that many sensors can be cheaply and efficiently put on to a single chip.Our project has attracted support from leading UK companies including Teraview and Selex-Galileo that have immediate routes to market for successful technology. Our aim is to complete the research that will demonstrate new technologies to the point where further investment will enable the creation of new products that can be used by scientists| clinicians and the security services in the not to distant future.
In a gyrotron| electrons gyrating in a magnetic field are coupled to electromagnetic radiation in such a manner that the radiation is amplified by extracting the electron kinetic energy. We will investigate a novel concept which uses a helical corrugation on the inside surface of a 'cylindrical' waveguide to radically modify the wave dispersion giving eigenmodes with finite| constant group velocity in the region of near infinite phase velocity. This novel dispersion opens up for the first time the potential for a high power (5kW)| broadband (10%)| high gain &gt;40dB| efficient (30%) gyrotron amplifier in the 90GHz to 100GHz frequency range and above. We have performed a preliminary experiment at X-band (8GHz to 10GHz) frequencies and will build on our lead to create an amplifier in the W-band (90GHz to 100GHz) frequency band based on the best understanding of this new concept and perform precision measurements of its gain| bandwidth| efficiency and stability against oscillations. New theory and computational models benchmarked against W-band experimental data will be used to demonstrate the potential for this novel amplifier to generate high frequency (360GHz to 400GHz and 460GHz to 500GHz)| high power (~0.5kW)| broadband (10%)| pulsed and continuous coherent radiation crucially needed by the many known applications.
Therapeutic preparations of blood clotting factors are absolutely essential for haemophiliac patients. Although haemophilia is a relatively rare| sex linked disorder affecting males| it occurs in all races and ethnic groups. It is a major world health issue and it has a huge economic impact as well as health and welfare impact on the lives of sufferers and their families. The safety of the clotting factors has been improved considerably in the last two decades by introduction of so-called recombinant laboratory-produced factors that replaced the previously used materials derived from blood extracts. This reduced markedly the risk of infection by virally contaminated preparations. However| there is no doubt that there is still a great need to improve the performance of the blood clotting factors; in particular| there is an urgent requirement to improve their stability| and to reduce the cost of their production. Blood clotting factors are complex proteins that are inherently very unstable. Consequently| these therapeutically important proteins must be produced in a dried or lyophilized form and stored refrigerated. The instability has a marked effect on the cost of their production and also limits their subsequent storage and use to applications where refrigeration is available. Insense Ltd has developed a novel method to stabilize proteins in aqueous (water-based) solutions| and demonstrated this technology with remarkable results using a wide range of commercially relevant proteins which would otherwise deteriorate readily at room temperature in aqueous solution. The stabilization is achieved using unique principles that in many ways contradict the conventional teaching regarding protein formulation. It has been shown repeatedly by Insense Ltd that such unconventional formulations result in markedly improved protein shelf life. Formulations of clotting factors with markedly improved storage stability would be a major innovation arising from this project. The overall aims of this project| which is a collaboration between Insense Ltd| the University of Kent| and the National Institute for Biological Standards and Control (NIBSC)| are two-fold. Firstly| the Insense Ltd protein stabilization technology will be applied to a range of commercially available blood clotting factors to improve storage stability| and to identify the most effective formulations. The stabilizing formulations developed in the first part of the project will be incorporated into the recombinant protein production process - using mammalian cells grown in the laboratory - that will be developed at the University of Kent. This in-process stabilization approach is thought to be unique| and if proved to be effective it would clearly have potential to transform the way biopharmaceutical production is conducted| leading directly to innovative process design for the clotting factors. The key advantage of such novel process design will be in minimizing the time between protein production and its transfer into the stabilizing medium. In the case of very unstable proteins| such as clotting factors| this delay| even if relatively short| will result in protein breakdown| and will therefore have a considerable effect on production quality| yield and efficiency. Importantly| the knowledge and expertise accumulated within this project will be directly applicable to other kinds of unstable proteins| and could significantly reduce their production costs| with an associated reduction in expense incurred by the National Health Service.
Ionotronic devices rely on charge effects based on ions instead of/or in addition to electrons. The field has begun to gain very wide attention recently. It has been applied mainly to oxide thin film memristors (resistance depends on voltage and can be switched between an 'on' and an 'off' state of high and low resistance). These devices are interesting for creating electrically switchable memory| but there are challenges with these structures including the requirement of a setting process and variable properties from one film to another. 

In this proposal| we have the new idea to utilise ionotronic effects to create a new kind of electrically switchable memory. Here ionic defects at vertical interfaces in vertical nanocomposite thin films charge couple to magnetism in a magnetic transition metal oxide. Since the cation valences in the metal oxide depend on oxygen concentration or charge state| and since the magnetic properties depend on cation valences| it should be possible to switch magnetism on and off by applying an electric field. This device is an ionotronic magnetoelectric| and it represents a completely new form of magnetoelectric RAM. 

Magnetoelectric RAM is where electric field controls magnetism instead of electric current doing so as in other forms of RAM| and it is a long sought-after goal. It offers the possibility of low power| very high density| high-speed reading and writing times| and non-volatility. Low energy| high performance computing is promised with this technology. However| while a range of structures and materials have been studied to date| none has proved practical in terms of ease of structure formation| stability| temperature of operation| or size of magnetoelectric effect. 

Making the ionotronic magnetoelectric a practical reality is not trivial| and relies on advanced materials science - the growth of very thin films| the creation of highly ordered materials combinations on a very small scale (1/0000 the thickness of a human hair)| the movement of charges along interface nanochannels near to room temperature| the knowledge of which materials combine together in a compatible way| the imaging of materials at the atomic scale| etc. To attain the 'practical magnetoelectric' dream we propose to create and measure new structures| we will use unique experimental capabilities and will also collaborate with world-leading researchers. Our starting point for the research is our ability to create| at the nanometre scale| ionic interface channels in perfect vertical nanocomposite films. We have also observed the first signs that ions can indeed charge couple to magnetic properties.
Our research has the potential to save millions of lives| save energy| save carbon emissions and enable totally secure communications. It is based on gallium nitride| which is probably the most important new semiconductor since silicon. Unlike silicon| gallium nitride emits brilliant light when a small electric current is passed through it. We can produce light of any colour (for example blue| green| yellow| red) by adding more and more indium to gallium nitride. On the other hand| if we add aluminium to gallium nitride we can produce ultra-violet light. Gallium nitride based light emitting diodes (LEDs) and laser diodes are already in widespread use| for example as LED traffic lights and as Blu-ray laser diodes for the latest DVD players. If we coat a blue LED with a yellow-emitting phosphor then a cool white light is produced| and such white LEDs are used as front bicycle lights| flashlights| backlighting for mobile phones| etc|The aim of this Platform Grant is to underpin our research in a number of key areas. Gallium nitride produces light so efficiently that if we could use white gallium nitride based LEDs for home and office lighting we could save 15% of all electricity used| reduce carbon emissions from power stations by 15% and close eight large power stations. However| high-power white LEDs are too expensive for home and office lighting| and the quality of the white light is too poor to be acceptable. Gallium nitride based LEDs are currently grown on two-inch diameter sapphire wafers. We are developing their growth on six-inch silicon wafers. If successful| this will reduce the cost of each LED by a factor of ten| which will make white LEDs cheap enough for home and office lighting. Some challenging new science in required for this| but we are world leading in this research. We are also planning to produce high quality white light| like natural sunlight| by developing new green and red phosphors| and we will tailor the wavelength of our LEDs to maximise the excitation of these new phosphors. We also plan to eliminate phosphors totally| which will further improve the efficiency| and produce white light by mixing blue| green| yellow and red LEDs. Currently green and yellow LEDs have relatively poor efficiency| for reasons which are not totally clear| and we plan to solve this problem. Solving both the problems of cost and quality will yield low-cost high-efficiency high-quality lighting for our homes and offices| with the substantial energy and carbon savings referred to above.Deep ultra-violet radiation stops bacteria and viruses from reproducing and hence essentially kills them. Aluminium gallium nitride LEDs at present emit in the deep-UV| but their efficiency is too low to be useful. We propose to make highly-efficient LEDs emitting in the deep-UV. These could be used to purify drinking water in the developing world. Over one billion people in the world do not have access to drinkable water| and drinking impure water kills more people in the world than AIDS. Our research could lead to literally millions of lives being saved. The LEDs operate at typically 4 Volts and so can be powered by solar cells| ideal for the developing world. Additionally such deep-UV LEDs could be used in a flashlight to shine on hospital walls| floors and bedding to kill superbugs.We plan to develop a novel gallium nitride based light source called a single photon emitter| which emits a single photon on demand. This would be used for sending totally secure messages. For example a mobile phone| with a single photon emitter| could send a message to a cash machine for you to obtain money| with no possibility of anyone obtaining your bank details| PIN number| etc. Our research therefore promises substantial benefits to the health| wealth| wellbeing and security of our society.
In the not to distant future information technology will have to cope with devices and components which do not obey the usual laws of classical physics but those of quantum physics. This passage is unavoidable due to the decrease of scale required for the increase of computational power and for the miniaturization of devices. But this passage also comes with fascinating new opportunities| for example the quantum algorithms which endanger the current widely used (classical) cryptographic encoding schemes (e.g. bank transactions and e-commerce)| and at the same time quantum information and computation (QIC) also provides the corresponding remedy in terms of secure quantum cryptographic and communication schemes. Without any doubt `quantum information technology' is here to stay and promises to become one of the most intriguing endeavors of this new century. But while quantum information and computation is the fruit of a major paradigmatic change which consisted of conceiving the `weird' laws of quantum physics not as a bug but as a feature| the methods haven't changed since the early days of quantum theory| and one can compare the `manipulations of strings of complex numbers and corresponding matrices' with the `acrobatics with 0's and 1's in the early days of computer programming'. At the same time many important questions related to the limits of QIC and a general model for QIC remain unanswered and it is unlikely that the current low-level methods of QIC will provide the necessary capabilities to do so. Here we see a great opportunity for `British-style Computer Science semantics and logic' which we intend to exploit. The high-level mathematical models (e.g. categorical) and corresponding logics developed to cope with distributed| hybrid and in particular resource sensitive computational settings seem to be perfectly tailored for capturing the quantum mechanical realm. Indeed| the starting point for `upgrading QIC' needs to be the quantum mechanical formalism itself| due to von Neumann| but which was also renounced by von Neumann only 3 years after its creation. A breakthrough results in this direction was recently obtained by Abramsky and myself were we stripped down the quantum formalisms to its bare `category-theoretic bones'| and within this skeleton we still seemed to be able to do full-blown QIC| but then in a far more conceptual| systematic and straightforward manner. But the greatest merit of this high-level abstraction is that we were also able to show that the formal calculations are equivalent to extremely intuitive manipulations within a very simple graphical calculus| which has the potential to release QIC research from its banner of being hard and completely inaccessible for the non-initiated ones. We intend to turn QIC research into a systematic discipline based on a small set of well-understood primitive concepts| and subject to automated design and development tools| involving the appropriate analogues to the currently available high-level methods from Computer Science such as types| well-behaving calculi| program logics etc. To this means| we intend to further unveil `the structure of quantum information' (both its qualitative and quantitative content)| and of its flow| of its interaction with classical information-flow| spatio-temporal causal structure| agents| knowledge &amp; belief and their updates. As some concrete applications of this endeavor we mention an integrated high-level approach to information security| which also in the classical domain is a very delicate matter| impossible to tackle without the appropriate high-level tools. We also intend to develop a general model for the vastly in popularity gaining measurement based quantum computing| hence contributing to the understanding of what is a practicable model of general QIC| and what are its limits.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
In the 1980s unexpected applications of the model theory of modules to the representation theory of finite-dimensional algebras were discovered and since then there has been further| sometimes deep| interaction between these areas. Model theory uses ideas and results from mathematical logic to investigate general questions about mathematical structure and also to obtain new results in other parts of mathematics. It provides a particular perspective which often gives new insights into other parts of mathematics. Almost always model theory makes heavy use of the Compactness Theorem of mathematical logic and| for that| one needs to be working in a context within which there is room to make infinitary constructions. In the specific context of the representation theory of finite-dimensional algebras| where interest is typically focussed on finite-dimensional representations| that means that we have to extend our interest to at least some of the infinite-dimensional representations| even if our eventual applications are back in the context of the finite-dimensional ones. This particular project will deep the interaction of model theory and representation theory. 

The question underlying the project is &quot;How complex is a particular collection of representations?&quot;; various ways of answering this question have been investigated already and the principal aim is to show that the most standard algebraic answer - which is given in terms of certain embeddings of one collection in another - fits well with the model-theoretic one. The latter is in terms of the notion of interpretation| which is essentially a translation from one language (associated to a collection of representations) to another. That has already been shown to be equivalent to a particularly nice kind of embedding but it is not known how to close the gap between that and kind of embedding which is the standard algebraic answer to the above question. Closing that gap is one of the aims of the project. Going beyond that| the project has as an aim a substantial refinement of the existing rather broad algebraic classification of complexity classes into tame and wild (with further refinements of tame).

The project will combine very general methods| some being inspired by algebraic geometry and abstract category theory| with very specific investigations of the representations of particular algebras where entirely explicit descriptions are the aim. It will draw on two well-developed subjects; the model theory of modules and the representation theory of finite-dimensional algebras| and will use techniques from homological algebra and additive functor category theory. In view of that breadth of necessary input as well as on account of the number and nature of the aims of the project| two PDRAs| working together with the PI| all sharing their expertise| will form the research team.
The proposed research looks to create new ways of making molecules using catalysts - catalytic chemistry. A catalyst is something added in very small amounts to a reaction that will make it faster| and they play a very important in modern chemistry. Up to 90% of chemically produced materials have used a catalyst in their production - the enzymes in washing powder are a type of biological catalyst that helps break down organic stains on clothes| for example. The catalytic converter in a car contains precious metal catalysts that help convert harmful nitrogen monoxide fumes into harmless nitrogen gas.Catalysts can dramatically accelerate chemical reactions| to the extent where some impossibly slow processes become highly efficient when performed under catalytic conditions. The trick is matching up the right catalyst with the right chemical reaction. This research proposal will look at the chemical reactions that are used to make a class of molecule called heterocycles. Heterocyclic compounds have enormous importance in our society: DNA| sugars| proteins| the molecules of nature| drugs| insecticides and vitamins represent just some of the classes of heterocycle essential to the way we live our lives. As a result| the discovery of new and improved ways to synthesise new and improved heterocycles is at the forefront of modern chemistry research. The successful research project will produce new molecules using catalytic processes that are quicker| cheaper and more environmentally friendly than existing methods. We will take these reactions and apply them to the production of new heterocycles for application in medicine| engineering and agriculture.
Ion channels are proteins that are involved in the regulation of almost every cellular mechanism and they constitute the second largest class of pharmacological drug targets. A family of these channels are located in the inner compartments of a cell (i.e. they are intracellular) and they are typically excluded from industrial large-throughput automated screening (e.g. automated patch clamp technology) that probe ion channels only in the outer cell membrane. As such| implications arise that affect the hit discovery rate of new drugs for such proteins. This proposal aims to produce and test a new microsystem technology for drug screening of human intracellular ion channels. The system will comprise a medium-throughput microfluidic prototype relying entirely on synthetic cell membranes harbouring intracellular ion channels. Whilst developing this new technology| this study will investigate two proteins that are involved in cancer and neurodegeneration| namely CLIC1 (used for validation) and CLIC4| which currently has no known pharmacological identified drug. Drug screening will be done in collaboration with industrial partners AstraZeneca and Smartox.
In a remarkable recent paper Xiao et al. at Argonne National Laboratories demonstrated that 'architecture-tuneable' Pb mesostructures (samples whose dimensions lie between microscopic 'atomic' scales and macroscopic 'bulk' scales at which the specific geometry no longer plays a role for physical properties) can be grown by electrodeposition from lead salt solutions onto graphite substrates. Simply varying the electrode potentials allows an extraordinary variety of different sample morphologies to be realised| ranging from regular polyhedra and nanowires to multipods and 'snowflakes'. These structures are truly three-dimensional (3D) superconducting mesocrystals with few bulk defects and perfectly smooth faceted faces| whose magnetic properties are dominated by their size and shape. The same deposition method should be readily extendable to many ferromagnetic metals and alloys. For the first time it is now possible to controllably fabricate regular faceted 3D mesoscrystals without the disorder and rough surfaces/edges characteristic of lithographically-patterned thin film structures. Crucially| the dimensions of these 3D mesostructures are comparable with the relevant characteristic lengthscales found in ferromagnetism and superconductivity (e.g. ferromagnetic domain size and/or domain wall width or superconducting coherence length and/or magnetic field penetration depth) in contrast to widely studied nanoscale particles/clusters and nanowires. Competition between different processes as a function of the size and shape of these 3D structures should lead to rich new physical phenomena with strong potential for exploitation. In collaboration with the Argonne group we have shown that surface/shape effects can completely dominate the magnetisation of these materials| opening up the possibility of 'designing' crystals with desirable| exploitable properties. We propose to considerably extend the scope of this work within a collaboration between well established groups in electrochemistry and nanoscale physics at the University of Bath and theoreticians in Southampton and Antwerp. We plan to grow and investigate both superconducting and ferromagnetic mesocrystals with a wide range of morphologies| as well as hybrid ferromagnetic-superconductor core-shell structures and continuous hybrid networks. The most promising materials produced will be systematically characterised using Hall nanomagnetometry and/or magnetoresistance measurements. Experimental results will be interpreted by comparison with tailor-made state-of-the-art 3D micromagnetic simulations and/or solutions of the 3D Ginzburg-Landau equation. Opportunities for exploitation of these novel magnetic materials will also be identified and explored.
In Systems Biology the mathematical/network models that are generated invariably include large numbers of variables with numerous parameters| many of which are unknown| or cannot be directly measured. With such highly complex systems there are often few direct measurements that can be made and limited access for inputs or perturbations. These limitations cause immense problems when investigating the existence of hidden mechanisms or attempting to estimate unknown parameters and these problems severely hinder validation of the model. It is therefore highly desirable to have a formal approach to determine what additional inputs and/or measurements are necessary in order to reduce| or remove| these limitations and permit the derivation of models that can be used for practical purposes with greater confidence.The purpose of this project is to ascertain the possible effectiveness of using structural indistinguishability techniques in model discrimination within Systems Biology networks. This is the important question of how to design an experiment| or experiments| to allow discrimination between two (or more) competing biological mechanisms. Structural indistinguishability for systems models is concerned with determining the uniqueness between possible candidates for the model (or mechanism) structure. The formal nature of the analysis performed in this project should permit the generation of a minimal set| or sets| of reactants that must be available for measurement in order to distinguish between competing reaction schemes. Structural identifiability can be considered as a special case of the structural indistinguishability problem and considers the uniqueness of the unknown model parameters from the input-output structure corresponding to proposed experiments for data collection. If parameter estimates are to be used to inform intervention or inhibition strategies| or other critical decisions| then it is essential that the parameters be uniquely identifiable. Once an appropriate scheme has been selected| a structural identifiability analysis will be performed| which should generate a similar set of reactants that must be available for measurement in order to guarantee uniqueness of the model parameters with respect to the responses measured. This analysis will be performed on parts of the overall system| that can themselves be considered as (sub)systems| and then the results will be combined in a novel way to test for the identifiability of the complete system.These theoretical techniques will be used to suggest innovative forms of measurement for a case study (Bacterial Peptidoglycan Biosynthesis) considered within the project. Understanding of the underlying biological process for the case study is essential for developing new strategies for dealing with antibiotic resistance. In addition| modelling of the unknown components within the case study will be driven by the results obtained from the theoretical analysis and data collected from appropriate biological experiments. In addition| the development of a new stopped flow spectrophotometer will have the capacity to collect simultaneous measurements| within a single reaction| from fluoresence changes upon formation of the enzyme substrate complex and absorbance changes upon product formation. These novel data will further inform and test the model.The overall aim of this project will be to develop| innovative| formal and generic methods for performing this analysis for models in Systems Biology. The approach will be to develop these generic tools via application to the exemplar system (Bacterial Peptidoglycan Biosynthesis)| then to extend the results obtained to more general systems models.
The cutting edge laser systems that have been developed in laboratories around the world in recent years do not want for performance. For example| lasers based on crystals of sapphire doped with titanium now routinely produce pulses of a few millionths of a billionth of a second: the shortest of man-made events. For that tiny fraction of a second| the power of the laser light is the equivalent the output of a power-station. These and other extreme specifications of today's high performance laser make them potentially revolutionary tools. Indeed| across science and engineering that revolution has started| allowing the very small| the very fast and the very complex to be studied in detail. The potential| however| is greater still. Today's high performance laser is not yet the penknife in the scientist's pocket; unwieldy and expensive| the titan is chained to the laser lab. The laser engineering challenge is to harness this performance and power in a practical package| such that the laser can go to the user rather than the user having to come to the laser. This will trigger a second - and arguably bigger - applications revolution. We believe that the use of a disk of laser material| rather than the conventional rod| can make a large contribution to civilising high-performance lasers. There are essentially two reasons for this. First| a number of important - but detrimental - properties of laser materials scale with length; these problems can be minimised by using thin disks. Second| finesse lasers| such as those based on titanium sapphire| are typically pumped by other lasers; these pump lasers can cost tens of thousands of pounds due to the performance levels required. The use of disks reduces the quality of the pump beam that is needed; thus| we believe lower cost devices such a laser diodes and even LEDs can be used with laser systems that have traditionally required high cost pump lasers.Serendipitously| the development of blue laser diodes for next generation DVD and high power light emitting diodes (LEDs) for solid-state lighting has led to a considerable improvement in performance of these light sources. As these devices are aimed at mass markets| the unit costs will be small| making them ideal low-cost pump sources. Even with these improvements| such light sources lack the power and the beam quality to pump conventional finesse lasers. However| disk geometries remove these hurdles enabling| we believe| the first demonstration of diode-laser pumping of Ti:sapphire and a new generation of LED pumped lasers. These are potentially disruptive technologies. Lower-cost| more compact Ti:sapphire lasers will take the benefits of this thoroughbred laser system directly to the application and low-cost LED pumped lasers will enable applications - like high-risk undersea or toxic substance sensing - that required finesse lasers but where loss or damage is inevitable.
The last fifteen years have seen two fairly disjoint developments in Iwasawa theory| and its relationship with come of the basic problems in arithmetic geometry. On the one hand| the precise formulation of the main conjectures in noncommutative Iwasawa theory reached a certain maturity in the work of Fukaya-Kato. An important case of the noncommutative main conjecture was proven by the PI (and independently by Burns-Rtter-Weiss). On the other| the theory of automorphic forms (p-adic and lambda-adic) was systematically developed and applied to prove main conjectures in commutative Iwasawa theory beyond the classical main conjectures by several authors including Hida| Tilouine| Urban and Skinner. It is therefore an appropriate time to combine these two developments to prove new results in both directions. We propose to tackle three inter-related problems in this general area. Firstly| we want to extend our methods used to prove the noncommutative main conjectures for Tate motives to prove new results on noncommutative main conjectures for motives other than Tate motives. To this end we propose to systematically study p-adic and lambda-adic automorphic forms over various totally real fields and relations between these automorphic forms as the fields vary. Secondly| implicit in the conjectures of Fukaya-Kato are certain factorisations of p-adic L-functions. These factorisations| known only in a couple of cases| have deep arithmetic implications such as towards Greenberg's L-invariant conjectures. We propose a new strategy to attack these factorisation problems using the tools developed to tackle our first question. Lastly| we propose to study main conjectures over function fields. The algebraic techniques we have developed have already proven very fruitful in Iwasawa theory over function fields in the work of Burns. There is| however| another family of main conjectures over function fields (e.g. in the work of Trihan and his collaborators). Our third project is to use our algebraic results and techniques used by Burns to attack these main conjectures.
The twentieth century saw an explosion in semiconductor electronics from the first transistor| which was used in hearing aids| to the ultrafast computers of today. A similar surge is anticipated for Plastic Electronics based on a new type of semiconducting material which is soft and flexible rather than hard and brittle. Plastic Electronics is considered a disruptive technology| not displacing conventional electronics| but creating new markets because it enables the printing of electronic materials at low temperatures so that plastic| fabric| paper and other flexible materials can be used as substrates. Printing minimises the waste of materials and low cost roll-to-roll manufacturing can be used because the substrates are flexible. New applications include intelligent or interactive packaging| RFID tags| e-readers| flexible power sources and lighting panels. The organic field effect transistor (OFET) is the fundamental building block of plastic electronics and is used to amplify and switch electronic signals. The organic semiconducting channel connects the source and drain electrodes and is separated from the gate electrode by an insulating dielectric. A positive/negative gate voltage induces negative/positive charges at the insulator/semiconductor interface and so controls the conductivity of the semiconductor and consequently the current flowing between the source and drain. The future success of the industry depends on the availability of high performance solution processable materials and low voltage device operation. The semiconductors must have high electron and hole mobility (velocity/electric field) achieved by the hopping of carriers between closely spaced molecular sites. A new class of lamellar polymers| mostly developed in the UK| provides the required state-of the art performance because of their macromolecular self-organisation. However a major problem is that the materials are only well-ordered in microscopic domains; trapping in grain boundaries and poor interconnectivity between domains substantially reduce performance and reliability. The low voltage operation of OFETs requires that the gate insulators have a high dielectric constant. 
We propose novel insulating dielectrics for OFETs to simultaneously align the plastic semiconductors and ensure low voltage operation. They will be solution processable at low temperatures for compatibility with printing and other large area manufacturing techniques. We will synthesise and characterise the new materials and test their performance using state of the art semiconductors. We will engage with industrial end-users to ensure that our technology is exploited so contributing to the high-tech economy in an area where the UK is already pre-eminent. We anticipate that our novel insulators will provide monodomain order over large areas to the overlying semiconductor and so will enhance OFET performance and stability. Hence we aim to hasten the commercialisation of Plastic Electronics.
Positron emission tomography (PET) is the most sensitive functional imaging method clinically and it application is growing rapidly through the Western world and developing countries| particularly as a diagnostic imaging tool for cancers and degenerative neurological disorders. Many major hospitals and clinical research centres in the Europe| the US and Asia are now commissioning cyclotrons and developing PET research facilities locally. Fluorine-18 is an important isotope for PET. It has a relatively long half-life (109 mins) and is readily generated in a cyclotron in the form of [18F]-fluoride ion| in very high specific activity (GBq's) from oxygen-18 water. As a consequence new methods to develop C-[18F]F bond formation for PET labelling are in demand| in general the link between fluorine chemistry and pharmaceutical/medical applications is strong. Approximately 20% of all pharmaceutical| since the 1950s| contain a fluorine atom and the bio-distribution of all new pharmaceutical products are required to be explored by PET| as part of clinical trials. Also new PET tracers are in demand as tools for early diagnosis as indicators of disease states. New fluorine chemistry is required to meet the demands of a growing and dynamic PET research community both in the UK and internationally. This proposal aims to develop a novel methodology for incorporating fluoride-18 specifically into peptides and proteins. 

In this proposal we aim to exploit a novel enzyme which can form C-F bonds from fluoride ion. The fluorinase enzyme was discovered in 2002 (Nature| 2002| 416| 279) in St Andrews and it has been over-expressed and its structure (X-ray) and mechanism elucidated. The enzyme catalyses the reaction of fluoride ion and S-adenosyl-L-methionine (SAM) to generate 5'-FDA and L-methionine. It has proven to be a chemoselective biotransformation method for generating C-18F bonds from inorganic [18F]-fluoride. However we have found a weakness in the substrate specificity. We find that at a very specific location we can attach a linker to the substrate| and it will be accepted by the enze| this linker provides an anchor point to run a molecular line (poly ethylene glycol) to a peptide molecule of choice. The chosen peptides are those that identify cancer cells in the body| known as homing peptides| or small antibodies called 'affibodies' that identify tumour cells. In this way we can use the enzyme to attach the fluorine-18 isotope. The important advantage is that the fluoride-18 is generated in water| and the enzyme functions in water at neutral pH. Also peptides are nicely soluble in water| so the labelling can take place without the difficulty of using organic solvents for these biomolecules. This presents attractive possibilities. The fluorinase is the only example of an enzyme used in fluorine-18 PET synthesis and in this regard it offers an entirely new method for incorporating fluorine. In practical terms it has emerged to be particularly appropriate| because PET uses picomolar [18F]-fluoride ion| but the over-expressed fluorinase enzyme is present at mg/ml (microM)| and therefore the kinetics favour C-18F synthesis due to a large molar excess of enzyme. 

This is a research collaboration between the Universities of St Andrews and Aberdeen where the enzymatic methods for labelling the petides and proteins will be developed in St Andrews and the radiolabeling protocols carried out at the Aberdeen PET Centre| situated in the Aberdeen Royal Infirmary. The major focus of the research will concentrate on rapid labelling of peptides under neutral ambient conditions.

The research in aims to establish new methods for much wider applications by the growing international research community of PET radiochemists and we have ambitions to translate the methods to the clinic through interactions with PET based companies such an Imanova and our established interactions with the Beatson Cancer Institute in Glasgow.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Our vision is sustainable international leadership in chemical materials design that will allow the UK to discover new step change functional materials| thus driving inward investment and economic growth. This will be driven by scientific excellence| will be strongly integrated with industrial exploitation| and will link together the world premier groups in the UK to maximise return on investment. Operationally| we will use the existing Materials Innovation Factory (MIF) infrastructure and its business model to ensure that this theme operates as a distinct and unique offering that is accessible to external partners in a clearly branded and state-of-the-art space-this will become the Royce @ Laboratory| and it will operate within the broader 11|600 m2 Materials Innovation Factory. By choosing this route| we ensure strong industrial engagement from the outset: at least 110 industrial researchers from at least two major UK companies will be collocated in the same building on 'day one'. Hence| we can demonstrate cross-sector benefit in this Royce Institute theme to our funders and this greatly enhances future prospects for long-term sustainability of the theme and makes a strong contribution to the Northern Powerhouse legacy.

Our vision relies on the integration of experimental and computational methods to both accelerate materials discovery through design and to open up access to new classes of both 'hard' and 'soft' functional material. The new enabling methodology for materials discovery that we will create will be actively transferred to the direct drivers of economic growth within key UK industry partners. Our capital request comprises equipment| such as the high-throughput 'Formulation Engine'| that is unique not only in the UK but also globally.
An aneurysm is a bulge (dilation) in the wall of an artery| usually the aorta. An aneurysm that grows and becomes large enough can burst| causing dangerous| often fatal| bleeding inside thebody. Information from mathematical modeling of aneurysm formation can help doctors make the difficult decision about which course of action to take once an aneurysm has been diagnosed (whether to carry out a surgery| to prescribe appropriate drugs to reduce the risk of aneurysm bursting or to simply put the patient under observation). Previous studies have focused on modeling the evolution of aneurysms numerically by assuming that a seriously enough inhomogeneous weakening of the artery has taken place. We aim to model aneurysm formation from a different perspective: we view the initiation of an aneurysm as a bifurcation problem; it can occur even if the material properties are homogeneous along the artery. We hope to establish a theoretical framework under which the initiation of an aneurysm can be predicted| and once an operation to remove or repair an aneurysm has been carried out the integrity of the operated section can be assessed. This will involve the following two tasks: (i) derivation of appropriate constitutive models for healthy and pathological arteries| and (ii) given a particular material model| describing precisely whether an aneurysm can form or not and how it will form (e.g. whether it will grow axi-symmetrically or from the side).
The importance| motivation and stimulus of this multi-disciplinary (chemical synthesis| liquid crystal and polymer science| optical technology and information storage) and international (UK| Japan| Denmark and USA) materials-related feasibility research proposal is to address the urgent global consumer requirement for an ever-increasing demand for higher data storage capacity. Current technologies such as conventional magneto-optical are fast becoming economically unviable and will soon reach their physical limitations of storage capacity. Hence new solutions are required to address this multi-billion dollar problem. Optical holographic storage is a critical next-generation technology that can support the growing information storage needs of the 21st century. Novel holographic read/write media are required. Our solution encompasses technology transfer between academia and industry via the synthesis| characterisation (chemical and optical) and industrial global evaluation of strategic organic materials as a source of novel highcapacity holographic read/write storage media. The materials are organic-based polyesters comprising both side-chain mesogenic and side-chain heterocyclic photoresponsive groups. The synthetic chemistry is versatile and readily amenable to large-scale production. The media will be industrially tested for 'end-user' commercial applications providing the project with focus| application and realism.
The increased understanding of the genome has been one of the great success stories in biology over the past 50 years. Basically DNA in the genome contains genes which contain the information needed to build proteins| which in turn carry out the functions of life. However| many deep questions remain| and statistical ideas will play a central role in understanding genes and proteins. In particular the shape of a protein is one of the key properties which determines how a protein works. As one example| protein folding is a challenging problem in bioinformatics (a successful solution to this problem will surely lead to a Nobel prize nomination). The advances in geometric statistics and particularly shape analysis from LASR workshops enable us to explore new ways of modelling protein structure.Each year we select a topic at the cutting edge of research. LASR 2006 looks forward to exciting developments at the interface between statistics and bioinformatics. We believe we are the only Statistics Department in this country to make a strong commitment in research in statistical protein bioinformatics. For example| our speakers| Janet Thornton (Director| European Bioinformatics Institute| Cambridge) and Brian Athey (Director| Michigan Centre)| are not exposed to statisticians and our aim was to get a good group of statisticians and bioinformaticians together for a joint dialogue.The workshop is primarily aimed at academic staff| research fellows and research students. Participants for Leeds research groups will be encouraged to attend| but we will focus on attracting a broad range of UK delegates. Where appropriate| keynote speakers have been imported from continental Europe and America to strengthen the UK science base. We expect about 80 participants coming from a wide variety of fields: statistics| bioinformatics| computer science and engineering. We also expect a number of non-academic and industrial participants. Published proceedings| including all papers and abstracts for posters| will be available for participants at the beginning of the workshop. The gradual building of expertise and research findings will enhance the position of UK research in this exciting area.The University of Leeds is well-placed to host such an event| with strong groups in both statistics| bioinformatics and the new centre of Statistical Bioinformatics
Describe the proposed research in simple terms in a way that could be publicised to a general audience [up to 4000 chars]. Note that this summary will be automatically published on EPSRC's website in the event that a grant is awarded.

The recently developed memory architectures based on resistive-variable devices such as Phase Charge Memories| Programmable Metallization Cell or memristors have reliability issues that are drastically different from those affecting CMOS based memories. These novel memories although based on different technologies| they all share the principle of storing information as the resistance value imposed to a resistive-variable devices and consequently also the possible type of faults that may occur.
This project proposes to leverage data obtained from experimental results to characterize resistive-variable devices and to exploit both information and architectural redundancies to enhance reliability and yield of these devices. 
To face the presence of a massive number of defects suitable spare resources| such as spare row and/or columns will be used combined with suitable error detection methods and efficient readdressing scheme to substitute faulty elements. To leverage the use of spares resources| codes novel models and algorithms to estimate the reliability versus overhead trade-off will be developed| with the aim of obtaining a reliability-aware driven synthesis tool for these memory devices.
In the study of dynamical systems| the long term asymptotic behaviour is often best understood in terms of properties of invariant measures. In the particular setting of Lagrangian flows| Mane and Mather formulated a number of important questions about those measures whose integrals maximized a particular integral. As part of a general theory| one can ask similar questions about quite diverse dynamical systems. In the particular case of hyperbolic (or chaotic) dynamical systems| we can consider a natural class of measures called Gibbs measures| whose study originated in the mathematical theory of Statistical Mechanics| and the work of Ruelle and Sinai. This proposal relates to how maximizing measures for typical functions for these hyperbolic systems can be approximated by these better behaved Gibbs measures. This has important implications for understanding the quite complicated| but important| maximizing measures in terms of much simpler Gibbs measures.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Organic compounds containing a cyclic arrangement of atoms| where at least one atom in the ring is an atom other than carbon| are refered to as heterocycles. Heterocyclic motifs are found in many natural and man-made biologically active compounds| for example drugs| and functional organic materials| such as organic semiconductors and liquid crystals. Whether these heterocyclic compounds are the constituents of new medicines or make up components of new electronic devices| this class of organic molecule has a tremendous impact on our quality of life. It is not surprising then that the development of new chemical processes that allow heterocyclic architectures to be constructed in a concise fashion is of major| international importance and is a highly competitive area of science. Recent discoveries in our research laboratories mean that we are uniquely placed to exploit our preliminary results in this area and to take a lead in the field.The grand challenge in organic synthesis - the construction of complex organic molecules from simple ones - is the development of efficient routes| using few chemical reactions| that produce the target compounds with minimum purification of intermediates. In this project we will develop strategies that allow important heterocyclic structures to be built quickly| using new chemical reactions| including 'cascade' reactions| and separation technology to reduce the need for traditional purification techniques such as chromatography. Cascade reactions are chemical reactions were a number of chemical changes happen in one reaction flask thus saving time and resources.The new chemical reactions we will use to form heterocycles are triggered by either the addition or the loss of a thiol - the sulfur analogue of an alcohol - from starting materials. We will 'couple' these new chemical reactions so that they work in a synergistic fashion and provide short routes to compounds that display either important biological activity (e.g. anti-tumour agents) or exhibit valuable physical properties (the constituents of semiconductor devices that show improved stability). When incorporated| the thiol unit will help us modify intermediates and will allows us to purify them quickly thus avoiding the expense of traditional chromatography.The project will feature the synthesis of analogues of two natural product families| the ecteinascidins and the spirotryprostatins. Natural products are| as the name suggest| naturally occuring organic molecules that often have important medicinal properties. One of the most famous examples is the natural product Taxol that was isolated from the bark of the Pacific Yew tree and is now a leading anti-cancer drug. The ecteinascidin and spirotryprostatin also have important anti-cancer activity and there is an urgent need for larger amounts of analogues of these scarce natural products for evaluation. We will also use our new strategies to make collections of indolocarbazoles| 'unnatural products' that have exciting semiconductor properties.Developing expedient routes to these natural and unnatural products is particularly timely as the link between the molecule's structure and its activity in these families is not clear. As existing access to these targets is limited| material for study is scarce. Ultimately| our research may lead to new heterocyclic drugs and organic electronic devices| and subsequently| to improvements in the quality of life| worldwide.
This proposal| in response to EPSRC 3rd Interact call| is to initiate and enhance UK - China collaborations in the area of global logistics and supply chain management research. The project entails six UK academics with long standing interest in logistics and manufacturing supply chains to visit leading Chinese institutions at the fore-front of research in China. The UK academics are from the Universities of Liverpool| Cardiff| Huddersfield| Hull| Leeds Met| Loughborough| and Staffordshire| Nottingham whilst the Chinese academics are from Tsinghua University| Chinese Academy of Sciences and Shanghai Jiaotong University. The China Federation of Logistics and Purchasing will also be host to the UK delegation. It is planned to explore areas for potential collaboration with Chinese counterparts while in China and also to give seminars to audiences in there and hold workshops in Beijing and Shanghai. On return to the UK| the outcomes of the visit will be publicised via the EPSRC website| Programme newsletter Connect ; and seminars will be held under the auspices of the Chartered Institute of Logistics and Transport - Dr Yusuf and Prof Pawar are members of the Institute - and summary of the seminar will be published in the Institute's trade magazine| Logistics &amp; Transport focus . The summary will also be published in the Institute of Operations Management (IOM) magazine| Control | which reaches over 4|000 members - both Dr Yusuf and Professor Little are members of the IOM.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
Reliable electricity supply forms a one of the basic requirements of modern 21st Century life. Sustaining this reliable supply is one of the key challenges for the coming decades. A solution is not straight-forward and will have many parts. Integrating offshore wind energy generation as cheaply as possible is one part. Linking our electricity transmission network to the generation and services of other European countries is another part. Reinforcing the onshore electricity network to cope with new power flows| is a further part. 
Addressing these challenges requires an offshore electricity network| which is controlled to support our existing infrastructure. Such an offshore network disrupts far less of the onshore countryside and living environment than conventional onshore solutions. Enabling this necessary offshore network is the goal of this proposal. The technology needed to achieve such a solution is so-called Voltage-Source High-Voltage DC Transmission (VSC-HVDC): DC connections using converter stations with the latest state-of-the-art| high-voltage semiconductor power processing technology. Only such stations have the required flexibility| compactness offshore and ability to transmit power over long sub-sea cables. However our experience with such technology is limited to point-to-point systems. No small networks (so-called multi-terminal systems) have been built. No large networks (so-called DC grids) have been constructed. Very little research has been published into how to control such systems. There is a dearth of information on how to make large offshore networks 'work'. However many industrial and academic organizations have highlighted the substantial potential benefits in terms of reduced cost| improved reliability and greater functionality which could be offered by such DC offshore networks to our existing electricity infrastructure. 
This project will undertake the research urgently required to assess the best way to control and mange such networks. Since telecommunications| controller architecture and control are intimately linked| research to assess and include the impact of these constraints will also be incorporated. Candidate networks will be formulated| analyzed and simulated using state-of-the-art models. These models will be improved to include the effects of distributed control and telecommunications effects/Quality of Service. New techniques will be developed that allow similar benefits to 'perfect' (idealized Master) control to be achieved with more realistic distributed hardware systems.
The transformative goals of this project are thus:
1. To establish how Master and Distributed Master controllers can improve VSC-HVDC-grid performance and offer robust and reliable services to AC onshore networks.
2. To investigate advanced controls| and effective exploitation of state-of-the-art and developing telecommunication technologies| to integrate this control with local station control and to overcome conventional operational speed limitations.
Better system understanding| models| and improved control will result. This in turn should allow the creation of a cheaper| more effective offshore network.
Natural and industrial porous media is key to a wide variety of traditional and emerging engineering applications| including but not limited to oil and gas extraction from geological reservoirs| carbon capture and storage| geothermal reservoir engineering| soil sciences| groundwater remediation and protection| biological engineering| food processing| fuel cells| nano-technology| construction engineering| wood processing and printing. 

We are proposing the formation of a UK wide research network focussed on porous media flow which will sit at the interface between engineering| applied mathematics| applied probability and scientific computing. The overall aim of the network is to transfer techniques| models and scientific insights between engineering and mathematics| as well as promote mobility between academia and industry. Initially| the key areas of scientific research will include: large scale computational modelling| fundamental pore-scale physics| inverse problems and history matching| reservoir simulations| soil science and shallow ecosystems| theoretical biology and physiology| groundwater remediation| subsurface storage of greenhouse gases and nuclear waste| uncertainty quantification| homogenisation and multi-scale methods| visualization| numerical analysis and random field modelling.
When a fluid filled container is shaken vertically| one may observe waves on the surface of that container if the shaking is sufficiently strong. These waves arise out of a subharmonic instability: they have half the frequency of the shaking| and are called Faraday waves.

In separate experiments| high-speed films of droplet impacts on static fluid baths show that the droplet does not always coalesce with the bath on impact| but may bounce a few times before coalescing.

Combining these two experimental facts| about 10 years ago it was discovered that millimetric liquid droplets can bounce indefinitely when dropped on the surface of a bath of the same liquid in a shaken container. The phenomenon occurs below the shaking threshold for the Faraday instability. More surprisingly| the droplets can also spontaneously &quot;walk&quot; along the surface of the vibrating bath. These walkers then exhibit many features previously thought to be exclusive to quantum mechanics such as wave-particle duality| quantised energy states| single particle diffraction and tunnelling behaviour.

The aim of this proposal is to explore the fluid mechanical aspects of this system. There are many unanswered challenging questions due to the complexity of the problem. Fluid mechanics questions include the understanding of non coalescing drop impact| and the behaviour of reflecting walkers and their pilot wave field at walls. We will also seek to understand how a purely classical mechanics system exhibits quantum mechanical-like behaviour| and probe the limits of this analogy. 

The proposed research involves a combination of analytical and numerical approaches as well as comparisons with experiments. We will partner with an MIT state-of-the-art fluid dynamics laboratory which will provide both experimental data and design validation experiments. The problems we plan to study are of general interest in fluid mechanics and in the theory of free boundary problems and dynamical systems. It is expected that the results will have broad applications| in particular to the understanding of the impact of drops and particles with fluids.

Faraday instabilities are also the most reliable way of generating consistently sized droplets continuously. Because of this there are several possible microfluidics applications for this research| such as developing better devices for delivering inhaled drugs.
The main objective of this proposal is capacity building in theoretical complexity science by coordinating and developing existing activities in the Departments of Mathematics| Physics and Bioengineering at Imperial. The RA hired for the project will be placed in the Institute for Mathematical Sciences (IMS) at Imperial. The IMS provides a venue for transdisciplinary research in mathematical sciences applied to real world problems. In this way the project will benefit from the other complexity activities hosted by the IMS as well as forging an inventive collaboration between researchers from various Departments. The proposed research will focus on network dynamics| a term that encompasses both dynamics on| and dynamics of| networks. Theoretical tools related to statistical mechanics| dynamical systems theory and stochastic processes will be developed to analyse and characterise the relationship between network structure and the emergence of collective network behaviour. In particular| the research will develop our understanding of the dynamical evolutionary processes leading to specific network structure and the properties of dynamical processes taking place on such networks. The theoretical modelling will be inspired by functional brain imaging data obtained experimentally by the Division of Clinical Neuroscience. The theoretical research will on the other hand motivate the experimental development.
In 1948| Shannon published his famous paper &quot;A Mathematical Theory of Communication&quot; [88]| which laid the foundations of information theory and led to a revolution in communication technologies. Shannon's fundamental contribution was to provide a precise way by which information could be represented|
quantified and transmitted. Critical to Shannon's ideas was the notion that the content of a message is irrelevant to its transmission| since any signal can be represented in terms of bits.

However| Shannon's theory has some limitations. In 1953| Weaver argued that there are three levels
of communication problems: the technical problem &quot;How accurately can the symbols of
communication be transmitted?&quot;| the semantic problem &quot;How precisely do the transmitted symbols
convey the desired meaning?&quot;| and the effectiveness problem &quot;How effectively does the received
meaning affect conduct in the desired way?&quot; Hence| a key limitation of Shannon's theory is that it
is limited to the technical problem. 

This was also pointed out by Bar-Hillel and Carnap in 1953| who argued that &quot;The Mathematical Theory of Communication| often referred to also as Theory (of Transmission) of Information| as practised nowadays| is not interested in the content of the symbols whose information it measures. The measures| as defined| for instance| by Shannon| have nothing to do with what these symbols symbolise| but only with the frequency of their occurrence.&quot; While Bar-Hillel and Carnap argued that &quot;the fundamental concepts of the theory of semantic information can be defined in a straightforward way on the basis of the theory of inductive probability&quot;| their work was based primarily on logic rules that were applicable to a very restricted class of
signals (e.g. text). In the last 60 years there has been extraordinary progress in information theory|
signal| image and video processing| statistics| machine learning and optimization| which have led
to dramatic improvements in speech recognition| machine translation| and computer vision technologies.
However| the fundamental question of how to represent| quantify and transmit semantic is what this programme of research shall address.
Osteoarthritis (OA) is the gradual degeneration of cartilage covering the bony ends of joints. It is a debilitating disease which develops in 33% of adults in the mid 40s and affects 15% of the worlds population. The cost of OA treatment for the UK National Health Service (NHS) was &pound;850M in 2007 (5% of the NHS budget) and is increasing. There is an urgent need for an injectable fluid that transforms into a gel in the body that provides both immediate load support to damaged cartilage and results in regeneration of cartilage tissue. Hollow polymer particles have potential to enable regeneration of cartilage tissue. In our proof-of-concept study we established a new injectable fluid containing pH-responsive biodegradable hollow polymer particles that change from a fluid to a gel at physiological conditions. In this proposal we aim to establish methods for linking the hollow particles together to prepare injectable gels that are both mechanically stable and are able to be disassembled on demand using molecules that naturally occur in the body. These are essential steps which| if successful| will result in design rules for preparing injectable| high strength| hollow particle gels that could enable a new OA therapy. This ambitious proposal greatly extends our earlier study and will be conducted by a postdoctoral research associate over a period of 30 months.
The requirements and criteria for what constitute good and bad rotorcraft handling qualities have developed to the point that new designs and upgrades can be brought to service with a very low risk that any limitations on flight safety or on the capability to perform intended missions will result from deficiencies in flying characteristics. The research base that has elevated the discipline was created over more than two decades of flight and ground-based simulation testing| supported by modelling and simulation| and undertaken by multi-national teams of engineers and pilots.

Alongside these endeavours| the technologies for flight simulators have been developing| but have lacked the benefit of an underpinning research base. The metrics and tolerances in current standards are derived from fixed-wing criteria and shown to be lacking in a number of important aspects. The EPSRC funded research at Liverpool| Lifting Standards (2008-11)| has developed a more rational basis for quantifying simulation fidelity| using a handling qualities approach. The research at Liverpool features the 6 degree of freedom motion simulator| HELIFLIGHT-R| alongside close collaboration with the Flight Research Laboratory (NRC| Ottawa). Metrics for predicting fidelity and capturing pilot perceptual fidelity have been derived and used in the development of a new unified approach to qualification. Central to the approach is the need to understand and quantify the level of adaptation that pilots apply as they transition from the simulator to flight. Beyond a certain level of adaptation| the resulting negative training means that safety and operational capability may be compromised. Within the concept of strategy adaptation is the degree of control compensation and hence the link between handling quality and fidelity strengthens. Outstanding questions concern the acceptable tolerances on predicted and perceptual fidelity metrics that a simulator is 'fit for purpose'; what constitutes Level 1 fidelity| and how critical are the handling qualities to this question are continuing research questions. 

These questions formed the backdrop to the American Helicopter Society (AHS) workshop on Simulation Fidelity held in Virginia Beach| May 2011. The workshop| chaired by the proposer| was attended by more than 70 delegates and seeds were sown for further collaboration between research laboratories and industry to develop the required evidence base; there is a historical perspective to the development of best practice that needs to be brought into the continuing research. Much has been left poorly documented. In this short research project| the proposer will bring these themes together.

A core activity of the research project will be the preparation of the prestigious AHS Nikolsky paper and lecture| and dissemination at various US Centres| where the opportunity will be taken to reinforce collaboration. Padfield will review the developments of handling qualities criteria since the birth of the practical helicopter 70 years ago. The key innovations that have allowed the industry to break through the barriers to formulating and adopting quality criteria will be identified and described. The critical enabling flight control technologies will also be reviewed and the continuing developments that confer super handling analysed and conjectured. The improvements in rotorcraft handling qualities should have a massive impact on safety and operational capability on the one hand and the technical requirements and training effectiveness of simulators on the other. The author will take the opportunity to strengthen the collaboration on handling qualities and simulation fidelity| setting the stage for the 2012 fidelity workshop in Fort Worth and continuing collaboration into 2013
While the traditional| deductive approach to logic begins with premisses and in step-by-step fashion applies proof rules to derive conclusions| the complementary reductive approach instead begins with a putative conclusion and searches for premisses sufficient for a legitimate derivation to exist by systematically reducing the space of possible proofs. 

Not only does this picture more closely resemble the way in which mathematicians actually prove theorems and| more generally| the way in which people solve problems using formal representations| it also encapsulates diverse applications of logic in computer science such as the programming paradigm known as logic programming| the proof-search problem at the heart of AI and automated theorem proving| precondition generation in program verification and more. It is also reflected at the level of truth-functional semantics --- the perspective on logic utilized for the purpose of model checking and thus verifying the correctness of industrial systems --- wherein the truth value of a formula is calculated according to the truth values of its constituent parts. 

Despite the reductive viewpoint reflecting logic as it is actually used| and in stark contrast to deductive logic| a uniform mathematical foundation for reductive logic does not exist. Substantial background is provided by the work of Pym| Ritter| and Wallen| but this is essentially restricted to classical and intuitionistic logic and| even then| lacks an explicit theory of the computational processes involved. We believe coalgebra --- a unifying mathematical framework for computation| state-based systems and decomposition| for which Silva is a leading contributor and exponent --- can be applied to this end. Deduction is essentially captured by inductive constructions| but reduction is captured through the coalgebraic technique of coinduction| which decomposes goals down into subgoals. 

Existing work shows that coalgebra generalizes truth-functional semantics and can represent basic aspects of search spaces. We will systematize this work to logics in full generality and| by utilizing the coalgebraic approach to the modelling of computation| also capture the control procedures required for proof-search. The algebraic properties of coalgebra should ensure that all aspects of this modelling| including the definitions of logics| their search spaces| and their search procedures| will be compositional.

Beyond this advance on the state of the art in semantic approaches to proof-search|
we can hope to utilize coalgebraic presentations of computation to achieve much more. By interfacing coalgebraic models of proof-search with coalgebraic models of| for example| probabalistic computation or programming languages| we can hope to give a clean| generic and modular presentation of applications of the reductive logic viewpoint as diverse as inductive logic programming and abduction-based Separation Logic tools such as Facebook's Infer.

Abstracting the key features of such systems into a modular semantic framework can help with more than simply understanding how existing tools work and can be improved. Such a framework can also guide the design and implementation of new tools. Thus| in tandem with our theoretical development| we will develop efficient| semantically driven automated reasoning support with wide application. In doing so we can thus hope to implement tools capable of deployment for a large range of reasoning problems and guide the design of theorem provers for specific logics.
Multiferroic materials span a rich diversity of phenomena and applications. They have striking features such as cross-coupling of electro-magnetic| electro-elasto and electro-optic properties and there is a tremendous need for further research bridging all the way from atom defects| nanoscale structure of domain walls| epitaxial stress and strain| to their order of magnitude impact on macroscale properties.The challenge is to combine ferromagnetism with ferroelectricity and then to couple ferromagnetism with ferroelectricity. In order to achieve this we need simultaneous room temperature ferroelectricity and ferromagnetism. Oxide perovskites are a remarkable family of materials that can be doped in order to provide a huge range of functions. Transitions from localised to itinerant electronic behaviour and from ferroelectric to anti FE states are determined by conflicting instabilities on an atomic scale. The Problem: A true multiferroic material is one where a single material| such as bismuth ferrite| exhibits multiferroic behaviour. The problem is that all true multiferroic materials possess insufficient coupling between phenomena to be useful for devices. The key properties are compromised when realised in a single material.The Solution: In this proposal we will make films of e.g. ferroelectric| ferromagnetic and piezoelectric material separately| but in close proximity in an artificial supercell. By doing this we can optimise the key properties of the single material but on a macroscopic scale ensure coupling between the materials to obtain good device performance.
The discovery and understanding of the reactivity of metal nanoparticles and their potential applications is slowly transforming our World due to their unique chemical and physical properties. However| their implementation is mainly limited by their tendency to agglomerate and sinter into bigger and more stable particles| losing their exceptional characteristics. The aim of this project is to stabilize metal nanoparticles using morphologically engineered supports overcoming the diffusion challenges faced by conventional stabilization approaches| specially relevant in catalytic applications. The potential of this new type of metal nanostructured catalyst will be explored in areas of green chemistry| environment and energy applications.
The construction of complex molecular frameworks underpins the future development of everything from new medicines to novel materials. The ability to make carbon-carbon bonds is key to this development. A number of the most used methods to carry out this bond forming reaction rely on the use of expensive| toxic and environmentally damaging transition-metal catalysts. 

This research programme aims to develop iron-based alternatives to the currently used methods and expand upon the scope and applicability of the current transformations. Iron catalysts offer the advantage of being inexpensive| non-toxic and environmentally benign and so are of great interest to the chemical community. Specifically| we will introduce a new carbon-carbon bond forming reaction with a concurrent reduction to produce fully saturated products (alkanes).
We will develop an apparatus for transferring quantum states from an ion to a photon and the other way around| in order to send the quantum information content to other| distant ions. This device will be a key building block of a so-called quantum network| which in the future will connect quantum computers like the internet does with present-day computers.Already today single quanta of light (photons) are used to transmit information securely over long distances| a process called quantum communication. The laws of quantum mechanics would foil any attempt of eavesdropping. Quantum effects can also be used to do computation. Researchers use single ions stored in linear traps to replace the bits in a classical computer. Operations on these quantum bits are performed with laser light. In our project we will combine the areas of quantum computation and quantum communication by building a user-controlled interface (a quantum link) between ions and photons. The transfer of quantum states from ions to photons requires that we strongly couple the two systems. We can achieve this by surrounding the ion with a cavity| enhancing its interaction with the photons. The conversion process from the ion-qubit to the photon-qubit will be steered with a suitable laser pulse applied to the ion. A photon will be generated with one of its properties (polarization) depending on the state of the ion. Interesting cases are those where the atom is in a superposition of two possible states. This is allowed in quantum mechanics. Our interface will make sure that the quantum state of the photon looks like that of the ion and will therefore have a superposition of polarizations. Even more interesting are the cases when the ion doesn't surrender all information on its original superposition state to the photon. The ion and the emitted photon will then be in a linked state| called entangled state| where the outcome of a measurement on the separate components is unpredictable| but combining the results of the two systems one always finds perfect correlation. Previously these states have been produced in a controlled way only in one place| while we will be able to distribute the entanglement to distant locations. This will be a major achievement of our project. We will also reverse the process and transfer the quantum state of an incoming photon to that of an ion in our cavity. Combining the two processes| we can transfer quantum states from one ion to a distant ion| or entangle their quantum states| with nothing in the process left to chance. This kind of entanglement is an important resource for performing efficient quantum computation in the future.To achieve our goals| we have to master two technologies: first we need to store a single ion in a very small region of space (less than 40 nm) for a long time (hours). This is possible with the help of a microscopic ion trap. The mirrors of the cavity surrounding the ion must be extremely good| allowing 200.000 reflections of the photon without loss. In addition| we must put the mirrors very close to the ion| to enhance the interaction between ion and photon. Combining the microscopic trap with a small mirror separation is the main experimental challenge of this project. The benefit is the development of a new quantum technology| linking quantum computing with quantum communication.
Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission| but may be because it included sensitive information such as personal details.
This proposal seeks support for a PDRA (one year)| Dr. Christophe Ladroue. The first goal is to develop and implement methods for statistical estimation and inference in the context of differential equations driven by rough paths (RDEs). Such differential equations are very general and can be used to model a large number of dynamical systems. Our motivation comes from multiscale modelling as we hope the approach we will develop could be useful for important applications| such as molecular dynamics or climate modelling. The second goal is to approximate the slow process of a multiscale stochastic differential equation (SDE) by an RDE at small scales. The final goal would be to use our parameter estimation methods to get some information about the limiting dynamics of the slow process using short paths of the multiscale system.
In the developed world most people are able to take the supply of safe clean drinking water for granted| most of the time. However water quality failures do occur and there are associated health risks. The analysis of water samples| taken at the customers tap by the UK Water Industry to meet regulatory requirements| has shown that for three consecutive years approximately 1 in every 200 samples failed to meet the standards for coliforms| an indicator of faecal contamination. The few epidemiologic studies in the area confirm that there is a problem and that it is related to the pipe infrastructure. This pipe infrastructure| used to deliver this basic human resource| is an extremely complicated mix of materials| pipe sizes and structures and appurtenances that are connected in a network| usually in loops| developed in a piecemeal manner over considerable time. This infrastructure is integral to our towns and cities and widespread replacement is unfeasible due to the associated costs and disruption. Whi1e there is existing knowledge and tools for understanding and making some predictions of the structural performance of these assets| the knowledge and applicable understanding of their water quality related performance is extremely poor.This system of buried infrastructure acts as a dynamic physical| microbiological and chemical reactor| with high surface area and with highly variable residence times. As a consequence there are a number of major and interacting physical and bio-chemical processes that degrade the quality of drinking water as it is transported. The situation is further complicated by the unknown| but deteriorating| internal condition of the infrastructure. This Challenging Engineering vision will enable the applicant to establish a world leading multidisciplinary team to derive new knowledge of the physical bio-chemical reactions and interactions occurring within water distribution systems| dominated by the aging infrastructure. The team will integrate across engineering and microbiological| chemical and computer science. Extensive use will be made of the latest instrumentation and measurement techniques from the different disciplines| applied to experimental studies on the internationally unique| 600m long temperature controlled pipe test loop facility at the University of Sheffield and ambitious live field trials with UK water companies (both areas of particular expertise of the applicant). The new understanding and knowledge gained will be applied to develop a suite of analysis and predictive tools to drive a paradigm shift in the way in which water distribution systems are operated| managed| rehabilitated and maintained for water quality with a move towards proactive management operating in near real time.The project is extremely ambitious| but presents the opportunity for the UK to establish an area of international expertise and to lead the world in an expanding research area of public interest and significance. The most apparent output will be superior water quality at least cost| consistent with the demands of an increasingly well informed society| leading to enhanced public health and well being. In the longer term| the multidisciplinary team will evolve by seeking to further develop the multidisciplinary approach for the even more complex environments of the complete urban water cycle and seek to stimulate further change for integrated| holistic and sustainable management across the cycle.
Many tissues in our bodies| such as cartilage| tendon and ligaments are loaded as we move around and the living cells in the tissues are able to detect the loading and alter their activity in response. This process is called mechanotransduction and is important as it keeps the tissues healthy and functioning properly. Damage to cartilage| tendon and ligaments can occurs as a result of injury or through diseases such as arthritis| resulting in pain and loss of function. In many cases the tissues are not able to repair well following damage| causing chronic pain. Until recently the only option for these patients may be a total joint replacement. This is not good solution for younger patients as most joint replacements will only last for 10-15 years before they need to be replaced. Over the past 15 years many groups worldwide have been developing an alternative solution| involving a process know as tissue engineering. Tissue engineering typically involves the creation of a new| functioning tissue in the laboratory| using the patient's own cells and a biomaterial scaffold. The new tissue can be implanted into the patient to repair the damage. As the new tissue will be loaded when implanted back into the patient is very important to understand how loading will affect the activity of the cells. Ideally the cells should respond to the load in a beneficial manner| so that normal exercise and activity improves the repair. In fact it may be beneficial to load the tissue in the laboratory before implantation| using devices known as bioreactors. Mechanotransduction is very complex and not well understood and so more research is needed to understand the process and ultimately to improve tissue engineering-based tissue repair.At Queen Mary University of London we have been studying with the ultimate aim of developing better tissue engineering-based repair systems for cartilage| tendons and ligaments for over 15 years. Our laboratory facilities are very good and we have brought together a team of researchers from many different backgrounds| including engineers| materials scientists| biologists and orthopaedic surgeons. In that time we have developed and we have achieved funding for many individual research projects that have been very successful. The Platform Grant will allow us to develop our research further and underpin our current activity. The funding will ensure that we can retain key members of our research group and perform high-risk pilot studies to improve our chance to gaining funding. We will also be able to improve our collaborative links with the leading groups world-wide who are involved in this type of research.
With the widespread use of small mobile computing devices like smartphones and tablets| power efficiency has become a very important design criterion for hardware manufacturers like Intel| AMD| Infineon| ST| Qualcom| Nvidia| etc. This is due to the limited energy storage capacity of mobile devices| imposed by constraints on their size and weight| as well as by problems of heat dissipation. Similar considerations of power efficiency apply to implanted medical devices| wearable computing| UAV (unmanned airborne vehicles)| satellites and sensor networks.

Since chip design has become more and more automated| electronic design automation companies consider energy efficiency as a prime concern in circuit design. However| so far| there has been hardly any use of formal mathematical methods in energy efficient circuit design. Instead| the main techniques used in practice were either based on simulation or on semi-formal approaches reasoning about patterns and structural properties. Typical work areas are the following:
1. Power estimation (based on simulation)| 
2. Power verification (of structural (i.e.| non-dynamic) properties)|
3. Power optimisation (coarse high-level reasoning about size and structural patterns)| and
4. Formal power verification (model checking applied to coarse abstractions based on activation/deactivation of blocks on the chip).

In this project| we bring modern formal mathematical methods into automated circuit design. This yields a new domain of

&quot;5. Formal power optimisation&quot;.

Here| efficient circuit design is achieved via solving the controller synthesis problem. This is to construct a controller that achieves (in every context) a combination of several objectives: 
(a) the functional correctness of the induced behaviour| as specified in the requirements specification| 
(b) a guaranteed limit on the peak energy consumption (i.e.| an upper bound on the worst case)| and
(c) a low average energy consumption.
While (a) and (b) are absolute constraints| the relative quality of the controller is measured in terms of how well it achieves objective (c).
 
We solve the synthesis problem by applying modern mathematical techniques and tools from game theory (energy games| mean-payoff games)| formal software verification (formal requirements specification and automata)| and logic and algorithms (SAT and SMT solvers). Beyond theoretical advances and new techniques for the synthesis of energy efficient controllers| the project aims for practical application of controller synthesis in the new field of Formal Power Optimisation in circuit design. A prototype of a software tool that implements the new methods and applies them to power optimization in chip design will be evaluated on case studies provided by our industrial project partner Atrenta Inc.
It is now widely accepted that the world's increasing reliance on fossil fuels over recent centuries is causing drastic changes in the Earth's climate. Renewable energy technologies - such as solar| wind and wave energy - offer a pathway for the generation of clean energy. This project concerns photovoltaic (PV) technology - the conversion of sunlight to electricity - and| in particular| involves the application of luminescent materials to PV modules. Shipments of PV modules have been increasing at a steady rate of 45% per annum since 1999| however a shortfall in silicon feedstock supplies - the material used to fabricate nearly 95% of today's solar cells - is expected to continue for the next few years| This is significant as the cost of the solar cells makes up 70% of the final cost of a PV module. New technologies are therefore extremely important to satisfy the exponential demand for PV products| This project pursues an alternative PV technology called the luminescent solar concentrator (LSC). The primary advantage of this technology is reduced cost since large areas of silicon solar cells are replaced with cheap plastic sheets. The trick to the new technology involves fluorescent dyes embedded in the plastic sheet. These dyes absorb sunlight that is incident on the sheet and then re-emit this light such that 75% of the light is trapped within the plastic sheet and is reflected to the edges of the sheet| which then appear very bright. This concentrated light is converted to electricity by then placing solar cells along the perimeter of the sheet. Thus| the LSC technology can be envisaged as being an electricity-generating window . Because the light is concentrated at the edge of the sheet| only a fraction of solar cells are required to cover this area resulting in large cost savings. Further advantages of the LSC technology are: - That existing high-efficiency silicon solar cells can be used| similar to those that are commercially produced today| meaning that valuable research time and funding does not need to go into developing a new solar cell. - The LSC module does not have to track the path of the sun across the sky in order to concentrate the light| as is required with other lens and mirror-based solar concentrating systems. In addition| the LSC is equally efficient on cloudy days making it a very relevant PV technology for the majority of Europe - something that cannot be achieved with traditional solar concentrating systems.- The LSC technology is ideally suited for integration into buildings (building integrated photovoltaics| BIPV)|due to i) its ability to act as an electrically active window| ii) being able to adjust the colour of the LSC module to give an appealing appearance. Before the technology can be realised| the performance of the LSC system needs to be significantly improved| with the current LSC world-record conversion efficiency standing at 3.2%. This research proposal brings together an interdisciplinary team comprised of PV engineers and chemists. Novel dyes will be fabricated that will enable the LSC to achieve two new results. Firstly| dyes will be developed that can absorb solar wavelengths of 600 - 900nm| a large part of the solar spectrum that current dyes cannot efficiently concentrate. Secondly| controlling the light emission from dye will allow the light to be directed towards the concentrator edge rather than being emitted in random directions such that a percentage is lost through the faces of the plastic sheet. This would result in all the luminescence reaching the edge of the LSC giving a 25% boost in performance. Initial modelling results indicate that conversion efficiencies of up to 11% could be realisable if both of these strategies are successful and can be integrated together.
Despite of the fact that electrical cars are under development and have the potential to provide alternatives for short distance light duty transport| the internal combustion engine will continue to be the main power unit in vehicles for several decades to come. Compared with extensive research on combustion and after-treatment systems| little work has been completed with respect to engine system control optimisation| leaving considerable room to improve fuel economy and lower emissions. Current engine calibration process relies on deriving static tabular relationships and the corresponding values between each calibrated engine operating point| with closed-loop feedback control to adjust the settings accordingly for air-fuel ratio control in real engine operation so as to meet the performance targets and emissions legislation. Such a widely adopted method| however| is not efficient in achieving the best fuel economy of the vehicle due to the constraints in the time duration and cost of engine-bed based calibration. Environmental conditions changes| the time required for the closed-loop control to respond| cycle-by-cycle variations| and cylinder-to-cylinder variations make the current engine control impossible to handle the the optimisation of the engine functionalities.
 
The development trend for future engines is towards an on-board intelligence for control and calibration and some research activities for the development of model based control systems are reported in literature. However| feasible strategies to control the engine operation cycle-by-cycle and cylinder-by-cylinder are not yet available. 

Expanding the work of the applicants in the related areas for many years| the overall Goal of this project is to use a combination of joint efforts from 3 research groups with expertise of engine technology| control technology and computing algorithm in order to develop and test a new engine control and calibration methodology with on-line intelligence built in. This overall goal will be achieved through realising the following objectives:

(1) To develop a full real-time multi-cylinder engine model for cylinder-resolved-control purpose
(2) To develop a novel engine control strategy involving optimization of control points and control point locations| and multi-objective evaluation of test cycle performance
(3) To develop dynamic multi-objective evolutionary algorithms for online engine control optimization
(4) To demonstrate the implementation of the engine control models initially on Hardware-in-the-Loop (HIL) dSPACE system and then further rapid prototyping on a test engine.
(5) To compare the engine performance using the new techniques with traditional calibration and control approaches| and demonstrate improvements in terms of engine output| fuel consumption| and emissions.
 
The new engine control methodology will be evaluated on a new Jaguar gasoline direct injection (GDI) engine model.
This project addresses the TSB criteria novel approaches to address pests| diseases| disease vectors and weeds and development of durable pest-and disease-resistant crop varieties . We will deliver more effective control of a serious and problematic pathogen of barley through understanding its entire life cycle| rather than just the visible disease syptoms which have been used previously to identify infection. The project will use new knowledge about the symptomless rhynchosporium infection of barley to develop new varieties that are more durable to rhynchosporium infection and therefore protected against yield loss to this pathogen. Various sources of host plant resistance will be assessed for efficacy so that the best ones are prioritised. The introgression of an alien resistance gene offers the opportunity of introducing a novel resistance mechanism that| backed up by the marker tools and ability to pyramid with other durable resistance genes| will enjoy a much greater useful variety lifespan in widespread use. Novel molecular and microscopy methods using tagged pathogen isolates will be used to generate knowledge of resistance mechanisms so that appropriate combinations of natural resistance sources can be brought together in optimum combinations. The project will also help develop crop protection strategies which are strategically well directed for increased yield response and risk reduction. Their enhanced effectiveness will be based on an understanding of the way different resistance genes in varieties work and using appropriate fungicides in more intelligent| integrated programmes. The proposal therefore represents a novel approach to both breeding for durable resistance and more effective crop protection with existing chemicals| whilst informing discovery strategies. The durable resistance sources will be developed in new barley varieties and overall we will deliver more effective control of a serious and problematic pathogen of barley through understanding its entire lifecycle rather than just the visible symptoms which have been used previously.
Silicon Photonics is poised to transform photonics in applications ranging from intra and inter-chip interconnect to lab on a chip; from consumer products to Fibre to the Home transceivers; from high performance computing interconnect to environmental sensing. In other words silicon will bring photonics to mass markets. Despite significant progress recently| in order to successfully transform photonics in this way| several key research challenges still need to be overcome. In this programme we will tackle all of these research challenges| and in so doing we will do nothing less than facilitate a revolution in low cost photonics| placing the UK at its centre. 

To succeed in mass markets silicon photonics requires (i) a low cost method of comprehensively testing at the wafer scale; (ii) a passive alignment coupling technique from fibre to optical chip; (iii) a means of scaling the functionality of the photonic circuit; (iv) very low power| high data rate modulators; and (v) low cost integrated lasers on chip. To date there are no satisfactory solutions for any of these issues| but this programme will find solutions for them all.

We have a technical advantage in all aspects of the work due either to previous projects in which we have produced the best silicon modulators in the world today| as well as the first erasable silicon Bragg gratings; or due to preparatory work that we have carried out in advance of this project in which we have carried out modelling and even some preparatory experimentation on dual layer photonics| passive alignment of fibres to silicon photonics circuits. In the case of low cost integrated lasers| we have previous experience within a European project| and we are also working with an international collaborator from KAIST| Korea| with whom we jointly have a technical lead in the area.

To maximise the impact of our work| we will produce proof-of-concept demonstrators towards the end of the programme| that showcase the research achievements to all stakeholders within the UK| an approach that has attracted key industrial partners to the programme as they recognise both the transformative work that will be done| and the opportunity to contribute to the work and influence its direction and impact. The importance of our proposed programme has already been recognised internationally as we have been asked in a letter of support from Professor Kimerling at MIT| to report annually to the USA industry forum| co-ordinated by MIT| giving tremendous exposure for UK supported work. 

In letters of support the proposed work has been endorsed as essential by leaders in the field from around the world at MIT| Intel| Tokyo University| and Paris-Sud University| as well as photonics leaders from within the UK engaged in other programme grants (Seeds (UCL)| Penty (Cambridge)| Zayats (Kings)| Dawson (Strathclyde)| Payne and Zheludev (both Southampton)| and UK industry (Oclaro| Sharp| Wentworth). 

Within the programme| we have 4 UK industrial partners (Oclaro| Wentworth Laboratories| Sharp Laboraties of Europe| and Intel)| 4 international academic partners (KAIST| MIT| University of Tokyo| and Paris Sud)| as well as numerous offers of support and collaboration from academic institutions within the UK. Our collaborators have pledged ~&pound;500|000 of in-kind support to the programme.
The age of Ubiquitous Computing is approaching fast: most people in the UK over the age of 8 carry mobile phones| which are becoming increasingly sophisticated interactive computing devices. Location-based services are also increasing in popularity and sophistication. There are many tracking and monitoring devices being developed that have a range of potential applications| from supporting mobile learning to remote health monitoring of the elderly and chronically ill. However| do users actually understand how much of their personal information is being shared with others? In a recently released report from the UK Information Commissioner| we were warned that the UK in particular is 'sleepwalking into a surveillance society'| as ordinary members of the public give up vast amounts of personal information with no significant personal or societal advantage gained. In general| there will be a trade off between usefulness of disclosing private information and the risk of it being misused. This project will investigate techniques for protecting the private information typically generated from ubiquitous computing applications from malicious or accidental misuse.The project will investigate privacy requirements across the general population for a specific set of ubiquitous computing technologies. These requirements will be used to produce a Privacy Rights Management (PRM) framework that enables users to specify privacy preferences| to help visualize them| to learn from the user's behaviour what their likely preferences are| and to enforce privacy policies. We will make use of a large cohort of over 1000 OU students with a broad range of ages and backgrounds| both for identifying requirements and for evaluating tools for privacy management. This work will address a number of research issues:* how do people perceive privacy in ubiquitous systems?* what types of privacy controls would people like to have when using ubiquitous systems?* how to develop privacy control tools that are easy to use via simple interfaces (e.g. mobile phones) as well as large screen devices?* how to detect and resolve inconsistencies in users' privacy requirements?* what mechanisms can be used to automate privacy control in ubiquitous systems?The PRM framework we produce to address these issues will integrate users' privacy policies with their personal information to control how information is used. This is analogous to Digital Rights Management (DRM)| which often incorporates information such as 'digital watermarks' in the data being protected or encapsulates the data such that it is self protecting. By providing an analysis and learning system within the framework| we believe that we can produce a usable system that does not burden users with complex privacy rule sets. The project relates to the Memories for Life and Ubiquitous Computing Grand Challenges| both of which raise issues relating to PRM in mobile applications.
The aim of this proposal is to expand the capability base that solid state NMR community has at its disposal so that more materials and chemistry systems can be effectively studied with this technique. Solid state NMR usually confines itself to the study of diamagnetic materials and compounds; i.e. systems that do not possess unpaired electrons in their electronic structure. Many modern materials and chemical systems being developed possess transition metals and/or rare earth species as part of the elemental composition; these introduce unpaired electrons into these systems and thus promote paramagnetic characteristics which are incompatible with the conventional NMR methodology. Our traditional mindset of how we approach the typical NMR measurement needs to be adjusted as our typical drive to higher external magnetic field strengths is counterproductive in this case. The electron polarisation that gives rise to paramagnetic anisotropies and shifts scales linearly with magnetic field| and these effects greatly detract from conventional NMR data thus masking the information that is normally sought. Severe cases of paramagnetism can preclude the NMR measurement of some systems completely.

The most direct way to address this solid state NMR challenge is to attempt measurements in a much reduced (rather than increased) magnetic field| and to spin the sample at very high MAS frequencies. This low field/fast MAS methodology maximises the chance for NMR data to be elucidated from these systems| however these types of NMR spectrometers are very rare commodities worldwide. While many thousand NMR instruments exist throughout the world at fields of 7.05 T (300 MHz for 1H) and above| only a handful of operational low field spectrometers exist to undertake these type of measurements; furthermore| the UK is not well catered for in this field of spectroscopy apart from very limited proof-of-concept pilot studies that have demonstrated this idea. This new capability will be as easy to operate as conventional solid state NMR instrumentation and no specific additional training is required to enable its usage for data acquisition. The impact of this methodology is expected to influence the fields of catalysis and energy materials (battery materials| solid oxide and H conduction fuel cells| hydrogen storage materials| supported metal nanoparticles systems| zeolites| nuclear waste glasses etc.)| general organometallc and inorganic chemistry| and the emerging field of medical engineering (rare earth doped biomaterials for oncology and blood vessel growth stimulation applications). It is also expected that this methodology will bridge across to established techniques such as EPR| and emerging technologies such as DNP| both of which employ different strategies for the manipulation of the paramagnetic interaction. These relationships are expected to stimulate a more vibrant magnetic resonance community that will be capable of collaboratively tackling the challenging research issues that confront the UK. Academic collaborators at Cambridge| Birmingham| Imperial| Queen Mary| Kent| UCL and Lancaster| and industrial partners such as Johnson Matthey and Unilever are all acutely aware of these new solid state NMR possibilities and flexibility that this methodology offers| and they eagerly await the improvements to the measurement technology that a low field/fast MAS combination can offer.

The specific objectives that shape this proposal are:

(a) to deliver a shared low-field/fast MAS solid state NMR resource to the UK magnetic resonance community that will augment the current UK suite of solid state NMR instrumentation in existence|

(b) to put in place a state-of-the-art solid state NMR console and appropriate fast MAS probe technology capable of delivering the most modern experiments|

(c) to align this methodology with established characterisation technologies such as EPR and emerging experimental initiatives such as DNP.
Manchester Centre for Mesoscience &amp; Nanotechnoly (CMN) is an active and successful facility which provides its users with a full range of microfabrication equipment needed to make and characterise structures and devices less than a micron in size. These include thin film deposition| scanning electron microscopy| scanning probe microscopy| photo- and electron-beam lithography| reactive plasma etching| microprobe testing and so on. Among CMN's facilities| electron-beam lithography occupies a special place: it is absolutely essential for making devices with minimal features between 10 and 100 nm and is a cornerstone of our success. Electron-beam lithography is a complex and expensive machine that has to be run by an experienced operator with a PhD. He/she ensures a continuous supply of innovative samples and devices made by e-beam lithography combined with other microfabrication techniques| trains PhD students| postdocs and other CMN users in clean-room technologies and also looks after the expensive equipment. Since the establishment of the Centre in 2002| a number of ambitious research projects at the CMN (graphene based electronics| mesoscopic superconductivity| plasmonic nano-optics| nanomagnetism| etc.) have been heavily reliant on the permanent presence at the CMN of such a highly skilled operator. A typical research project requires only 10 to 20% of the operator's time and| accordingly| the person is supported by small shares from many individual projects. As a result| the operator has to be employed on the basis of a long string of few-months contracts| which is obviously unattractive in term of future prospects and career development. At the same time| there is an acute shortage of experienced people capable of operating electron-beam lithography and other microfabrication equipment. Even though we have previously secured many years of continuous funding to keep this position going| it proved to be extremely difficult to employ and retain a high-quality person| as people are understandably unhappy about the lack of permanency. The requested platform funding would allow us to employ such a person on a permanent basis. It would also safeguard PhD training in electron-beam lithography and other clean-room technologies| which equips students with skills highly sought after by industry but very expensive to teach. Finally| it will serve as a cushion for some of our more adventurous projects and allow access to the CMN for newly-appointed staff without a track-record in microfabrication-based research.
Airbus's aim to reduce fuel burn per passenger km by at least 50% by 2020 will be difficult to achieve without a 30 to 50% reduction in skin-friction drag / the drag arising from the friction generated on the aircraft's surface by the direct action of the air flow. We propose| therefore| to investigate novel| practical| effective flow-control techniques for achieving this aim.Skin-friction drag in turbulent boundary layers is governed by the flow physics very close to the surface in a region of the flow field known as the viscous sublayer. The generation of wall friction is also known to be quasi-cyclic. An essential characteristic of this cycle and the near-wall flow physics are streaks of low- and high-speed flow and their strong interaction with wave-like disturbances. The resulting evolution of the streaks and their explosive growth are intimately connected with the generation of wall friction and thereby drag.Most researchers focus on these sublayer streaks because they are very closest to the wall and amenable to wall-based actuation and sensing. We estimate| however| that there are O(109) sublayer streaks over the fuselage of an Airbus A340-300 at any instant during cruise. Others have made similar estimates. This enormous number makes it utterly impractical to implement an active control strategy targeting streaks individually. But disrupting the cycle in a global untargeted way is feasible. Riblets (minute peaks and troughs running in the flow direction with crossflow spacing of about 1/3 of a human hair width) do this by disrupting streak growth| in effect by regularizing and partially stabilizing them. But conventional riblets only deliver less than 1.5% drag reduction in flight tests| although 6% is achieved in idealized laboratory experiments. Unless this poor performance can be greatly improved| riblets are of little practical interest. Spanwise oscillations have been studied recently and shown to be much more effective than riblets at reducing skin-friction drag. Again these appear to work by forcing the streaks into more stable orientations. But this technique requires substantial power input. Given the cyclic process described above| another option is to disrupt the interaction of the waves and streaks with randomized perturbations. This was tried by Sirovich et al. who obtained 12% drag reduction in experimental flow studies with randomized surface roughness elements. This approach has not really been further investigated| although disrupting the wave-streak interaction with randomized perturbations is likely to be much more effective than riblets.We propose to investigate: (i) the use of randomized distributions of small-scale Helmholtz resonators that create strong microjets without any power input; thus are likely to be more effective than roughness elements or riblets; (ii) conventional riblets localize the streaks| thus combining them with resonators could be much more effective than riblets alone; (iii) improving effectiveness with unconventional riblets; e.g.| wavy riblets mimicking spanwise oscillations and other 3D patterns. Our study will be based on our simplified theoretical model of the sublayer streaks which can be used at flight Reynolds number. Helmholtz resonators hold great promise as passive control devices because: (i) the control disturbance produced is proportionately much greater than for roughness elements| including riblets; (ii) they require no power input; and (iii) consisting simply of a cavity with a necked exit orifice| they are straightforward to manufacture at MEMS (micro) scale.
This is a proposal for a programme of short courses designed to provide an advanced training programme for High Performance Computing (HPC) that is both rigorous and wide ranging. The programme is designed as a partnership with PhD supervisors| freeing the supervisor to focus on the more discipline-specific aspects of their student's training. We will provide three types of activity: (1) an annual 2-week residential course (Autumn Academy) designed to allow students to start working with HPC code right from the start of their PhD; (2) A rolling 2-year programme of short residential courses on more specialised topics and that builds from the base provided by the Autumn Academy; and (3) a programme of half- or one-day events| using Access Grid technology where possible| designed to broaden the student's background in HPC related issues while also helping them to form networks with their peers. The proposed training programme is built firmly on the very considerable experience of the applicants and their 13 institutions in HPC training.
Over the past year or so there has been a revolution in X-ray science| in that new sources of soft and hard X-rays have been developed that are ten billion times brighter than those produced by synchrotrons. These novel sources emit extremely short (sub 100fsec) pulses of x-rays| and can be focussed to very small spots. As the pulses are so short| the power in the light is enormous - for the brief duration of the emission the power in the light is equivalent to that in a fair-sized electrical power station. When all this power is focussed to a small spot| enormous intensities of x-rays impinge upon the target in its path - intensities that have hitherto never been produced in the X-ray regime. In the last few months we have performed some of the first experiments aimed at understanding how matter reacts to such intense X-ray light| and the aim of this proposal is to vastly further that understanding. What we have already found is that the intensity is so great that an electron from every atom in the target can be knocked out by the X-rays| and this can alter the X-ray properties of the material itself - indeed| by this method we have made a so-called saturable absorber. What is of fundamental interest to us is that as the electrons re-fill the core holes| they provide information about the electronic structure of this exotic and highly-ionized state| providing completely new insight into the physics of very dense| yet very hot material. This material (warm dense matter) is of interest in that the thermal energies and electronic energies (the coulomb potential) are comparable| making its properties extremely difficult to calclulate. This situation - where the thermal and coulombic energies compete - also occurs in the initial stages of inertial confinement fusion| and is also part of the physics that is relevant to the understanding of the interior of the giant planets - thus there are many reasons for wishing to understand it better. The intense X-rays give a unique opportunity to understand such matter| as within femtoseconds they make a particular state - very hot electrons but cold ions| at a well defined density. Watching this state evolve ( by looking at the fluorescence| and monitoring the absorption as a function of time) gives detailed information on the electronic structure. For example| with highly ionized aluminium| we have an unusual situation at the highest intensities where a particular aluminium ion that undergoes recombination is now doing so with neighbours that themselves are still ionized. This drastically alters the shape of the fluorescence emission in a way which has much to do with how the fluorescence signal from an alloy is altered as the compound composition changes. Thus this research will provide unique insight into the electronic structure of matter at hundreds of thousands of degrees kelvin| yet still at solid density.
Nuclear magnetic resonance (NMR) is a versatile analytical tool with applications ranging from basic physics to medicine. In its imaging mode| MRI| it provides information on anatomy| metabolism and biological functions. However| NMR has low sensitivity| making many of its uses difficult and others impossible without some form of signal enhancement. For example| metabolic imaging of human cancer by MRI was only made possible by the recent introduction of nuclear spin hyperpolarisation methods. Among these methods| dissolution dynamic nuclear polarisation (dDNP - central to this proposal) prepare a very high degree of nuclear spin polarisation that can increase the signal-to-noise ratio up to 10|000 times. However| despite this enormous enhancement| in-vivo applications remain on the borderline of feasibility because of the relatively short lifetime of the enhanced polarisation. For example| the spatial resolution of hyperpolarised MRI images of cancer metabolism is compromised by the loss of signal during transport and purification of the hyperpolarised material. Improvements to post-hyperpolarisation protocols| allowing transport of hyperpolarised material| would therefore improve emerging techniques and open up new areas of research and applications. 

The proposed research will address three interconnected main obstacles: the lack of purity of the hyperpolarised material (electron radicals are required by the hyperpolarisation technique); the limited lifetime of hyperpolarised magnetisation (the presence of radicals and many other intrinsic factors make nuclear spin polarisation to decay over time| a mechanism know as spin relaxation); the limited mobility of the polarising equipment (dissolution-DNP equipment is expensive and bulky and the limited lifetime of the hyperpolarised agents makes it impossible to transport the agent for significant distances. The point-of-use is therefore confined to the near vicinity of the point-of-production).

In order to overcome these obstacles we will use supercritical-CO2 chromatography to rapidly and efficiently purify the hyperpolarised material. Because spin polarisation storage times are roughly inversely proportional to viscosity| and because supercritical-CO2 has a viscosity 10-30 times lower than that of conventional solvents| we will also store the purified material under supercritical-CO2| potentially extending the length of storage time by 5-10 times. We will then explore extending storage time further by using long-lived states and by freezing the hyperpolarised solution under liquid nitrogen| freezing molecular motion and therefore minimising relaxation losses. We aim to extend storage of hyperpolarised material to over two hours| increasing distance between the point-of-production and the point-of-use. We also intend to build a convenient and portable transport device to enable transport of hyperpolarised material over long distances (as allowed by maximum lifetime achieved) with loss of no more than 50% of polarisation.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
The proliferation of software across all aspects of our life means that software failure can have significant economic and social impact. It is therefore highly desirable to be able to develop software that is formally verified as correct with respect to its expected specification. This has also been identified as a key objective in one of the UK Grand Challenges (GC6). Although research on formal verification has a long history| dating back to the 1960's| it remains a challenging problem to automatically verify programs written in mainstream imperative languages such as C| C++| C# and Java. This is in part due to the prolific use of (recursive) shared mutable data structures which are difficult to keep track of statically and in a precise and concise way.The emergence of separation logic promotes scalable reasoning via explicit separation of structural properties over the memory heap where recursive data structures are dynamically allocated. Using separation logic| progress has recently been made on automated verification for pointer safety in the separation/shape domain. To verify the more general memory safety and functional correctness| it will require the combination of both separation (structural) and numerical (e.g. size) information. Therefore| advanced analysis and verification techniques are needed in the combined separation and numerical domain to verify memory safety and functional correctness. Nevertheless| this remains a clear challenge for program analysis research.As a first step to tackle the challenge| Our recent development on program verification using a combined separation and numerical domain also allows user-specified inductive predicates to appear in program specifications for better expressivity. Based on this specification mechanism| a verification system called HIP/SLEEK has been built to conduct the automated verification and proof search. Our experimental results have confirmed the viability of this approach. One issue with the current system is that it is a liability for the users to supply all loop invariants and method pre/post-conditions prior to the verification. This can be very demanding and challenging for the users.As the second phase towards tackling the challenge| we propose to develop advanced inference mechanisms in the combined separation and numerical domain with user-defined predicates so that loop invariants and method pre/post-conditions can be automatically synthesised| where possible. Achieving this goal means that a much higher level of automation will be achieved| therefore a significant advance will be made in automated verification on memory safety and functional correctness.A key objective in the proposed research is to find a systematic approach to abstraction construction in the combined domain| so that appropriate abstractions can be employed by the inference process. Abstractions are required in the analysis and verification for various reasons| such as termination and scalability. Appropriate abstraction mechanisms are crucial in maintaining a desirable scalability/precision trade-off. Apart from the abstraction mechanisms| we also intend to design analysis algorithms for loop invariant synthesis| method post-condition inference and method pre-condition discovery for the combined domain with arbitrary user-defined predicates. We will build a tool to implement these analyses and apply it to sizeable benchmark programs. As a challenging example| we will apply our tool for the verification of memory safety of a Linux kernel. Such a sizeable program can well be used to test the limit of our inference mechanisms. We believe our research outcomes will further improve the level of automation| and therefore significantly extend the viability and applicability of automated verification on memory safety as well as functional correctness for substantial imperative programs.
Mark Weiser's vision of ubiquitous computing| in which computers become transparently and seamlessly woven into the many activities of our daily lives| is slowly becoming a reality. Researchers have created prototype ubiquitous computing environments such as 'smart homes' that can automatically sense the presence of a resident in a particular room and change some aspect of the environment of the room such as turning on the lights| or 'smart museums' that can play recorded information about the museum artefact a visitor is standing in front of. There seem to be limitless possibilities for the kinds of environments and applications that can be developed for ubiquitous computing| yet the very nature of ubiquitous computing creates new and significant challenges for engineers who would like to build these environments and applications. Anybody who has ever used a computer has experienced the extreme frustration of using a software package that doesn't work the way it's supposed to| or that unceremoniously crashes in the middle of its operation| or that runs extremely slowly| or that transmits sensitive information such as credit card numbers over untrusted networks. For ubiquitous computing to achieve true transparent and seamless integration with its surroundings| it is important to prevent such mishaps| crashes| inefficiencies and insecurities from happening to the greatest extent possible. This project will define and implement a suite of sound| systematic methods that engineers can use to create correctly functioning| efficient and secure ubiquitous computing environments and applications. The research will be conducted and evaluated using the smart urban spaces and applications being developed in another ubiquitous computing project called Cityware.
The reduction of skin-friction drag even by a few percent in the transportation and energy generation sectors translates directly to reductions in fuel consumption and emissions| the need for which is now almost universally accepted. Consequently| in the last two decades| a whole range of Drag Reduction (DR) strategies has been proposed| but many of these have been tested and validated in fully-developed internal flows (i.e. pipe or channel flows) where there is no development of the flow along the streamwise direction. Therefore| the flow reaches an equilibrium with the wall condition and the potential for large drag reductions has been reported. However| almost all practical applications involve external flows where a turbulent boundary layer (TBL) will grow along the streamwise direction| such that it exhibits non-equilibrium behaviour as it continuously adjusts to the prescribed wall condition. More importantly| there could be significant potential benefits in exploiting non-equilibrium behaviour where only parts of the developing flow are affected. Therefore| it is of fundamental importance to examine non-equilibrium effects not only to understand the limitations of implementing a drag reduction strategy but also to exploit any practical benefits.

In this collaborative project| we explore the fundamental problem of non-equilibrium effects on wall-turbulence by examining the effects of two different types of non-equilibrium wall condition: (1) change in surface roughness and (2) change in the characteristics of a harmonically-varying in-plane surface wave. The surface roughness is a passive boundary condition and may locally increase surface shear stress while the in-plane surface wave is an active boundary condition. Both sets of experiments introduce non-equilibrium effects that will alter the development of skin-friction behaviour depending on the nature of the surface change. Crucially| both can reduce the local surface shear stress under specific conditions. By examining the two in parallel and comparing the response of a turbulent boundary layer to these different boundary conditions| we will provide new insights on the scaling and the adjustment of the boundary layers to these non-equilibrium effects. This is very much within the spirit of Clauser's &quot;black box&quot; analogy - the perturbation of an unknown system and the assessment of the response| here| with the added motivation of identifying the drag-altering behaviour.
The focus of this application is an aspect of nanoscience| the latter being defined as that area of science concerned with materials of dimensions of less than 1 micron. In fact we are working in the ultra-nano regime involving structures typically between 1-10nm in size (0.001 to 0.01 microns). Nanoscience and technology are extremely important for the current and future well-being of our country because increased miniaturisation of devices down to the nanosize regime offers benefits of reduced usage of raw materials in constructing devices| which is therefore beneficial to the environment and is a step towards sustainability of technology. We already make use of nanotechnology in a wide range of ways in everyday life - from cosmetics to electronic devices| from medicine to the fuel in our cars. The latter derives from the use of catalysts containing tiny Pt particles of only ~3nm diameter. It is the surface reactivity of nanoparticles and the relevance of nanoscience to catalysis| that is the focus of this application. In particular it concerns the fabrication| characterisation and reactivity of nanosized FeMo oxide particles which may be used for the selective oxidation of methanol to produce formaldehyde.The production of formaldehyde is a major global business and technology| since formaldehyde is used in a wide range of products from the worktops and flooring which cover our kitchens| and even to embalming fluid for preserving dead bodies (ie we use it from cradle to grave)! Its production involves reacting oxygen with methanol using a catalyst| the latter enables the reaction to proceed in a more environmentally-friendly way| using lower energy (lower temperature) and producing less by-products| than would otherwise be the case for a non-catalysed process. However| this kind of catalysis is called selective oxidation| and in all cases CO2 and water are also produced. Production of these means a loss of economic efficiency for the process| but perhaps more importantly it results in an additional CO2 burden to the atmosphere with negative consequences for global warming. Thus it is important to make all such processes more efficient and more selective| including the one we are considering here. Current processes work at about 95% selectivity| which means that about 350|000 tonnes per year of CO2 are emitted to the atmosphere| approximately equivalent to the emissions from 100|000 cars. Thus an improvement of selectivity of only 1%| will result in a saving of 20|000 cars equivalent of CO2 burden on the atmosphere globally. An important enabler to reduce these emissions is to understand the nature of the catalysis and the FeMo catalyst involved| because from that basis of knowledge we can engineer the material to be more efficient. The aim of the work proposed here is to make well-defined particles of iron molybdate on the surface of an iron oxide crystal FOR THE FIRST TIME. We use the latter to induce crystallographic order on the iron molybdate formed on its surface| and in this way to make models of iron molybdate catalysts. We will use the relatively new technique of scanning tunnelling microscopy to image the surface structure of the iron oxide and iron molybdate crystals. The important point about STM is that it is capable of atomic resolution| thereby enabling us the DIRECTLY identify the atomic structures and sites for molecule adsorption at the surface. We will combine this structural technique with the use of XPS (X-ray Photoelectron Spectroscopy) which is an analytical technique to tell us how much of each of the three elements (Fe| Mo| O) is present AT THE SURFACE. We will then go on to identify the nature of the reactive centre at the surface| something which is currently unknown; will methanol bind to Fe centres| Mo centres or defects in the surface layer (e.g. missing oxygens)? From knowledge of the active site we anticipate the ability to use that knowledge to tailor more efficient catalysts.
The aim of this proposal is to develop novel high performance| nanocomposite feed materials for Additive Manufacturing (AM). The field of AM| also known also as 3D Printing| has expanded significantly over the last couple of decades across virtually all-industrial sectors due a number of key advantages that traditional manufacturing just cannot offer. These include mass customisation| geometrical complexity| tool-less manufacture and sustainable manufacturing. Among the companies using AM are GE (medical devices| and home appliance parts)| Lockheed Martin and Boeing (aerospace and defense)| Invisalign (dental devices) and LUXeXcel (lenses for light-emitting diodes| or LEDs). The worldwide revenue from 3D printing is expected to grow from $3.07 billion in 2013 to $12.8 billion by 2018| and exceed $21 billion by 2020| and has a potential of generating an economic impact of $230 billion to $550 billion per year by 2025. 

While the forecast for AM products is huge this will only be achieved if we can actually manufacture parts with the desired properties. The majority of polymeric AM research is however focused on low glass transition temperature (Tg) polymers such as Polyamide 11| 12 | Polycarbonate and Poly Lactic acid (PLA)| due to their good processing characteristics (rheological| thermal and crystallization). For advanced| high value applications in aerospace| telecommunication and defense where harsh environmental conditions often exist (and in some key biomedical application) these low Tg polymers for AM are not acceptable so there is a real need to develop materials for these applications. Whilst a sufficiently high Tg polymer could offer the required high performance| nanocomposites with increased functionalities and potential combinations of properties such as high stiffness| strength| wear and specific thermal| electrical and microwave response can really transform the performance of AM components. The ability to manipulate other properties| such as rheological and thermal performance| by the addition of nanoparticles offers further potential advantages in terms of processing characteristics. 

This proposal will examine the potential of inorganic fullerene-like (IF) tungsten disulfide (WS2) or IF-WS2 as nanofillers for high value| PAEK (Poly Aryl Ether Ketone) based products made via the AM processes of Selective Laser Sintering (SLS) and Fused Deposition Modelling (FDM). The incorporation of IF particles has been shown to be efficient for improving thermal| mechanical and tribological properties of various thermoplastic polymers| such as polypropylene| nylon-6| poly(phenylene sulfide)| poly(ether ether ketone). These nanocomposites were fabricated by simple melt-processing routes without the need for modifiers or surfactants . IF-WS2 have been proven to exhibit extremely high tribological performance in composites to reduce wear and coefficient of friction .These characteristics will also have important processability benefits for AM processes as will their dispersion characteristics which are superior to 1D and 2D nanoparticles. They are also the best shock absorbing cage structures known to mankind. Importantly| they are non-toxic| and thermally stable. 

We will examine the two main AM processes for producing parts with engineering properties| Selective Laser Sintering (SLS) in which a laser is used to melt and sinter powdered polymer into the final part and Fused Deposition Modelling (FDM) in which a polymer filament is melted in a heated nozzle and deposited in the required pattern to form the part.
Site directed modification by both homogeneous glycosylation and pegylation has hitherto been unavailable in drug development and offers a major innovative advance to patients and carers alike. Such control of protein modifications by this consortium will for the first time bring the opportunity for clear structural control to produce the maximum therapeutic effect required. The consortium will use the additional funding provided by a successful application to develop better therapeutic glycoproteins. The expression of aglycosyl proteins in high yielding yeast systems will provide the protein backbone from which novel synthetic glycoproteins will be constructed. Synthetic glycans will be used to improve glycosylation and enhance pharmacokinetic properties. The application of a novel targeted pegylation technology will improve uniformity of pegylation as well as improve protein potency.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
During the past decades our theoretical understanding of the physical properties of liquids has been transformed by the synergy of theory and numerical simulation. By comparison| our understanding of the properties of granular packings is still at a much less advanced stage| not least because of a lack of hard numerical data for a key quantity: the packing entropy. The aim of the proposed research is to fill this gap. The theoretical work of Edwards and collaborators [1|2] suggests that| in exactly the same way that knowledge of the partition function of thermal many-body systems makes it possible to predict equilibrium properties and equations of state| so knowledge of the packing entropy would enable the prediction of the bulk behaviour of granular matter. However| we cannot currently test this suggestion because we have no hard numerical data on the packing entropy. Without numerical tests of the existing theories| fundamental progress is blocked. The key to progress is therefore a quantitative knowledge of the packing entropy of granular materials. To evaluate this entropy| we need techniques to compute the number of distinct configurations that assemblies of particles can pack into. This is a daunting task because the number of distinct jammed states grows exponentially with system size. Yet| progress is now within reach. One of the applicants (DF) has recently developed and tested a numerical scheme that makes it possible to count the number of jammed states| even if this number is so large that direct enumeration is utterly impossible. In this project| we will combine the Monte Carlo sampling approach of DF with the methods developed by RB to distinguish topologically distinct jammed structures using basic volume elements| called 'quadrons'. The simulations will be used to test existing theoretical predictions on properties of granular media and| where necessary| to modify the existing theoretical understanding. To establish contact with experiments| we will then investigate the relation between the history of preparation of granular packings and the number of accessible jammed states. As a specific| and very interesting example| we will study the factors that determine whether a granular material will form a crystalline or a disordered structure. The understanding of the nature of random packings is not only an intriguing fundamental theoretical problem| but is also key to advancing on a wide range of scientific and technological problems| as granular matter is ubiquitous in nature and of great importance in technology.[1]. S.F. Edwards| IMA Bulletin 25| A03 3/4 (1989); S.F. Edwards and R.B. Oakeshott| Physica D 38| 88 (1989); S.F. Edwards and R.B. Oakeshott| Physica A 157| 1080 (1989); A. Mehta| S.F. Edwards| Physica A 157| 1091 (1989); S.F. Edwards| Rheologica Acta 29| 493 (1990)[2]. R. Blumenfeld and S. F. Edwards| Phys. Rev. Lett. 90| 114303 (2003); R. Blumenfeld and S. F. Edwards| Eur. Phys. J. E 19| 23-30 (2006)
In recent years there has been a vast development in the engineering of artificial tissues to repair or replace damaged tissue. Scientists can now grow cartilage| produce artificial skin and even print 3D tracheas and are advancing towards the ideal goal of growing replacement organs from a patient's own cells. Whilst present advancements have had some patient benefit this has been limited and there is still a need for a greater understanding of how to control and determine the growth of artificial tissues if we are to achieve extensive improvements to health. The difficulty is that cells do not form tissue in isolation but also require a cell matrix or scaffold. The most promising analytical techniques for tissue engineering at present focus on the growth of cells on artificially printed 3D scaffolds. However| the majority of these techniques either require the labelling of cells with specific markers to detect their presence or the removal of the cells and scaffolds from cell culture conditions thus ending the process and only providing limited information. Our aim is to develop the use of Raman spectroscopy| an alternative non-destructive and label free approach| to investigate in situ cell growth on 3D scaffolds of differing topology.

One process that happens when light is shone at a substance is that it is scattered and sometimes the light scatters at a different wavelength; an effect named Raman scattering. The resultant Raman scattering from a molecule will depend on the chemical structure and for biomolecules it will also depend on the biophysical structure. Recent advancements in Raman spectrometers has enabled Raman maps of live cells to be rapidly collected from which images of cells can be produced identifying biochemical and biophysical changes that occur as cells grow. We will therefore develop Raman spectroscopy as a novel method for the direct in situ analysis of live cells growing on 3D scaffolds of different shapes. Various methods exist to produce artificial 3D scaffolds made from a variety of polymers. One of the most successful is direct laser writing which enables the printing of scaffolds on a microscale using a range of shapes| sizes and materials. By understanding how different scaffold topography affect cells grown in a 3D cell culture environment we will be a step nearer to controlling and determining cell and ultimately tissue growth necessary to advance further the field of tissue engineering.
The University of St Andrews has a vibrant postgraduate research community (across the science faculty there are currently over 400 PhD students) and offers DTP funded PhD studentships in Chemistry| Physics| Mathematics and Computer Science (in the approximate proportions 35/30/20/15%) including where these disciplines intersect with other sciences including Biology| Medicine and Psychology. For general information on postgraduate study at St Andrews see http://www.st-andrews.ac.uk/study/pg/. As a prospective PhD student| you will apply to work with an individual supervisor or supervisory team within a School 
http://www.st-andrews.ac.uk/research/university/schools/ or Institute| 
http://www.st-andrews.ac.uk/research/university/schools/ and not on a specific programme of study. It is therefore important that you look at staff research interests within the University and ensure that your project matches an existing area of research 
http://www.st-andrews.ac.uk/schools/research/. A searchable interface of the research in St Andrews http://risweb.st-andrews.ac.uk/portal/ provides information about the range of research being undertaken. 
Areas of priority for DTP funding include photonic materials| biophotonic techniques for diagnosis| therapy and quantum information| catalysis| materials characterization| new physical sciences for biology and health care| synthetic biology| complexity science (in the form of Discrete Mathematics)| fluid dynamics| geometry and topology| logic and combinatorics| mathematical analysis| computer systems| programming languages| human-computer interaction| artificial intelligence and constraint programming| sensor networks| biomedical modelling cloud and data-driven systems.
St Andrews University has a comprehensive transferable skills training programme for all PhD students (GRADskills) 
http://www.st-andrews.ac.uk/capod/students/pgresearch/gradskills/ that is organised by the University's Centre for Academic| Professional and Organisational Development (CAPOD). New PhD students assess their need for generic skills training together with their supervisor and then take the appropriate transferable skills courses (either from the GRADskills programme or externally| e.g. London Mathematical Society and Scottish Mathematical Sciences Training Centre provide specific generic skills training courses). PhD students are required to take at least two generic skills courses each semester. In addition specialist technical courses in the disciplines are provided together with vibrant seminar programs.
Applications are accepted via the online system at http://www.st-andrews.ac.uk/study/pg/apply/research/. Schools accept applications throughout the year but begin to make offers of DTP funded places from February onwards.
Solid helium-4 is an example of a quantum crystal due to the presence of large quantum fluctuations (zero point motion). It provides an ideal testbed for investigating the quantum behaviour of crystalline matter and structural defects such as dislocations (crystallographic line defects). Experiments by Kim and Chan| showed that a small component of solid helium appeared to decouple from the oscillatory motion of their container (a torsional oscillator)| sparking a huge amount of controversy regarding whether so-called supersolidity (i.e. the paradoxical superfluid flow of a solid) occurs in solid helium. The most recent research points towards the effect been largely due to the anomalous quantum plasticity of solid helium due to the motion of dislocations and their subsequent freezing due to pinning by helium-3 impurities at very low temperatures.

However| there have been several other very recent observations involving four different research groups of an effect due to steady DC rotation that may be independent of the changes in elasticity and instead due to some exotic quantum behaviour and perhaps supersolidity. The correct interpretation of these experiments is unclear and controversial. In addition| the group of Hallock has observed direct DC mass flow through solid helium which has been interpreted as being due to superflow along the cores of dislocations. There is thus a need for new experiments to search for unambiguous evidence of quantum coherence (such as supersolidity) in solid helium. 

Rotation has been successfully used to probe the helium superfluids in many different experiments| perhaps most remarkably in the demonstration of persistent mass currents (due to flow with no dissipation) - the &quot;smoking gun&quot; of superfluidity. We will use our new rotating dilution refrigerator to search for novel quantum phenomena when solid helium is rotated. Firstly| we will look for effects due to steady rotation on a disk of solid helium housed in a torsional oscillator that are independent of elastic effects| which will be measured simultaneously using shear plates. Secondly| we will conduct a direct search for persistent mass currents in solid helium by measuring the angular momentum of flow generated by rotation in an annular channel using a high-sensitivity gyroscope. Observation of persistent currents would constitute direct evidence of supersolid behaviour. Plastic effects and relaxation due to mechanical agitation| such as rapid changes in rotation will also be investigated.
Living organisms construct a tremendous variety of structures across a wide range of sizes| from bones to cells. Yet| the assembly of such structures ultimately rely on the organisation and production of building blocks that are essentially on the molecular to nanoscopic scale (Angstroms to nanometres). These structures| which are composed from a variety of compounds (proteins| fats| DNA) are synthesised by enzymes. These enzymes| which are the molecular machinery of all living organisms| are particularly interesting since they are able to perform a variety of reactions with high efficiency| giving mainly the desired compound with few unwanted by-products. Furthermore| they function under ambient conditions and do not rely on rare or toxic materials. As a result| many types of enzymes are now utilised in the production of medicines and other high-value chemicals.

One area in which enzymes have not been widely studied so far is in the chemistry of organic compounds containing silicon. Such &quot;organosilicon&quot; compounds are mainly used in the form of &quot;silicone&quot;| a plastic-like material. These silicones are extremely widely used in all sectors of human activity| from industrial machine parts| lubricants and sealants; to consumer goods such as homeware| cosmetics and paints; as well as in electronic and surgical devices. Indeed| these materials are economically very important| with the global production and use of silicones giving rise to a multi-&pound;billion turnover annually.

Unfortunately| current methods of producing silicones rely on chlorine-containing raw materials that are ecologically unfriendly and energy demanding to produce. In contrast| some species of marine sponges use silicon (in the form of glass-like silica) as part of their skeleton. To form this skeleton| the sponges employ a family of enzymes called &quot;silicateins&quot;| which are able to react with silica. 

Recent research by the lead investigator has shown that| remarkably| these enzymes are able to catalysethe formation| as well as degradation| of a range of organosilicon compounds under relatively mild conditions (less than 100 degrees C| using non-toxic starting materials). Thus| these enzymes could potentially offer a sustainable means of producing silicone compounds that would find use in many areas of the chemical industry. Furthermore| the silicateins could also be applied to decompose unwanted silicone waste into compounds that could be recycled| which cannot currently be achieved using conventional chemical methods.

Accordingly| the goals of this research are to investigate the feasibility of using silicateins for the efficient and precise synthesis of silicone materials| and develop modified versions of the enzymes that will be able to perform the production of silicones with a variety of chemical structures. The types of silicones that will be targeted include both silicones that are applicable to industrial applications| but also novel types that are otherwise difficult to synthesise by other means. In parallel| the feasibility of using them in the reprocessing and recycling of silicones will also be researched. In all cases| a major part of this research will be to study the chemical mechanisms by which the silicateins are able to perform these reactions. Such an understanding of how these enzymes function will therefore allow us to make modifications to improve their capabilities.
Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes| see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.
In the age of Big Data| knowledge workers - individuals| companies and organisations whose primary focus is knowledge
and information extraction and usage - find it increasingly difficult to search for and identify accurate and relevant
information. In particular| in the domain of scientific literature and IP search| where the underlying corpora are growing at a
huge rate| this is a daunting task and human expertise and involvement remain critical. This project aims to develop a suite
of techniques and methods that will enable users to search for and identify relevant information within a corpus more
efficiently and effectively. The methods developed will deploy semantic-based analysis| domain and lexical linguistic
ontologies in order to first understand the user needs based on the underlying domain of application and subsequently
enable more accurate information retrieval through enhanced search and cross-reference of information. In addition| the
project aims to offer advanced user services through sharing of search strategies which will be identified by observing and
understanding patterns in users' search behaviours.
The proposed research concerns the synthesis of the complex marine natural product gambieric acid A from simple| commercially available starting materials. The gambieric acids (A-D) were isolated in minute amounts from a simple marine alga which was collected off the coast of the Gambier Islands in the South Pacific. These natural products possess very powerful activity against certain types of disease-causing fungi. Structurally related natural products isolated from the same alga are highly neurotoxic (i.e. they prevent nerves from functioning properly)| but the gambieric acids do not possess this activity and can block the toxicity of neurotoxic marine natural products of similar structure. Gambieric acid A has a very complex molecular structure comprising 10 ether (oxygen-containing) rings - nine of which are fused together - and 27 chiral centres (i.e. carbon atoms where the handedness defines the three-dimensional structure of the molecule) embedded in the molecular framework. The aim of the project is to synthesise gambieric acid A in a highly efficient manner using new chemical reactions and strategies to construct the rings and join complex fragments of the molecule together. The proposed research is extraordinarily challenging because few molecules of comparable size and complexity have been synthesised and very elaborate and relatively inefficient routes have been used to construct those that have. The proposed project is particularly challenging because some of the rings are difficult to construct| due to their size| and the configurations of all 27 chiral centres must be set unambiguously.The important features of our synthesis will be the highly efficient and rapid synthesis of molecular fragments by simultaneous construction of rings in two directions (so-called two-directional or bi-directional synthesis) and the efficient union of these pieces to form the intact molecule. Examples of two-directional chain or ring construction are very rare in complex natural product synthesis| and the use of this strategy to assemble such a complex target is unprecedented. The research project will allow us to test whether two-directional ring construction is a viable strategy and will allow us develop the synthetic techniques and tools required to construct complex biologically active natural products in an efficient manner. The successful synthesis of gambieric acid A will also permit the biological activity of the natural product to be explored further and will allow the relationship between the molecular structure and the biological activity of marine polyethers to be elucidated more clearly. The synthetic strategies| tactics and reactions that we develop during the project will be generally applicable to a wide variety of other complex natural product targets.
The proposed research seeks to develop and validate a time dependent| 3D numerical model of inclined oil-water pipe flow. Inclined oil-water flows are commonly encountered downhole in oil wells at depths where the hydrostatic pressure is too high to allow dissolved gases to come out of solution. 'Production Logging Tools' (PLTs) are used by oil companies to make fluid flow measurements in such oil wells| as part of the process of maximising oil production from UK reservoirs| and the numerical model will greatly facilitate interpretation of measurement data from these PLTs. Inclined oil-water flows are highly complex due to the presence of Kelvin-Helmholtz (K-H) waves which intermittently form and decay. The effect of these waves is to induce large| time dependent variations in the magnitude and direction of the local velocity vector of both the oil and water as well as causing large time dependent variations in the local volume fraction distribution of both phases. It is intended that the numerical model will predict the fine detail of the structure of inclined oil-water flows including (i) time dependent variations in the local velocity vector distribution of both phases; (ii) time dependent variations in the local volume fraction distribution of both phases; and (iii) the structure and propagation speed of intermittent K-H waves in the flow. If the model is successful in predicting the propagation speed of K-H waves for a wide range of flow conditions this will greatly facilitate interpretation of a novel Production Logging technique which estimates the oil-water mixture superficial velocity from measurements of the K-H wave speed. The numerical model will be validated in oil-in-water flows using a laboratory flow loop and two independent| state of the art measurement techniques which enable time dependent measurements of the local velocity vector of the dispersed phase (oil) and the local volume fraction of both phases to be measured. These techniques are; (i) high speed dual-plane Electrical Impedance Tomography (EIT) and (ii) the local| multi-sensor conductance probe. Both techniques can operate at high values of the mean dispersed phase volume fraction (e.g. for oil-in-water flows EIT operates up to about 45% oil volume fraction and the local probe operates up to about 30% oil volume fraction) where optical techniques such as PIV and LDA cannot generally be used due to the effects of light scattering from multiple oil droplet surfaces and the opacity of the oil-water mixture. Given the highly novel and innovative nature of both high speed| dual-plane EIT and the local multi-sensor conductance probe| work will be undertaken to develop these techniques such that measurements obtained from them are of sufficient accuracy to be useful in validating the numerical model. Since both measurement techniques are novel| an important feature of the proposed research will be the cross-checking of these techniques against each other.
Since 9-11 and 7-7| terrorism has been a major public concern. To ensure public safety and to protect the UK economy| research is needed that offers new methods to foil attacks before they are executed| to identify people and networks who might be preparing for or undertaking an attack| and to provide clear evidence that can be used to justify questioning| arrests and prosecutions. In this study| we will investigate whether deception can be identified and proved from 'scent trails'| that is| coherent accounts of suspects' activities over time compiled from tracking their movements| communications and behaviours. We will develop software to derive inferences about what activities are consistent with suspects' scent trails and what are ruled out. These inferences will allow investigators to challenge suspects| both in real time (e.g.| to encourage suspects to abandon an ongoing attack) and during interviews (e.g.| to point out inconsistencies between a suspect's account and scent trail evidence that might change the course of an interview). The project will investigate scent trails in the context of people undertaking deceptive activities to gain advantage in adversarial 'treasure hunt'-type games. The games will be developed in consultation with stakeholders to provide a non-sensitive analogy to counter-terrorism contexts. Players| typically undergraduate students paid for participation| will be monitored during games via positional and communication data obtained from mobile devices enabled with geospatial positioning devices. Novel software for integrating these data will be developed to build up scent trails of players' activities during game play. Methods of artificial intelligence will be combined to derive inferences from the scent trails about what kinds of activity are possible and impossible given a player's location| trajectory| activities and links with others. We envision games with 3 teams: Team A represent the adversary| Team B the police or general public| and Team C the intelligence services. Team A scores points by visiting target locations within a time limit under a set of game rules that they must violate if they are to win. They must try to hide rule violations from Team B| who score points by preventing or identifying Team A's deceptions successfully. Team C can challenge Team A by sending them indications of the scent trails that are held or can feed Team B intelligence information. Moreover| the inferences from scent trails will support Team C in deciding how best to prove or falsify a suspicion during an interview with Team A players at key points during the games. By conducting observation of players during games| we can investigate how people change their behaviours when they are confronted with evidence that reveals their deceptions. We will also interview players at key points during games as a simulation of interviews with suspects| eliciting from players accounts of their activities before presenting them with challenges based on their own scent trails that are either consistent or inconsistent with legal game playing. This will allow interview and analysis techniques to be improved and will provide clues as to how people subsequently change their behaviour after they have been confronted with their deception. The results will also allow us to test between hypotheses deriving from forensic psychology as to how best to detect deception. The research also allows us to explore public awareness of| and response to| monitoring and surveillance in counter-terrorism. With an advisory panel of stakeholders and subject specialists representing key public and academic bodies| we will identify ethical and legal issues associated with collecting and using data on peoples' movements through public spaces. We will also conduct questionnaire studies with game players and others not involved in the games| to measure attitudes to monitoring and surveillance in game-playing and other contexts.
Microwave and terahertz technologies play a critical role in modern life. Microwaves underpin mobile and satellite communications and are used for radar in navigation and meteorology. At higher frequencies| terahertz technologies are used to perform chemical sensing| non-invasive imaging| condition monitoring and more. These applications| and others| require fast detectors offering high sensitivity and the ability to perform spatially resolved imaging| which is particularly challenging in the terahertz domain where the majority of detectors require cryogenic cooling and offer slow thermal response times with limited absolute accuracy.

In this proposal we seek to address this technology gap by developing a new class of atom-based sensors that exploit the extreme sensitivity of highly-excited Rydberg atoms which act as antennae to provide precision electric field measurement across the microwave and terahertz frequency range. Using lasers to excite Rydberg atoms in a thermal vapour cell| the radio-frequency fields can be measured from the resulting perturbation in the transmission of a weak probe beam.

Atom-based sensors provide a number of advantages over traditional electric field measurement techniques; namely (i) they are intrinsically calibrated by relating the atomic properties to SI units to provide full measurement traceability| (2) act as point-like antenna for an in-situ measurement of the field| and (3) can be optically probed to enable sub-wavelength resolution of the radio-frequency field under study. 

The proposed research programme will explore a number of key challenges to implementing Rydberg-atom-based electric field sensors| including optimising the cell materials and geometry to minimise the perturbation or suppression of the applied field and developing measurement techniques to achieve the fundamental limits of sensitivity and accuracy. To address these challenges we will combine UK based expertise| including the pioneers of optical detection of Rydberg atoms| to fabricate and characterise atomic vapour cells compatible with microwave and terahertz measurements and demonstrate precision field measurement and 2D imaging of structured radio-frequency fields. To verify the device accuracy we will compare the performance of our sensors to state-of-the-art calibrated references at the National Physical Laboratory. Finally| we will demonstrate real-world application of the sensors to areas including all-optical microwave communication schemes similar to WiFi and characterisation of the complex near-field emission from a terahertz antenna array. These sensors offer a new approach to radiofrequency sensing| imaging and metrology and provide a route to achieving enhanced sensitivity at microwave frequencies whilst providing an enabling technology for emerging applications in the terahertz domain.
Robotics is changing the landscape of innovation. But traditional design approaches are not suited to novel or unknown habitats and contexts| for instance: robot colonies for ore mining| exploring or developing other planets or asteroids| or robot swarms for monitoring extreme environments on Earth. New design methodologies are needed that support optimising robot behaviour under different conditions for different purposes. It is accepted that behaviour is determined by a combination of the body (morphology| hardware) and the mind (controller| software). Embodied AI and morphological computing have made major progress in engineering artificial agents (i.e.| robots) by focusing on the links between morphology and intelligence of natural agents (i.e.| animals). While such a holistic body-mind approach has been hailed for its merits| we still lack an actual pathway to achieve this.
While this goal is ambitious| it is achievable by introducing a unique methodology: a hybridisation of the physical evolutionary system with a virtual one. On the one hand| it is appreciated that an effective design methodology requires the use and testing of physical robots. This is because simulations are prone to hidden biases| errors and simplifications in the underlying models. Simulating populations of robots (rather than just simulating specific parts) leads to accumulated errors and a lack of physical plausibility: the evolved designs will not work in the real system. This is the notorious reality gap of evolutionary robotics. On the other hand| evolving everything in hardware is time and resource consuming. One of our major innovations is to run simulated evolution concurrently with the physical and hybridise them by cross-breeding| where a physical and a virtual robot can parent a child that may be born in the real world| in the virtual world or in both. The advantages of such a hybrid system are significant. Physical evolution is accelerated by the virtual component that can run faster to find good robot features with less time and resources; simulated evolution benefits from the influx of genes that are tested favourably in the real world. Furthermore| monitoring of and feedback from the physical system can improve the simulator| reducing the reality gap.
A mason begins a new project by first taking stock of the materials available - bricks and stones come in various shapes and sizes. He or she then must recall the rules governing how the bricks may be assembled and stacked. There is a general principal here: creating a complicated composite object like a house or a tower from elementary pieces like bricks requires that one first answer two questions.1. What are the elementary building blocks available? 2. How are these allowed to be assembled?Although mathematicians work with purely intellectual and abstract objects| often they| like masons and engineers| must build complicated objects from simpler ones. In mathematics| the answers to both of the above questions are often encapsulated in the form of a intricate mathematical object known as a 'moduli space'. It is a geometric object that we can visualise| and its geometric and topological properties -- the curvature and size and shape -- encode a wealth of important information.For example| a mathematical building block could be the solution set to an equation| such as the parabola y = x^2. A moduli space is the object which tells us how things like the solution set of an equation can be extruded and bent and wrapped around to make more complicated objects; it can tell us about the shapes of all possible parabolas at once. Moduli spaces are the universal blueprints describing simultaneously all possible composites which can be assembled from the basic building blocks.Two of the most fundamental types of moduli spaces in mathematics are the `moduli spaces of algebraic curves'| and the `moduli spaces of abelian varieties'. These sets of blueprints are created by the intricate machinery of algebraic geometry and they are used in many branches of mathematics| as well as in theoretical physics. The problem is that we cannot fully read them yet. My research program brings the powerful tools of topology to bear on these moduli spaces from algebraic geometry. The tools of one field illuminate the creations of another| and a better understanding of the structure of these moduli spaces could lead to results in many mathematical fields| such as number theory or even theoretical physics. It is an example of the interconnectedness of the mathematical universe. The novelty and advantage of using topological tools here is that topology is designed to organise and filter information; it ignores the the local structure and sees only the underlying global skeletal structure. Focusing attention on only the global structure allows a flexibility of models| and this flexibility can reveal patterns and properties that were previously invisible. This is what led to the proof of the Mumford conjecture by Madsen and Weiss| which described much of the topological structure of the moduli spaces of algebraic curves. I will apply these and other techniques to the moduli spaces of abelian varieties and related spaces.
This application brings together two world-renowned research- and educational-focused Universities in a unique collaboration to create an interdisciplinary training approach to meet challenges in healthcare. With complementary strengths in basic physical sciences| engineering and clinical translation| close strategic and geographical links and a CDT embedded within a top-rated teaching hospital| the KCL/ICL alliance is superbly placed to train the next generation of imaging scientists and research leaders.
The CDT will provide a unique interdisciplinary training program to develop the skills for creating innovative technical solutions through integration of the physical sciences| engineering and biological and clinical disciplines. The Centre will be integrated into a large research portfolio in medical imaging funded through EPSRC/Wellcome Trust Medical Engineering Centres| MRC centres| the CRUK/EPSRC Cancer Imaging Centres| and the BHF Centres of Excellence. In order to foster clinical translation of research| the CDT will be linked into two Academic Health Science Centres and NIHR-Biomedical Research Centres.
The CDT will create a critical mass of teachers and researchers to establish an interdisciplinary training program by bringing together students from different disciplines to work on research topics in medical imaging. The CDT will feature a 1 + 3 years MRes+PhD structure and will manage the students as a single cohort. We have developed the different phases of the PhD programme| i.e. Recruitment| MRes| PhD and Alumni| to achieve the highest quality in training| research and career development for the individual student. We place a strong emphasis on clinical translation| therefore the CDT will continue with a formal training programme in clinical applications in parallel to the PhD projects. In addition| the teaching location of the Centre in a dedicated| newly-refurbished CDT teaching hub within a world-class teaching hospital engenders strong links with the NHS and provides further enhanced opportunities for clinical translation. The first and foremost goal of this CDT will be to provide the highest quality supervision for individual students. To achieve this| we will combine the experience of senior supervisors with the energy and development of more junior academics. At the start of the CDT| we will be defining PhD projects from 60 supervisors with world-leading research expertise in the underpinning of the multidisciplinary themes in medical imaging. All of those scientists have a track record in PhD supervision and delivering research funded by research councils.
We have also identified clinical champions in three major disease areas (Cardiology| Oncology| Neuro) who will organize training in clinical application. This training is designed to forge interactions between scientists and clinicians. It will provide students with valuable contacts with whom they can discuss clinical implications of their PhD research.

The CDT will provide training of a new generation of scientists with skills in interdisciplinary research| clinical translation and entrepreneurship. The focus of both graduate training and the individual student research projects will be to innovate medical imaging technologies in the care cycle of patients across a range of diseases. Another central theme within the program will be training to translate innovations into commercial products. For this| we will leverage our strong industrial links and have obtained financial commitment for more than 25 co-funded industrial CDT studentships from various industrial partners. The partners| including new UK-based SMEs and start-up companies| will also provide internships to enable career paths into industry.
This project aims to provide the fundamental basis to enable microwave processing as a viable technology for the extraction of oils from tar-sands and oil-shales. If successful the technology will offer a step-change in energy efficiency compared with conventional processes| thereby improving both the technical and economic feasibility of oil extraction. It is estimated that there are in excess of 450 billion tonnes of tar sands located throughout the world| with only 10% of these being economically extractable using existing technology. Compared with the 140 billion tonnes of proven crude oil reserves| a small increase in the extractable tonnage of tar sands will have a dramatic impact on the future security and sustainability of worldwide energy reserves. Current extraction technology for tar sands is limited by the energy intensity of the process. Natural gas usage alone amounts to over 1200 kWh per tonne of extracted oil in the conventional hot-water extraction process. Previous studies have identified microwave technology as an energy efficient alternative| and shown that oil can be extracted from both shales and tar sands. The limitation of this research was the lack of understanding of the interaction of microwaves with the materials of interest| resulting in a non-optimised microwave cavity where the potential benefits of the technology were not realised to their full extent. This study will utilise the facilities| expertise and networks available at the University of Nottingham to adopt a multidisciplinary approach. Laboratory studies will be undertaken to enhance the understanding of the interaction of oil shales and tar sands with microwaves| and the fundamental oil extraction mechanisms. This knowledge will be used to input into the design of a continuous microwave cavity to yield a precisely defined electric field strength and distribution. Studies using the optimised| continuous system will assess the technical abilities and limitations| and will be used to understand how the design needs to change for different feedstocks and larger scale operation. The project will deliver the fundamental scientific understanding which will form a platform for future exploitation by industry and academia.This First Grant project addresses several key areas highlighted in the recent EPSRC International Review of Engineering| namely high risk| high impact research involving younger researchers and interdisciplinary research.
Future generation (5G) mobile phones and other portable devices will need to transfer data at a much higher rate than at present in order to accommodate an increase in the number of users| the employment of multi-band and multi-channel operation| the projected dramatic increase in wireless information exchange such as with high definition video and the large increase in connectivity where many devices will be connected to other devices (called &quot;The Internet of Things&quot;). This places big challenges on the performance of base stations in terms of fidelity of the signal and improved energy efficiency since energy usage could increase in line with the amount of data transfer. To meet the predicted massive increase in capacity there will be a reduced reliance on large coverage base-stations| with small-cell base-stations (operating at lower power levels) becoming much more common. In addition to the challenges mentioned above| small cells will demand a larger number of low cost systems.

To meet these challenges this proposal aims to use electronic devices made from gallium nitride (GaN) which has the desirable property of being able to operate at very high frequencies (for high data transfer rates) and in a very efficient manner to reduce the projected energy usage. To maintain the high frequency capability of these devices| circuits will be integrated into a single circuit to reduce the slowing effects of stray inductances and capacitances. Additionally these integrated circuits will be manufactured on large area silicon substrates which will reduce the system unit cost significantly.

The proposed high levels of integration using GaN devices as the basic building block and combining microwave and switching technologies have never been attempted before and requires a multi-disciplinary team with complementary specialist expertise. The proposed consortium brings together the leading UK groups with expertise in GaN crystal growth (Cambridge)| device design and fabrication (Sheffield)| high frequency circuit design and fabrication (Glasgow)| variable power supply design (Manchester) and high frequency characterisation and power amplifier design (Cardiff). Before designing and developing the technology for fabricating the integrated systems to demonstrate the viability of the proposed solutions| a deep scientific understanding is required into how the quality of the GaN crystals on silicon substrates affect the operation of the devices. In summary| the powerful grouping within the project will bring together the expertise to design and produce the novel integrated circuits and systems to meet the demanding objectives of this research proposal.
Many important activities in our lives involve the web. We socialize on Facebook| have fun on YouTube| bank online| store our work in the cloud| find a job on LinkedIn and some of us even get married on Second Life. What makes web technology so exciting is that people and companies keep finding new and creative ways of using it for applications not foreseen by its designers: for example| using the web to make phone calls and mobile phones to browse the web.Unfortunately| for this very reason| the software and protocols on which web applications are based are not designed with the appropriate level of security in mind. Some of the information we share with web applications is very valuable| and should be protected carefully. News stories often remind us how cyber-crime negatively affects our finances| privacy and well-being.Web companies are strongly innovation-driven and focus on delivering new applications and features as quickly as possible| selecting which ones to maintain based on popularity or profitability. While the importance of security is acknowledged| the most common approach is to enforce security by monitoring the system and intervening when a security violation is detected. As this industry matures| there is a raising awareness that security must to be built into the languages and tools used to program web applications| and there is a growing need to gain some level of confidence that an application is effectively secure.In my career so far| I have studied in depth the foundations and principles for understanding computer programs and making sure that they work correctly without security breaches. Over the next few years| I will face the challenge of applying these principles to lay web programming on a sound formal ground. I want to understand deeply the current and emerging technologies that are used on the web| find ways to make them more secure| and contribute to the design of future web technologies and tools. This process will involve lots of creative thinking| and lead to innovative scientific results| because a secure web application must combine securely non-trivial components such as databases| internet protocols| scripting languages and web browsers.Here is an example of a first step in the direction of my proposal. Facebook users write Facebook applications in JavaScript (the language that sits inside web pages and makes them interactive) and share them with other users. This raises the problem of restricting such JavaScript| written by a potentially malicious user| to make sure that it is safe for all the other Facebook users. With colleagues in Stanford| I modelled JavaScript as a set of simple mathematical formulas with a very precise meaning| and once I understood the language and its security properties (by proving several mathematical results)| I studied the way Facebook restricts JavaScript and found several flaws. A malicious user could have written bad Facebook applications| able to steal information and damage the profile or the web browser of other users. I contacted the Facebook team and discussed possible solutions| and they modified their restriction mechanism accordingly.This is just an example of how the work I am proposing consists in original foundational research that also has direct impact on the life of millions of people. Following a similar approach I will also model the languages that are used to program web servers| such as PHP| and the browser with its DOM libraries| and study their security properties. I will participate in the definition of standards related to web security| and influence the design of several major web applications such as the future versions of the iGoogle portal| Yahoo!'s advertising platform and the Microsoft Web Sandbox framework for mashups. I have already met researchers from these companies| all interested in receiving input from this line of research.
Aerospace is a key sector for the UK| with strategic importance in view of its contribution to the economy and major research challenges to address global environmental issues. Regional| national and international strategies have identified aerospace as a key sector for the UK and Europe and this has resulted in the provision of substantial funding for the sector. The University of Nottingham aims to strengthen and consolidate its position as a leading institution for research into aerospace technologies by building on its existing broad research base and current portfolio of aerospace research and investing in infrastructure and business engagement activity to further grow its portfolio in line with industrial demands for knowledge| skills and technologies. This proposal presents a case for a 1.38M EPSRC investment into equipment to support the University's large and growing aerospace research portfolio. Building upon our substantial EPSRC portfolio related to aerospace research| the capital equipment will underpin fundamental research into aerospace technologies| leading to applied research| demonstration and exploitation. The equipment contributes to three research themes where UoN has world-leading research activities; - Power Conversion| Power Systems and Future Actuation Technologies for the More Electric Aircraft| led by Prof Pat Wheeler| Prof Jon Clare| Prof Mark Johnson - Non-Destructive Evaluation for Next Generation Aerospace Materials and Structures| led by Dr Matt Clark| Prof Andy Long| Prof Mike Somekh| Prof Richard Challis. - Advanced Manufacturing for the Aerospace Sector| led by Prof Svetan Ratchev| Prof Nabil Gindy| Dr Atanas Popov| Dr Neils Lohse| Dr Dragos Axinte.Researchers within each of these themes are addressing key research challenges for the sector and through their current and future applied research programmes will contribute to the sector's ability to meet the targets set by the Advisory Council on Aeronautics Research in Europe (ACARE). For manufacturers and suppliers| this means demonstrating continual improvements in the performance of new aircraft entering into service in 2020| compared with their 2000 equivalents| by committing to challenging targets on fuel efficiency| NOx emissions and noise. Fundamental research| leading to applied research and demonstration| is essential if the UK is retain its position as one of the world's leaders in aerospace innovation and continue to enjoy the commercial advantages provided by our air transport sector.
The UK Engineering and Physical Science Council (EPSRC) funded research consortium| Supergen Marine (1)| which consisted of the University of Edinburgh; Heriot-Watt University; The University of Lancaster; The University of Strathclyde and the Robert Gordon University| has| since October 2003| been undertaking cutting edge research in support of the developing marine renewables industry. The consortium| which has been modified to include The Queen's University Belfast and the move of key members of the Robert Gordon University Marine Energy Group to the University of Edinburgh| is now bidding for continued support from the research council. The aims of the original Supergen marine research programme primarily related to enhancing understanding of the location| extent and characteristics of the marine energy resources. This was on a 3-10 year horizon| and is still valid. However| research priorities have evolved to recognise experiences and questions arising from early tests| the deployment of prototype devices and the outcomes of the original work programme. The overall aim| while still generic| has evolved and is now directed| in the revised research programme| towards increasing understanding of the device-sea interactions of energy converters from model-scale in the laboratory to full size in the open sea. The programme includes work on: device arrays and how these will influence local and regional environmental conditions; radical design approaches| which take into account new philosophies of design guidance; ensuring that numerical and physical design support is consistent and robust; the challenges posed by design in mixed tidal and wave environments; system control in complex non linear and evolving environments; the complex challenges posed by fixing| mooring and recovery of marine systems; the economic challenges posed by the variable and intermittent nature of the marine resource; the sparse information available to predict and assess the long term reliability of marine energy systems and how an increased understanding of all of these issues can be best disseminated within the stakeholder community.
A novel product will be developed for designing| drilling| completing and managing well systems that incorporate many laterals with increased reservoir contact for geothermal industry. A hybrid drilling approach| based on conventional and jetting (water and supercritical-CO2) technologies| will be employed along with advanced numerical models to help optimise the deployment and management of the well system. The product targets the fast-growing geothermal industry| and can be readily re-applied to oil/gas production| with a particular focus on intermediate-deep geothermal resources. Objectives of this work include: (1) application of advanced well drilling and completion technologies for more efficient well system construction; (2) evaluation of new-generation numerical models for solving fluid flow and heat transfer problems in complex well-reservoir systems| (3) optimisation of well design and management for cost-effective production| and (4) deployment of the product to geothermal reservoirs for field trials. The novelty of this project comes from the unique combination of new drilling and completion technologies with novel computational methodologies for well management and production.

China's current energy demands require innovative| cost-effective and environment-friendly solutions. We are proposing an innovative multi-lateral well system Smart-GeoWells to help meet these challenges. This will be used to develop cleaner| more affordable| localised (building| village| town| city) heating/hot water and electricity| harnessing almost limitless| sustainable and secure geothermal energy. In order to develop the new multi-lateral wells (with potentially hundreds of laterals)| the proposed team (each member a world-leader in their fields) will apply their specialised knowledge in testing and exploiting the new well engineering solutions| hybrid drilling technologies| advanced numerical modelling and optimal well design and management methods. For the UK and China teams| this will be the first stepping stone towards long-term collaboration| aiming at optimal exploitation of geothermal resources and if successful will have a massive impact on the energy sector. However| the scope of the work is also immense and thus our initial product (that we aim to develop rapidly) will be focussed on geothermal hot water production| although the developed technology can serve as a longer term product for geothermal electricity generation as well as O&amp;G production. The new multi-lateral drilling concepts of XLTL (project partner) together with the novel techniques in modelling multiphase fluid flows and heat transfer through these large number of laterals (similar to the fishbone structure)| will lead to economic and efficient ways of drilling financially-competitive multi-lateral wells through: a) enhanced contact and connectivity with geothermal regions; b) minimisation of environmental damage i.e. pollution of groundwater sources/surrounding countryside and c) optimal control/management of the production wells. During the project| Sinopec will provide geothermal sites| test equipment and specialised engineers/technicans for field trials (the company's funding contribution amounts to 5 million RMB) with which the advanced drilling techniques will be examined and the prediction software will be validated. The developed Smart-GeoWells platform will be made available to the interested local and other companies/businesses| as well as public services| and will also benefit them through enhanced knowledge and technology transfer. The longer-term implications on the welfare of the local and other communities are immense| both directly through reduced pollution (water and air) and climate change impacts and| indirectly| through economic impacts.
